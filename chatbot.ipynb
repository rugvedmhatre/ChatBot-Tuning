{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "2d73704b09784a40a1ed89525ab054c1": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "VBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "VBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "VBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_196bb02d6f17472d8c1b28bbe08fa634",
              "IPY_MODEL_4d6c1ec8510f4bca8d5a36ce267e8df5"
            ],
            "layout": "IPY_MODEL_84c4b5c8d3af4bacb5f0df99c7ba2938"
          }
        },
        "196bb02d6f17472d8c1b28bbe08fa634": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "LabelModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "LabelModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "LabelView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_a26b80662951462083cfbfe27ff5190e",
            "placeholder": "​",
            "style": "IPY_MODEL_5642e2242c074ae3804f00e57cd40ba9",
            "value": "0.011 MB of 0.011 MB uploaded\r"
          }
        },
        "4d6c1ec8510f4bca8d5a36ce267e8df5": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_24fa38c2ec3a48fe8b6f1db2b287dedf",
            "max": 1,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_43d95ea04a74479d97e7b18290019dc8",
            "value": 1
          }
        },
        "84c4b5c8d3af4bacb5f0df99c7ba2938": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "a26b80662951462083cfbfe27ff5190e": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "5642e2242c074ae3804f00e57cd40ba9": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "24fa38c2ec3a48fe8b6f1db2b287dedf": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "43d95ea04a74479d97e7b18290019dc8": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        }
      }
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# HPML Assignment 3\n",
        "\n",
        "**Author:** Rugved Mhatre (rrm9598)"
      ],
      "metadata": {
        "id": "y44vlxcDIgHT"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Problem 1.1"
      ],
      "metadata": {
        "id": "0G4ddQbrLNt6"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Preparations\n",
        "\n",
        "Downloading Cornell Movie-Dialogs Corpus dataset"
      ],
      "metadata": {
        "id": "WGXDEM7KIp3r"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "UKF5PEitFSpG",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d8387215-f355-4a0c-b7f4-73830c45a95f"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--2024-10-24 04:07:11--  https://zissou.infosci.cornell.edu/convokit/datasets/movie-corpus/movie-corpus.zip\n",
            "Resolving zissou.infosci.cornell.edu (zissou.infosci.cornell.edu)... 128.253.51.179\n",
            "Connecting to zissou.infosci.cornell.edu (zissou.infosci.cornell.edu)|128.253.51.179|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 40854701 (39M) [application/zip]\n",
            "Saving to: ‘data/movie-corpus.zip’\n",
            "\n",
            "data/movie-corpus.z 100%[===================>]  38.96M  13.5MB/s    in 2.9s    \n",
            "\n",
            "2024-10-24 04:07:14 (13.5 MB/s) - ‘data/movie-corpus.zip’ saved [40854701/40854701]\n",
            "\n",
            "Archive:  data/movie-corpus.zip\n",
            "   creating: data/movie-corpus/\n",
            "  inflating: data/movie-corpus/utterances.jsonl  \n",
            "  inflating: data/movie-corpus/conversations.json  \n",
            "  inflating: data/movie-corpus/corpus.json  \n",
            "  inflating: data/movie-corpus/speakers.json  \n",
            "  inflating: data/movie-corpus/index.json  \n"
          ]
        }
      ],
      "source": [
        "!mkdir -p data\n",
        "!wget -O data/movie-corpus.zip https://zissou.infosci.cornell.edu/convokit/datasets/movie-corpus/movie-corpus.zip\n",
        "!unzip -o data/movie-corpus.zip -d data"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Importing libraries"
      ],
      "metadata": {
        "id": "kY7FKVyOKRQZ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "from torch.jit import script, trace\n",
        "import torch.nn as nn\n",
        "from torch import optim\n",
        "import torch.nn.functional as F\n",
        "import csv\n",
        "import random\n",
        "import re\n",
        "import os\n",
        "import unicodedata\n",
        "import codecs\n",
        "from io import open\n",
        "import itertools\n",
        "import math\n",
        "import json\n",
        "import time\n",
        "import numpy as np\n",
        "\n",
        "USE_CUDA = torch.cuda.is_available()\n",
        "device = torch.device(\"cuda\" if USE_CUDA else \"cpu\")"
      ],
      "metadata": {
        "id": "akM99CpTKcUb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Load & Preprocess Data"
      ],
      "metadata": {
        "id": "B3jmRmiqLopR"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "corpus_name = \"movie-corpus\"\n",
        "corpus = os.path.join(\"data\", corpus_name)\n",
        "\n",
        "def printLines(file, n=10):\n",
        "    with open(file, 'rb') as datafile:\n",
        "        lines = datafile.readlines()\n",
        "    for line in lines[:n]:\n",
        "        print(line)\n",
        "\n",
        "printLines(os.path.join(corpus, \"utterances.jsonl\"))"
      ],
      "metadata": {
        "id": "xGG_fOswLo8K",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "3e013667-011d-459b-cd91-7299fb656c7a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "b'{\"id\": \"L1045\", \"conversation_id\": \"L1044\", \"text\": \"They do not!\", \"speaker\": \"u0\", \"meta\": {\"movie_id\": \"m0\", \"parsed\": [{\"rt\": 1, \"toks\": [{\"tok\": \"They\", \"tag\": \"PRP\", \"dep\": \"nsubj\", \"up\": 1, \"dn\": []}, {\"tok\": \"do\", \"tag\": \"VBP\", \"dep\": \"ROOT\", \"dn\": [0, 2, 3]}, {\"tok\": \"not\", \"tag\": \"RB\", \"dep\": \"neg\", \"up\": 1, \"dn\": []}, {\"tok\": \"!\", \"tag\": \".\", \"dep\": \"punct\", \"up\": 1, \"dn\": []}]}]}, \"reply-to\": \"L1044\", \"timestamp\": null, \"vectors\": []}\\n'\n",
            "b'{\"id\": \"L1044\", \"conversation_id\": \"L1044\", \"text\": \"They do to!\", \"speaker\": \"u2\", \"meta\": {\"movie_id\": \"m0\", \"parsed\": [{\"rt\": 1, \"toks\": [{\"tok\": \"They\", \"tag\": \"PRP\", \"dep\": \"nsubj\", \"up\": 1, \"dn\": []}, {\"tok\": \"do\", \"tag\": \"VBP\", \"dep\": \"ROOT\", \"dn\": [0, 2, 3]}, {\"tok\": \"to\", \"tag\": \"TO\", \"dep\": \"dobj\", \"up\": 1, \"dn\": []}, {\"tok\": \"!\", \"tag\": \".\", \"dep\": \"punct\", \"up\": 1, \"dn\": []}]}]}, \"reply-to\": null, \"timestamp\": null, \"vectors\": []}\\n'\n",
            "b'{\"id\": \"L985\", \"conversation_id\": \"L984\", \"text\": \"I hope so.\", \"speaker\": \"u0\", \"meta\": {\"movie_id\": \"m0\", \"parsed\": [{\"rt\": 1, \"toks\": [{\"tok\": \"I\", \"tag\": \"PRP\", \"dep\": \"nsubj\", \"up\": 1, \"dn\": []}, {\"tok\": \"hope\", \"tag\": \"VBP\", \"dep\": \"ROOT\", \"dn\": [0, 2, 3]}, {\"tok\": \"so\", \"tag\": \"RB\", \"dep\": \"advmod\", \"up\": 1, \"dn\": []}, {\"tok\": \".\", \"tag\": \".\", \"dep\": \"punct\", \"up\": 1, \"dn\": []}]}]}, \"reply-to\": \"L984\", \"timestamp\": null, \"vectors\": []}\\n'\n",
            "b'{\"id\": \"L984\", \"conversation_id\": \"L984\", \"text\": \"She okay?\", \"speaker\": \"u2\", \"meta\": {\"movie_id\": \"m0\", \"parsed\": [{\"rt\": 1, \"toks\": [{\"tok\": \"She\", \"tag\": \"PRP\", \"dep\": \"nsubj\", \"up\": 1, \"dn\": []}, {\"tok\": \"okay\", \"tag\": \"RB\", \"dep\": \"ROOT\", \"dn\": [0, 2]}, {\"tok\": \"?\", \"tag\": \".\", \"dep\": \"punct\", \"up\": 1, \"dn\": []}]}]}, \"reply-to\": null, \"timestamp\": null, \"vectors\": []}\\n'\n",
            "b'{\"id\": \"L925\", \"conversation_id\": \"L924\", \"text\": \"Let\\'s go.\", \"speaker\": \"u0\", \"meta\": {\"movie_id\": \"m0\", \"parsed\": [{\"rt\": 0, \"toks\": [{\"tok\": \"Let\", \"tag\": \"VB\", \"dep\": \"ROOT\", \"dn\": [2, 3]}, {\"tok\": \"\\'s\", \"tag\": \"PRP\", \"dep\": \"nsubj\", \"up\": 2, \"dn\": []}, {\"tok\": \"go\", \"tag\": \"VB\", \"dep\": \"ccomp\", \"up\": 0, \"dn\": [1]}, {\"tok\": \".\", \"tag\": \".\", \"dep\": \"punct\", \"up\": 0, \"dn\": []}]}]}, \"reply-to\": \"L924\", \"timestamp\": null, \"vectors\": []}\\n'\n",
            "b'{\"id\": \"L924\", \"conversation_id\": \"L924\", \"text\": \"Wow\", \"speaker\": \"u2\", \"meta\": {\"movie_id\": \"m0\", \"parsed\": [{\"rt\": 0, \"toks\": [{\"tok\": \"Wow\", \"tag\": \"UH\", \"dep\": \"ROOT\", \"dn\": []}]}]}, \"reply-to\": null, \"timestamp\": null, \"vectors\": []}\\n'\n",
            "b'{\"id\": \"L872\", \"conversation_id\": \"L870\", \"text\": \"Okay -- you\\'re gonna need to learn how to lie.\", \"speaker\": \"u0\", \"meta\": {\"movie_id\": \"m0\", \"parsed\": [{\"rt\": 4, \"toks\": [{\"tok\": \"Okay\", \"tag\": \"UH\", \"dep\": \"intj\", \"up\": 4, \"dn\": []}, {\"tok\": \"--\", \"tag\": \":\", \"dep\": \"punct\", \"up\": 4, \"dn\": []}, {\"tok\": \"you\", \"tag\": \"PRP\", \"dep\": \"nsubj\", \"up\": 4, \"dn\": []}, {\"tok\": \"\\'re\", \"tag\": \"VBP\", \"dep\": \"aux\", \"up\": 4, \"dn\": []}, {\"tok\": \"gon\", \"tag\": \"VBG\", \"dep\": \"ROOT\", \"dn\": [0, 1, 2, 3, 6, 12]}, {\"tok\": \"na\", \"tag\": \"TO\", \"dep\": \"aux\", \"up\": 6, \"dn\": []}, {\"tok\": \"need\", \"tag\": \"VB\", \"dep\": \"xcomp\", \"up\": 4, \"dn\": [5, 8]}, {\"tok\": \"to\", \"tag\": \"TO\", \"dep\": \"aux\", \"up\": 8, \"dn\": []}, {\"tok\": \"learn\", \"tag\": \"VB\", \"dep\": \"xcomp\", \"up\": 6, \"dn\": [7, 11]}, {\"tok\": \"how\", \"tag\": \"WRB\", \"dep\": \"advmod\", \"up\": 11, \"dn\": []}, {\"tok\": \"to\", \"tag\": \"TO\", \"dep\": \"aux\", \"up\": 11, \"dn\": []}, {\"tok\": \"lie\", \"tag\": \"VB\", \"dep\": \"xcomp\", \"up\": 8, \"dn\": [9, 10]}, {\"tok\": \".\", \"tag\": \".\", \"dep\": \"punct\", \"up\": 4, \"dn\": []}]}]}, \"reply-to\": \"L871\", \"timestamp\": null, \"vectors\": []}\\n'\n",
            "b'{\"id\": \"L871\", \"conversation_id\": \"L870\", \"text\": \"No\", \"speaker\": \"u2\", \"meta\": {\"movie_id\": \"m0\", \"parsed\": [{\"rt\": 0, \"toks\": [{\"tok\": \"No\", \"tag\": \"UH\", \"dep\": \"ROOT\", \"dn\": []}]}]}, \"reply-to\": \"L870\", \"timestamp\": null, \"vectors\": []}\\n'\n",
            "b'{\"id\": \"L870\", \"conversation_id\": \"L870\", \"text\": \"I\\'m kidding.  You know how sometimes you just become this \\\\\"persona\\\\\"?  And you don\\'t know how to quit?\", \"speaker\": \"u0\", \"meta\": {\"movie_id\": \"m0\", \"parsed\": [{\"rt\": 2, \"toks\": [{\"tok\": \"I\", \"tag\": \"PRP\", \"dep\": \"nsubj\", \"up\": 2, \"dn\": []}, {\"tok\": \"\\'m\", \"tag\": \"VBP\", \"dep\": \"aux\", \"up\": 2, \"dn\": []}, {\"tok\": \"kidding\", \"tag\": \"VBG\", \"dep\": \"ROOT\", \"dn\": [0, 1, 3]}, {\"tok\": \".\", \"tag\": \".\", \"dep\": \"punct\", \"up\": 2, \"dn\": [4]}, {\"tok\": \" \", \"tag\": \"_SP\", \"dep\": \"\", \"up\": 3, \"dn\": []}]}, {\"rt\": 1, \"toks\": [{\"tok\": \"You\", \"tag\": \"PRP\", \"dep\": \"nsubj\", \"up\": 1, \"dn\": []}, {\"tok\": \"know\", \"tag\": \"VBP\", \"dep\": \"ROOT\", \"dn\": [0, 6, 11]}, {\"tok\": \"how\", \"tag\": \"WRB\", \"dep\": \"advmod\", \"up\": 3, \"dn\": []}, {\"tok\": \"sometimes\", \"tag\": \"RB\", \"dep\": \"advmod\", \"up\": 6, \"dn\": [2]}, {\"tok\": \"you\", \"tag\": \"PRP\", \"dep\": \"nsubj\", \"up\": 6, \"dn\": []}, {\"tok\": \"just\", \"tag\": \"RB\", \"dep\": \"advmod\", \"up\": 6, \"dn\": []}, {\"tok\": \"become\", \"tag\": \"VBP\", \"dep\": \"ccomp\", \"up\": 1, \"dn\": [3, 4, 5, 9]}, {\"tok\": \"this\", \"tag\": \"DT\", \"dep\": \"det\", \"up\": 9, \"dn\": []}, {\"tok\": \"\\\\\"\", \"tag\": \"``\", \"dep\": \"punct\", \"up\": 9, \"dn\": []}, {\"tok\": \"persona\", \"tag\": \"NN\", \"dep\": \"attr\", \"up\": 6, \"dn\": [7, 8, 10]}, {\"tok\": \"\\\\\"\", \"tag\": \"\\'\\'\", \"dep\": \"punct\", \"up\": 9, \"dn\": []}, {\"tok\": \"?\", \"tag\": \".\", \"dep\": \"punct\", \"up\": 1, \"dn\": [12]}, {\"tok\": \" \", \"tag\": \"_SP\", \"dep\": \"\", \"up\": 11, \"dn\": []}]}, {\"rt\": 4, \"toks\": [{\"tok\": \"And\", \"tag\": \"CC\", \"dep\": \"cc\", \"up\": 4, \"dn\": []}, {\"tok\": \"you\", \"tag\": \"PRP\", \"dep\": \"nsubj\", \"up\": 4, \"dn\": []}, {\"tok\": \"do\", \"tag\": \"VBP\", \"dep\": \"aux\", \"up\": 4, \"dn\": []}, {\"tok\": \"n\\'t\", \"tag\": \"RB\", \"dep\": \"neg\", \"up\": 4, \"dn\": []}, {\"tok\": \"know\", \"tag\": \"VB\", \"dep\": \"ROOT\", \"dn\": [0, 1, 2, 3, 7, 8]}, {\"tok\": \"how\", \"tag\": \"WRB\", \"dep\": \"advmod\", \"up\": 7, \"dn\": []}, {\"tok\": \"to\", \"tag\": \"TO\", \"dep\": \"aux\", \"up\": 7, \"dn\": []}, {\"tok\": \"quit\", \"tag\": \"VB\", \"dep\": \"xcomp\", \"up\": 4, \"dn\": [5, 6]}, {\"tok\": \"?\", \"tag\": \".\", \"dep\": \"punct\", \"up\": 4, \"dn\": []}]}]}, \"reply-to\": null, \"timestamp\": null, \"vectors\": []}\\n'\n",
            "b'{\"id\": \"L869\", \"conversation_id\": \"L866\", \"text\": \"Like my fear of wearing pastels?\", \"speaker\": \"u0\", \"meta\": {\"movie_id\": \"m0\", \"parsed\": [{\"rt\": 0, \"toks\": [{\"tok\": \"Like\", \"tag\": \"IN\", \"dep\": \"ROOT\", \"dn\": [2, 6]}, {\"tok\": \"my\", \"tag\": \"PRP$\", \"dep\": \"poss\", \"up\": 2, \"dn\": []}, {\"tok\": \"fear\", \"tag\": \"NN\", \"dep\": \"pobj\", \"up\": 0, \"dn\": [1, 3]}, {\"tok\": \"of\", \"tag\": \"IN\", \"dep\": \"prep\", \"up\": 2, \"dn\": [4]}, {\"tok\": \"wearing\", \"tag\": \"VBG\", \"dep\": \"pcomp\", \"up\": 3, \"dn\": [5]}, {\"tok\": \"pastels\", \"tag\": \"NNS\", \"dep\": \"dobj\", \"up\": 4, \"dn\": []}, {\"tok\": \"?\", \"tag\": \".\", \"dep\": \"punct\", \"up\": 0, \"dn\": []}]}]}, \"reply-to\": \"L868\", \"timestamp\": null, \"vectors\": []}\\n'\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Creating a formatted data file"
      ],
      "metadata": {
        "id": "pf4ga0UEMuQi"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Splits each line of the file to create lines and conversations\n",
        "def loadLinesAndConversations(fileName):\n",
        "    lines = {}\n",
        "    conversations = {}\n",
        "    with open(fileName, 'r', encoding='iso-8859-1') as f:\n",
        "        for line in f:\n",
        "            lineJson = json.loads(line)\n",
        "            # Extract fields for line object\n",
        "            lineObj = {}\n",
        "            lineObj[\"lineID\"] = lineJson[\"id\"]\n",
        "            lineObj[\"characterID\"] = lineJson[\"speaker\"]\n",
        "            lineObj[\"text\"] = lineJson[\"text\"]\n",
        "            lines[lineObj['lineID']] = lineObj\n",
        "\n",
        "            # Extract fields for conversation object\n",
        "            if lineJson[\"conversation_id\"] not in conversations:\n",
        "                convObj = {}\n",
        "                convObj[\"conversationID\"] = lineJson[\"conversation_id\"]\n",
        "                convObj[\"movieID\"] = lineJson[\"meta\"][\"movie_id\"]\n",
        "                convObj[\"lines\"] = [lineObj]\n",
        "            else:\n",
        "                convObj = conversations[lineJson[\"conversation_id\"]]\n",
        "                convObj[\"lines\"].insert(0, lineObj)\n",
        "            conversations[convObj[\"conversationID\"]] = convObj\n",
        "\n",
        "    return lines, conversations\n",
        "\n",
        "\n",
        "# Extracts pairs of sentences from conversations\n",
        "def extractSentencePairs(conversations):\n",
        "    qa_pairs = []\n",
        "    for conversation in conversations.values():\n",
        "        # Iterate over all the lines of the conversation\n",
        "        for i in range(len(conversation[\"lines\"]) - 1):  # We ignore the last line (no answer for it)\n",
        "            inputLine = conversation[\"lines\"][i][\"text\"].strip()\n",
        "            targetLine = conversation[\"lines\"][i+1][\"text\"].strip()\n",
        "            # Filter wrong samples (if one of the lists is empty)\n",
        "            if inputLine and targetLine:\n",
        "                qa_pairs.append([inputLine, targetLine])\n",
        "    return qa_pairs"
      ],
      "metadata": {
        "id": "X-lIg7KBLoQP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Define path to new file\n",
        "datafile = os.path.join(corpus, \"formatted_movie_lines.txt\")\n",
        "\n",
        "delimiter = '\\t'\n",
        "# Unescape the delimiter\n",
        "delimiter = str(codecs.decode(delimiter, \"unicode_escape\"))\n",
        "\n",
        "# Initialize lines dict and conversations dict\n",
        "lines = {}\n",
        "conversations = {}\n",
        "# Load lines and conversations\n",
        "print(\"\\nProcessing corpus into lines and conversations...\")\n",
        "lines, conversations = loadLinesAndConversations(os.path.join(corpus, \"utterances.jsonl\"))\n",
        "\n",
        "# Write new csv file\n",
        "print(\"\\nWriting newly formatted file...\")\n",
        "with open(datafile, 'w', encoding='utf-8') as outputfile:\n",
        "    writer = csv.writer(outputfile, delimiter=delimiter, lineterminator='\\n')\n",
        "    for pair in extractSentencePairs(conversations):\n",
        "        writer.writerow(pair)\n",
        "\n",
        "# Print a sample of lines\n",
        "print(\"\\nSample lines from file:\")\n",
        "printLines(datafile)"
      ],
      "metadata": {
        "id": "GpoWVq-pMQIm",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "94a42a0c-3264-470d-e59d-0da39307e31c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Processing corpus into lines and conversations...\n",
            "\n",
            "Writing newly formatted file...\n",
            "\n",
            "Sample lines from file:\n",
            "b'They do to!\\tThey do not!\\n'\n",
            "b'She okay?\\tI hope so.\\n'\n",
            "b\"Wow\\tLet's go.\\n\"\n",
            "b'\"I\\'m kidding.  You know how sometimes you just become this \"\"persona\"\"?  And you don\\'t know how to quit?\"\\tNo\\n'\n",
            "b\"No\\tOkay -- you're gonna need to learn how to lie.\\n\"\n",
            "b\"I figured you'd get to the good stuff eventually.\\tWhat good stuff?\\n\"\n",
            "b'What good stuff?\\t\"The \"\"real you\"\".\"\\n'\n",
            "b'\"The \"\"real you\"\".\"\\tLike my fear of wearing pastels?\\n'\n",
            "b'do you listen to this crap?\\tWhat crap?\\n'\n",
            "b\"What crap?\\tMe.  This endless ...blonde babble. I'm like, boring myself.\\n\"\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Loading and trimming the data"
      ],
      "metadata": {
        "id": "kHltoo5AMizj"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Default word tokens\n",
        "PAD_token = 0  # Used for padding short sentences\n",
        "SOS_token = 1  # Start-of-sentence token\n",
        "EOS_token = 2  # End-of-sentence token\n",
        "\n",
        "class Voc:\n",
        "    def __init__(self, name):\n",
        "        self.name = name\n",
        "        self.trimmed = False\n",
        "        self.word2index = {}\n",
        "        self.word2count = {}\n",
        "        self.index2word = {PAD_token: \"PAD\", SOS_token: \"SOS\", EOS_token: \"EOS\"}\n",
        "        self.num_words = 3  # Count SOS, EOS, PAD\n",
        "\n",
        "    def addSentence(self, sentence):\n",
        "        for word in sentence.split(' '):\n",
        "            self.addWord(word)\n",
        "\n",
        "    def addWord(self, word):\n",
        "        if word not in self.word2index:\n",
        "            self.word2index[word] = self.num_words\n",
        "            self.word2count[word] = 1\n",
        "            self.index2word[self.num_words] = word\n",
        "            self.num_words += 1\n",
        "        else:\n",
        "            self.word2count[word] += 1\n",
        "\n",
        "    # Remove words below a certain count threshold\n",
        "    def trim(self, min_count):\n",
        "        if self.trimmed:\n",
        "            return\n",
        "        self.trimmed = True\n",
        "\n",
        "        keep_words = []\n",
        "\n",
        "        for k, v in self.word2count.items():\n",
        "            if v >= min_count:\n",
        "                keep_words.append(k)\n",
        "\n",
        "        print('keep_words {} / {} = {:.4f}'.format(\n",
        "            len(keep_words), len(self.word2index), len(keep_words) / len(self.word2index)\n",
        "        ))\n",
        "\n",
        "        # Reinitialize dictionaries\n",
        "        self.word2index = {}\n",
        "        self.word2count = {}\n",
        "        self.index2word = {PAD_token: \"PAD\", SOS_token: \"SOS\", EOS_token: \"EOS\"}\n",
        "        self.num_words = 3 # Count default tokens\n",
        "\n",
        "        for word in keep_words:\n",
        "            self.addWord(word)"
      ],
      "metadata": {
        "id": "9wSxqg2CMjgf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "MAX_LENGTH = 10  # Maximum sentence length to consider\n",
        "\n",
        "# Turn a Unicode string to plain ASCII, thanks to\n",
        "# https://stackoverflow.com/a/518232/2809427\n",
        "def unicodeToAscii(s):\n",
        "    return ''.join(\n",
        "        c for c in unicodedata.normalize('NFD', s)\n",
        "        if unicodedata.category(c) != 'Mn'\n",
        "    )\n",
        "\n",
        "# Lowercase, trim, and remove non-letter characters\n",
        "def normalizeString(s):\n",
        "    s = unicodeToAscii(s.lower().strip())\n",
        "    s = re.sub(r\"([.!?])\", r\" \\1\", s)\n",
        "    s = re.sub(r\"[^a-zA-Z.!?]+\", r\" \", s)\n",
        "    s = re.sub(r\"\\s+\", r\" \", s).strip()\n",
        "    return s\n",
        "\n",
        "# Read query/response pairs and return a voc object\n",
        "def readVocs(datafile, corpus_name):\n",
        "    print(\"Reading lines...\")\n",
        "    # Read the file and split into lines\n",
        "    lines = open(datafile, encoding='utf-8').\\\n",
        "        read().strip().split('\\n')\n",
        "    # Split every line into pairs and normalize\n",
        "    pairs = [[normalizeString(s) for s in l.split('\\t')] for l in lines]\n",
        "    voc = Voc(corpus_name)\n",
        "    return voc, pairs\n",
        "\n",
        "# Returns True if both sentences in a pair 'p' are under the MAX_LENGTH threshold\n",
        "def filterPair(p):\n",
        "    # Input sequences need to preserve the last word for EOS token\n",
        "    return len(p[0].split(' ')) < MAX_LENGTH and len(p[1].split(' ')) < MAX_LENGTH\n",
        "\n",
        "# Filter pairs using the ``filterPair`` condition\n",
        "def filterPairs(pairs):\n",
        "    return [pair for pair in pairs if filterPair(pair)]\n",
        "\n",
        "# Using the functions defined above, return a populated voc object and pairs list\n",
        "def loadPrepareData(corpus, corpus_name, datafile, save_dir):\n",
        "    print(\"Start preparing training data ...\")\n",
        "    voc, pairs = readVocs(datafile, corpus_name)\n",
        "    print(\"Read {!s} sentence pairs\".format(len(pairs)))\n",
        "    pairs = filterPairs(pairs)\n",
        "    print(\"Trimmed to {!s} sentence pairs\".format(len(pairs)))\n",
        "    print(\"Counting words...\")\n",
        "    for pair in pairs:\n",
        "        voc.addSentence(pair[0])\n",
        "        voc.addSentence(pair[1])\n",
        "    print(\"Counted words:\", voc.num_words)\n",
        "    return voc, pairs\n",
        "\n",
        "\n",
        "# Load/Assemble voc and pairs\n",
        "save_dir = os.path.join(\"data\", \"save\")\n",
        "voc, pairs = loadPrepareData(corpus, corpus_name, datafile, save_dir)\n",
        "# Print some pairs to validate\n",
        "print(\"\\npairs:\")\n",
        "for pair in pairs[:10]:\n",
        "    print(pair)"
      ],
      "metadata": {
        "id": "eOV4ui6qNbFh",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "fa2baac9-4a1f-46f2-845c-8d07f9d01b0a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Start preparing training data ...\n",
            "Reading lines...\n",
            "Read 221282 sentence pairs\n",
            "Trimmed to 64313 sentence pairs\n",
            "Counting words...\n",
            "Counted words: 18082\n",
            "\n",
            "pairs:\n",
            "['they do to !', 'they do not !']\n",
            "['she okay ?', 'i hope so .']\n",
            "['wow', 'let s go .']\n",
            "['what good stuff ?', 'the real you .']\n",
            "['the real you .', 'like my fear of wearing pastels ?']\n",
            "['do you listen to this crap ?', 'what crap ?']\n",
            "['well no . . .', 'then that s all you had to say .']\n",
            "['then that s all you had to say .', 'but']\n",
            "['but', 'you always been this selfish ?']\n",
            "['have fun tonight ?', 'tons']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "MIN_COUNT = 3    # Minimum word count threshold for trimming\n",
        "\n",
        "def trimRareWords(voc, pairs, MIN_COUNT):\n",
        "    # Trim words used under the MIN_COUNT from the voc\n",
        "    voc.trim(MIN_COUNT)\n",
        "    # Filter out pairs with trimmed words\n",
        "    keep_pairs = []\n",
        "    for pair in pairs:\n",
        "        input_sentence = pair[0]\n",
        "        output_sentence = pair[1]\n",
        "        keep_input = True\n",
        "        keep_output = True\n",
        "        # Check input sentence\n",
        "        for word in input_sentence.split(' '):\n",
        "            if word not in voc.word2index:\n",
        "                keep_input = False\n",
        "                break\n",
        "        # Check output sentence\n",
        "        for word in output_sentence.split(' '):\n",
        "            if word not in voc.word2index:\n",
        "                keep_output = False\n",
        "                break\n",
        "\n",
        "        # Only keep pairs that do not contain trimmed word(s) in their input or output sentence\n",
        "        if keep_input and keep_output:\n",
        "            keep_pairs.append(pair)\n",
        "\n",
        "    print(\"Trimmed from {} pairs to {}, {:.4f} of total\".format(len(pairs), len(keep_pairs), len(keep_pairs) / len(pairs)))\n",
        "    return keep_pairs\n",
        "\n",
        "\n",
        "# Trim voc and pairs\n",
        "pairs = trimRareWords(voc, pairs, MIN_COUNT)"
      ],
      "metadata": {
        "id": "_iC8llpzNf_8",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e40bd2a6-da7c-42a6-d0a1-aa0dd73250d2"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "keep_words 7833 / 18079 = 0.4333\n",
            "Trimmed from 64313 pairs to 53131, 0.8261 of total\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Prepare Data for Models"
      ],
      "metadata": {
        "id": "7NbAFIkVNuha"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def indexesFromSentence(voc, sentence):\n",
        "    return [voc.word2index[word] for word in sentence.split(' ')] + [EOS_token]\n",
        "\n",
        "\n",
        "def zeroPadding(l, fillvalue=PAD_token):\n",
        "    return list(itertools.zip_longest(*l, fillvalue=fillvalue))\n",
        "\n",
        "def binaryMatrix(l, value=PAD_token):\n",
        "    m = []\n",
        "    for i, seq in enumerate(l):\n",
        "        m.append([])\n",
        "        for token in seq:\n",
        "            if token == PAD_token:\n",
        "                m[i].append(0)\n",
        "            else:\n",
        "                m[i].append(1)\n",
        "    return m\n",
        "\n",
        "# Returns padded input sequence tensor and lengths\n",
        "def inputVar(l, voc):\n",
        "    indexes_batch = [indexesFromSentence(voc, sentence) for sentence in l]\n",
        "    lengths = torch.tensor([len(indexes) for indexes in indexes_batch])\n",
        "    padList = zeroPadding(indexes_batch)\n",
        "    padVar = torch.LongTensor(padList)\n",
        "    return padVar, lengths\n",
        "\n",
        "# Returns padded target sequence tensor, padding mask, and max target length\n",
        "def outputVar(l, voc):\n",
        "    indexes_batch = [indexesFromSentence(voc, sentence) for sentence in l]\n",
        "    max_target_len = max([len(indexes) for indexes in indexes_batch])\n",
        "    padList = zeroPadding(indexes_batch)\n",
        "    mask = binaryMatrix(padList)\n",
        "    mask = torch.BoolTensor(mask)\n",
        "    padVar = torch.LongTensor(padList)\n",
        "    return padVar, mask, max_target_len\n",
        "\n",
        "# Returns all items for a given batch of pairs\n",
        "def batch2TrainData(voc, pair_batch):\n",
        "    pair_batch.sort(key=lambda x: len(x[0].split(\" \")), reverse=True)\n",
        "    input_batch, output_batch = [], []\n",
        "    for pair in pair_batch:\n",
        "        input_batch.append(pair[0])\n",
        "        output_batch.append(pair[1])\n",
        "    inp, lengths = inputVar(input_batch, voc)\n",
        "    output, mask, max_target_len = outputVar(output_batch, voc)\n",
        "    return inp, lengths, output, mask, max_target_len\n",
        "\n",
        "\n",
        "# Example for validation\n",
        "small_batch_size = 5\n",
        "batches = batch2TrainData(voc, [random.choice(pairs) for _ in range(small_batch_size)])\n",
        "input_variable, lengths, target_variable, mask, max_target_len = batches\n",
        "\n",
        "print(\"input_variable:\", input_variable)\n",
        "print(\"lengths:\", lengths)\n",
        "print(\"target_variable:\", target_variable)\n",
        "print(\"mask:\", mask)\n",
        "print(\"max_target_len:\", max_target_len)"
      ],
      "metadata": {
        "id": "AGU5D3m2Nxzv",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "caaf9fcc-e1f2-459c-e8a9-a6e50bf3f1b8"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "input_variable: tensor([[  24,   24, 1012,   36,  658],\n",
            "        [   4,  246,   67,   17,   14],\n",
            "        [  79,  135,   90,  380,    2],\n",
            "        [ 606, 1805, 3210,   14,    0],\n",
            "        [ 284,  160, 1012,    2,    0],\n",
            "        [ 900,   99,   10,    0,    0],\n",
            "        [ 307, 1845,    2,    0,    0],\n",
            "        [ 738,   14,    0,    0,    0],\n",
            "        [  14,    2,    0,    0,    0],\n",
            "        [   2,    0,    0,    0,    0]])\n",
            "lengths: tensor([10,  9,  7,  5,  3])\n",
            "target_variable: tensor([[1684,  104, 1250,   11,   20],\n",
            "        [  14,  246,  449,  208,  658],\n",
            "        [   2,  135,  113,  135,  681],\n",
            "        [   0,  136, 1257,  136,   14],\n",
            "        [   0,   72,  160,    5, 7011],\n",
            "        [   0,    5,   14,  186,   14],\n",
            "        [   0,   14,    2,   92,    2],\n",
            "        [   0,    2,    0,   66,    0],\n",
            "        [   0,    0,    0,   14,    0],\n",
            "        [   0,    0,    0,    2,    0]])\n",
            "mask: tensor([[ True,  True,  True,  True,  True],\n",
            "        [ True,  True,  True,  True,  True],\n",
            "        [ True,  True,  True,  True,  True],\n",
            "        [False,  True,  True,  True,  True],\n",
            "        [False,  True,  True,  True,  True],\n",
            "        [False,  True,  True,  True,  True],\n",
            "        [False,  True,  True,  True,  True],\n",
            "        [False,  True, False,  True, False],\n",
            "        [False, False, False,  True, False],\n",
            "        [False, False, False,  True, False]])\n",
            "max_target_len: 10\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Models"
      ],
      "metadata": {
        "id": "0bNcT3hpOoN4"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Seq2Seq Model"
      ],
      "metadata": {
        "id": "5nkqd6ffOrFI"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### Encoder"
      ],
      "metadata": {
        "id": "7BZN4kj2Q4Ty"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class EncoderRNN(nn.Module):\n",
        "    def __init__(self, hidden_size, embedding, n_layers=1, dropout=0):\n",
        "        super(EncoderRNN, self).__init__()\n",
        "        self.n_layers = n_layers\n",
        "        self.hidden_size = hidden_size\n",
        "        self.embedding = embedding\n",
        "\n",
        "        # Initialize GRU; the input_size and hidden_size parameters are both set to 'hidden_size'\n",
        "        #   because our input size is a word embedding with number of features == hidden_size\n",
        "        self.gru = nn.GRU(hidden_size, hidden_size, n_layers,\n",
        "                          dropout=dropout, bidirectional=True)\n",
        "\n",
        "    def forward(self, input_seq: torch.Tensor, input_lengths: torch.Tensor):\n",
        "        hidden = torch.zeros(self.n_layers * 2, input_seq.shape[1], self.hidden_size).to(input_seq.device)\n",
        "        # Convert word indexes to embeddings\n",
        "        embedded = self.embedding(input_seq)\n",
        "        # Pack padded batch of sequences for RNN module\n",
        "        packed = nn.utils.rnn.pack_padded_sequence(embedded, input_lengths)\n",
        "        # Forward pass through GRU\n",
        "        outputs, hidden = self.gru(packed, hidden)\n",
        "        # Unpack padding\n",
        "        outputs, _ = nn.utils.rnn.pad_packed_sequence(outputs)\n",
        "        # Sum bidirectional GRU outputs\n",
        "        outputs = outputs[:, :, :self.hidden_size] + outputs[:, : ,self.hidden_size:]\n",
        "        # Return output and final hidden state\n",
        "        return outputs, hidden"
      ],
      "metadata": {
        "id": "AuDEIV-xOjJU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### Luong Attention Layer"
      ],
      "metadata": {
        "id": "H1PwNbvMPmMl"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Luong attention layer\n",
        "class Attn(nn.Module):\n",
        "    def __init__(self, method, hidden_size):\n",
        "        super(Attn, self).__init__()\n",
        "        self.method = method\n",
        "        if self.method not in ['dot', 'general', 'concat']:\n",
        "            raise ValueError(self.method, \"is not an appropriate attention method.\")\n",
        "        self.hidden_size = hidden_size\n",
        "        self.attn = nn.Linear(self.hidden_size, hidden_size)\n",
        "        self.v = nn.Parameter(torch.FloatTensor(hidden_size))\n",
        "\n",
        "    def dot_score(self, hidden, encoder_output):\n",
        "        return torch.sum(hidden * encoder_output, dim=2)\n",
        "\n",
        "    def general_score(self, hidden, encoder_output):\n",
        "        energy = self.attn(encoder_output)\n",
        "        return torch.sum(hidden * energy, dim=2)\n",
        "\n",
        "    def concat_score(self, hidden, encoder_output):\n",
        "        energy = self.attn(torch.cat((hidden.expand(encoder_output.size(0), -1, -1), encoder_output), 2)).tanh()\n",
        "        return torch.sum(self.v * energy, dim=2)\n",
        "\n",
        "    def forward(self, hidden, encoder_outputs):\n",
        "        # Calculate the attention weights (energies) based on the given method\n",
        "        attn_energies = torch.randn(1,1,1)\n",
        "\n",
        "        if self.method == 'general':\n",
        "            attn_energies = self.general_score(hidden, encoder_outputs)\n",
        "        elif self.method == 'concat':\n",
        "            attn_energies = self.concat_score(hidden, encoder_outputs)\n",
        "        elif self.method == 'dot':\n",
        "            attn_energies = self.dot_score(hidden, encoder_outputs)\n",
        "\n",
        "        # Transpose max_length and batch_size dimensions\n",
        "        attn_energies = attn_energies.t()\n",
        "\n",
        "        # Return the softmax normalized probability scores (with added dimension)\n",
        "        return F.softmax(attn_energies, dim=1).unsqueeze(1)"
      ],
      "metadata": {
        "id": "-wD3eXwIPJeP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### Decoder"
      ],
      "metadata": {
        "id": "J6HY4tmiPuw4"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class LuongAttnDecoderRNN(nn.Module):\n",
        "    def __init__(self, attn_model, embedding, hidden_size, output_size, n_layers=1, dropout=0.1):\n",
        "        super(LuongAttnDecoderRNN, self).__init__()\n",
        "\n",
        "        # Keep for reference\n",
        "        self.attn_model = attn_model\n",
        "        self.hidden_size = hidden_size\n",
        "        self.output_size = output_size\n",
        "        self.n_layers = n_layers\n",
        "        self.dropout = dropout\n",
        "\n",
        "        # Define layers\n",
        "        self.embedding = embedding\n",
        "        self.embedding_dropout = nn.Dropout(dropout)\n",
        "        self.gru = nn.GRU(hidden_size, hidden_size, n_layers, dropout=(0 if n_layers == 1 else dropout))\n",
        "        self.concat = nn.Linear(hidden_size * 2, hidden_size)\n",
        "        self.out = nn.Linear(hidden_size, output_size)\n",
        "\n",
        "        self.attn = Attn(attn_model, hidden_size)\n",
        "\n",
        "    def forward(self, input_step: torch.Tensor, last_hidden: torch.Tensor, encoder_outputs: torch.Tensor):\n",
        "        # Note: we run this one step (word) at a time\n",
        "        # Get embedding of current input word\n",
        "        embedded = self.embedding(input_step)\n",
        "        embedded = self.embedding_dropout(embedded)\n",
        "        # Forward through unidirectional GRU\n",
        "        rnn_output, hidden = self.gru(embedded, last_hidden)\n",
        "        # Calculate attention weights from the current GRU output\n",
        "        attn_weights = self.attn(rnn_output, encoder_outputs)\n",
        "        # Multiply attention weights to encoder outputs to get new \"weighted sum\" context vector\n",
        "        context = attn_weights.bmm(encoder_outputs.transpose(0, 1))\n",
        "        # Concatenate weighted context vector and GRU output using Luong eq. 5\n",
        "        rnn_output = rnn_output.squeeze(0)\n",
        "        context = context.squeeze(1)\n",
        "        concat_input = torch.cat((rnn_output, context), 1)\n",
        "        concat_output = torch.tanh(self.concat(concat_input))\n",
        "        # Predict next word using Luong eq. 6\n",
        "        output = self.out(concat_output)\n",
        "        output = F.softmax(output, dim=1)\n",
        "        # Return output and final hidden state\n",
        "        return output, hidden"
      ],
      "metadata": {
        "id": "rVCp3jK0PZ_4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Training Procedure"
      ],
      "metadata": {
        "id": "djzoG7RWQQGI"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Masked Loss"
      ],
      "metadata": {
        "id": "hmVa5f9iRE0l"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def maskNLLLoss(inp, target, mask):\n",
        "    nTotal = mask.sum()\n",
        "    crossEntropy = -torch.log(torch.gather(inp, 1, target.view(-1, 1)).squeeze(1))\n",
        "    loss = crossEntropy.masked_select(mask).mean()\n",
        "    loss = loss.to(device)\n",
        "    return loss, nTotal.item()"
      ],
      "metadata": {
        "id": "WP98OPdmQILF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Single Training Iteration"
      ],
      "metadata": {
        "id": "TfGv__WtQebk"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def train(input_variable, lengths, target_variable, mask, max_target_len, encoder, decoder, embedding,\n",
        "          encoder_optimizer, decoder_optimizer, batch_size, clip, teacher_forcing_ratio, max_length=MAX_LENGTH, record=False):\n",
        "\n",
        "    # Zero gradients\n",
        "    encoder_optimizer.zero_grad()\n",
        "    decoder_optimizer.zero_grad()\n",
        "\n",
        "    # Set device options\n",
        "    input_variable = input_variable.to(device)\n",
        "    target_variable = target_variable.to(device)\n",
        "    mask = mask.to(device)\n",
        "    # Lengths for RNN packing should always be on the CPU\n",
        "    lengths = lengths.to('cpu')\n",
        "\n",
        "    # Initialize variables\n",
        "    loss = 0\n",
        "    print_losses = []\n",
        "    n_totals = 0\n",
        "\n",
        "    # Forward pass through encoder\n",
        "    encoder_outputs, encoder_hidden = encoder(input_variable, lengths)\n",
        "\n",
        "    # Create initial decoder input (start with SOS tokens for each sentence)\n",
        "    decoder_input = torch.LongTensor([[SOS_token for _ in range(batch_size)]])\n",
        "    decoder_input = decoder_input.to(device)\n",
        "\n",
        "    # Set initial decoder hidden state to the encoder's final hidden state\n",
        "    decoder_hidden = encoder_hidden[:decoder.n_layers]\n",
        "\n",
        "    # Determine if we are using teacher forcing this iteration\n",
        "    use_teacher_forcing = True if random.random() < teacher_forcing_ratio else False\n",
        "\n",
        "    # Forward batch of sequences through decoder one time step at a time\n",
        "    if use_teacher_forcing:\n",
        "        for t in range(max_target_len):\n",
        "            decoder_output, decoder_hidden = decoder(\n",
        "                decoder_input, decoder_hidden, encoder_outputs\n",
        "            )\n",
        "            # Teacher forcing: next input is current target\n",
        "            decoder_input = target_variable[t].view(1, -1)\n",
        "            # Calculate and accumulate loss\n",
        "            mask_loss, nTotal = maskNLLLoss(decoder_output, target_variable[t], mask[t])\n",
        "            loss += mask_loss\n",
        "            print_losses.append(mask_loss.item() * nTotal)\n",
        "            n_totals += nTotal\n",
        "    else:\n",
        "        for t in range(max_target_len):\n",
        "            decoder_output, decoder_hidden = decoder(\n",
        "                decoder_input, decoder_hidden, encoder_outputs\n",
        "            )\n",
        "            # No teacher forcing: next input is decoder's own current output\n",
        "            _, topi = decoder_output.topk(1)\n",
        "            decoder_input = torch.LongTensor([[topi[i][0] for i in range(batch_size)]])\n",
        "            decoder_input = decoder_input.to(device)\n",
        "            # Calculate and accumulate loss\n",
        "            mask_loss, nTotal = maskNLLLoss(decoder_output, target_variable[t], mask[t])\n",
        "            loss += mask_loss\n",
        "            print_losses.append(mask_loss.item() * nTotal)\n",
        "            n_totals += nTotal\n",
        "\n",
        "    # Recording loss on wandb\n",
        "    if record:\n",
        "        wandb.log({\"loss\": sum(print_losses) / n_totals})\n",
        "\n",
        "    # Perform backpropagation\n",
        "    loss.backward()\n",
        "\n",
        "    # Clip gradients: gradients are modified in place\n",
        "    _ = nn.utils.clip_grad_norm_(encoder.parameters(), clip)\n",
        "    _ = nn.utils.clip_grad_norm_(decoder.parameters(), clip)\n",
        "\n",
        "    # Adjust model weights\n",
        "    encoder_optimizer.step()\n",
        "    decoder_optimizer.step()\n",
        "\n",
        "    return sum(print_losses) / n_totals"
      ],
      "metadata": {
        "id": "uO7-75dPQg6d"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Training iterations"
      ],
      "metadata": {
        "id": "ue7xE551RLTd"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def trainIters(model_name, voc, pairs, encoder, decoder, encoder_optimizer, decoder_optimizer, embedding, encoder_n_layers, decoder_n_layers, save_dir, n_iteration, batch_size, print_every, save_every, clip, teacher_forcing_ratio, hidden_size, corpus_name, record=False):\n",
        "\n",
        "    # Load batches for each iteration\n",
        "    training_batches = [batch2TrainData(voc, [random.choice(pairs) for _ in range(batch_size)])\n",
        "                      for _ in range(n_iteration)]\n",
        "\n",
        "    # Initializations\n",
        "    print('Initializing ...')\n",
        "    start_iteration = 1\n",
        "    print_loss = 0\n",
        "\n",
        "    # Training loop\n",
        "    print(\"Training...\")\n",
        "    for iteration in range(start_iteration, n_iteration + 1):\n",
        "        training_batch = training_batches[iteration - 1]\n",
        "        # Extract fields from batch\n",
        "        input_variable, lengths, target_variable, mask, max_target_len = training_batch\n",
        "\n",
        "        # Run a training iteration with batch\n",
        "        loss = train(input_variable, lengths, target_variable, mask, max_target_len, encoder,\n",
        "                     decoder, embedding, encoder_optimizer, decoder_optimizer, batch_size, clip, teacher_forcing_ratio, record=record)\n",
        "        print_loss += loss\n",
        "\n",
        "        # Print progress\n",
        "        if iteration % print_every == 0:\n",
        "            print_loss_avg = print_loss / print_every\n",
        "            print(\"Iteration: {}; Percent complete: {:.1f}%; Average loss: {:.4f}\".format(iteration, iteration / n_iteration * 100, print_loss_avg))\n",
        "            print_loss = 0\n",
        "\n",
        "        # Save checkpoint\n",
        "        if (iteration % save_every == 0):\n",
        "            directory = os.path.join(save_dir, model_name, corpus_name, '{}-{}_{}'.format(encoder_n_layers, decoder_n_layers, hidden_size))\n",
        "            if not os.path.exists(directory):\n",
        "                os.makedirs(directory)\n",
        "            torch.save({\n",
        "                'iteration': iteration,\n",
        "                'en': encoder.state_dict(),\n",
        "                'de': decoder.state_dict(),\n",
        "                'en_opt': encoder_optimizer.state_dict(),\n",
        "                'de_opt': decoder_optimizer.state_dict(),\n",
        "                'loss': loss,\n",
        "                'voc_dict': voc.__dict__,\n",
        "                'embedding': embedding.state_dict()\n",
        "            }, os.path.join(directory, '{}_{}.tar'.format(iteration, 'checkpoint')))"
      ],
      "metadata": {
        "id": "o6dyyK9zQpC7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Evaluation Procedure"
      ],
      "metadata": {
        "id": "2zJ2MJkmRYay"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Greedy Search Decoder"
      ],
      "metadata": {
        "id": "5s7Dxb6wReIw"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class GreedySearchDecoder(nn.Module):\n",
        "    def __init__(self, encoder, decoder):\n",
        "        super(GreedySearchDecoder, self).__init__()\n",
        "        self.encoder = encoder\n",
        "        self.decoder = decoder\n",
        "\n",
        "    def forward(self, input_seq: torch.Tensor, input_length: torch.Tensor, max_length: int):\n",
        "        # Forward input through encoder model\n",
        "        encoder_outputs, encoder_hidden = self.encoder(input_seq, input_length)\n",
        "        # Prepare encoder's final hidden layer to be first hidden input to the decoder\n",
        "        decoder_hidden = encoder_hidden[:self.decoder.n_layers]\n",
        "        # Initialize decoder input with SOS_token\n",
        "        decoder_input = torch.ones(1, input_seq.shape[1], device=device, dtype=torch.long) * SOS_token\n",
        "        # Initialize tensors to append decoded words to\n",
        "        all_tokens = torch.zeros([0], device=device, dtype=torch.long)\n",
        "        all_scores = torch.zeros([0], device=device)\n",
        "        # Iteratively decode one word token at a time\n",
        "        for _ in range(max_length):\n",
        "            # Forward pass through decoder\n",
        "            decoder_output, decoder_hidden = self.decoder(decoder_input, decoder_hidden, encoder_outputs)\n",
        "            # Obtain most likely word token and its softmax score\n",
        "            decoder_scores, decoder_input = torch.max(decoder_output, dim=1)\n",
        "            # Record token and score\n",
        "            all_tokens = torch.cat((all_tokens, decoder_input), dim=0)\n",
        "            all_scores = torch.cat((all_scores, decoder_scores), dim=0)\n",
        "            # Prepare current token to be next decoder input (add a dimension)\n",
        "            decoder_input = torch.unsqueeze(decoder_input, 0)\n",
        "        # Return collections of word tokens and scores\n",
        "        return all_tokens, all_scores"
      ],
      "metadata": {
        "id": "Fckmv3_6RRNQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Evaluate text"
      ],
      "metadata": {
        "id": "3kKNzJkQRj0n"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def evaluate(searcher, voc, sentence, max_length=MAX_LENGTH):\n",
        "    ### Format input sentence as a batch\n",
        "    # words -> indexes\n",
        "    indexes_batch = [indexesFromSentence(voc, sentence)]\n",
        "    # Create lengths tensor\n",
        "    lengths = torch.tensor([len(indexes) for indexes in indexes_batch])\n",
        "    # Transpose dimensions of batch to match models' expectations\n",
        "    input_batch = torch.LongTensor(indexes_batch).transpose(0, 1)\n",
        "    # Use appropriate device\n",
        "    input_batch = input_batch.to(device)\n",
        "    lengths = lengths.to('cpu')\n",
        "    # Decode sentence with searcher\n",
        "    tokens, scores = searcher(input_batch, lengths, max_length)\n",
        "    # indexes -> words\n",
        "    decoded_words = [voc.index2word[token.item()] for token in tokens]\n",
        "    return decoded_words\n",
        "\n",
        "# Evaluate inputs from user input (``stdin``)\n",
        "def evaluateInput(searcher, voc):\n",
        "    input_sentence = ''\n",
        "    while(1):\n",
        "        try:\n",
        "            # Get input sentence\n",
        "            input_sentence = input('> ')\n",
        "            # Check if it is quit case\n",
        "            if input_sentence == 'q' or input_sentence == 'quit': break\n",
        "            # Normalize sentence\n",
        "            input_sentence = normalizeString(input_sentence)\n",
        "            # Evaluate sentence\n",
        "            output_words = evaluate(searcher, voc, input_sentence)\n",
        "            # Format and print response sentence\n",
        "            output_words[:] = [x for x in output_words if not (x == 'EOS' or x == 'PAD')]\n",
        "            print('Bot:', ' '.join(output_words))\n",
        "\n",
        "        except KeyError:\n",
        "            print(\"Error: Encountered unknown word.\")\n",
        "\n",
        "# Normalize input sentence and call ``evaluate()``\n",
        "def evaluateExample(sentence, searcher, voc):\n",
        "    print(\"> \" + sentence)\n",
        "    # Normalize sentence\n",
        "    input_sentence = normalizeString(sentence)\n",
        "    # Evaluate sentence\n",
        "    output_words = evaluate(searcher, voc, input_sentence)\n",
        "    output_words[:] = [x for x in output_words if not (x == 'EOS' or x == 'PAD')]\n",
        "    print('Bot:', ' '.join(output_words))"
      ],
      "metadata": {
        "id": "iyt-URSiRkVz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Run Model"
      ],
      "metadata": {
        "id": "rXMSGErHRuJ-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Configure models\n",
        "model_name = 'cb_model'\n",
        "attn_model = 'dot'\n",
        "hidden_size = 500\n",
        "encoder_n_layers = 2\n",
        "decoder_n_layers = 2\n",
        "dropout = 0.1\n",
        "batch_size = 64\n",
        "\n",
        "print('Building encoder and decoder ...')\n",
        "# Initialize word embeddings\n",
        "embedding = nn.Embedding(voc.num_words, hidden_size)\n",
        "# Initialize encoder & decoder models\n",
        "encoder = EncoderRNN(hidden_size, embedding, encoder_n_layers, dropout)\n",
        "decoder = LuongAttnDecoderRNN(attn_model, embedding, hidden_size, voc.num_words, decoder_n_layers, dropout)\n",
        "# Use appropriate device\n",
        "encoder = encoder.to(device)\n",
        "decoder = decoder.to(device)\n",
        "print('Models built and ready to go!')"
      ],
      "metadata": {
        "id": "tAMzSLMMRtsC",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "204d23af-c979-418e-ced7-a5b4d99e8089"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Building encoder and decoder ...\n",
            "Models built and ready to go!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Run Training"
      ],
      "metadata": {
        "id": "TWmCbZJUSIF0"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Configure training/optimization\n",
        "clip = 50.0\n",
        "teacher_forcing_ratio = 1.0\n",
        "learning_rate = 0.0001\n",
        "decoder_learning_ratio = 5.0\n",
        "n_iteration = 4000\n",
        "print_every = 100\n",
        "save_every = 500\n",
        "\n",
        "# Ensure dropout layers are in train mode\n",
        "encoder.train()\n",
        "decoder.train()\n",
        "\n",
        "# Initialize optimizers\n",
        "print('Building optimizers ...')\n",
        "encoder_optimizer = optim.Adam(encoder.parameters(), lr=learning_rate)\n",
        "decoder_optimizer = optim.Adam(decoder.parameters(), lr=learning_rate * decoder_learning_ratio)\n",
        "\n",
        "# If you have CUDA, configure CUDA to call\n",
        "for state in encoder_optimizer.state.values():\n",
        "    for k, v in state.items():\n",
        "        if isinstance(v, torch.Tensor):\n",
        "            state[k] = v.cuda()\n",
        "\n",
        "for state in decoder_optimizer.state.values():\n",
        "    for k, v in state.items():\n",
        "        if isinstance(v, torch.Tensor):\n",
        "            state[k] = v.cuda()\n",
        "\n",
        "# Run training iterations\n",
        "print(\"Starting Training!\")\n",
        "trainIters(model_name, voc, pairs, encoder, decoder, encoder_optimizer, decoder_optimizer,\n",
        "           embedding, encoder_n_layers, decoder_n_layers, save_dir, n_iteration, batch_size,\n",
        "           print_every, save_every, clip, teacher_forcing_ratio, hidden_size, corpus_name)"
      ],
      "metadata": {
        "collapsed": true,
        "id": "sk1LWVM9SZ6z",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e76badd8-e5e1-4377-ad2a-bf0c67f588aa"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Building optimizers ...\n",
            "Starting Training!\n",
            "Initializing ...\n",
            "Training...\n",
            "Iteration: 100; Percent complete: 2.5%; Average loss: 5.0211\n",
            "Iteration: 200; Percent complete: 5.0%; Average loss: 4.2475\n",
            "Iteration: 300; Percent complete: 7.5%; Average loss: 3.9929\n",
            "Iteration: 400; Percent complete: 10.0%; Average loss: 3.8505\n",
            "Iteration: 500; Percent complete: 12.5%; Average loss: 3.7781\n",
            "Iteration: 600; Percent complete: 15.0%; Average loss: 3.6838\n",
            "Iteration: 700; Percent complete: 17.5%; Average loss: 3.6264\n",
            "Iteration: 800; Percent complete: 20.0%; Average loss: 3.5803\n",
            "Iteration: 900; Percent complete: 22.5%; Average loss: 3.5066\n",
            "Iteration: 1000; Percent complete: 25.0%; Average loss: 3.4795\n",
            "Iteration: 1100; Percent complete: 27.5%; Average loss: 3.4608\n",
            "Iteration: 1200; Percent complete: 30.0%; Average loss: 3.3994\n",
            "Iteration: 1300; Percent complete: 32.5%; Average loss: 3.3778\n",
            "Iteration: 1400; Percent complete: 35.0%; Average loss: 3.3276\n",
            "Iteration: 1500; Percent complete: 37.5%; Average loss: 3.2917\n",
            "Iteration: 1600; Percent complete: 40.0%; Average loss: 3.2746\n",
            "Iteration: 1700; Percent complete: 42.5%; Average loss: 3.2572\n",
            "Iteration: 1800; Percent complete: 45.0%; Average loss: 3.2399\n",
            "Iteration: 1900; Percent complete: 47.5%; Average loss: 3.1812\n",
            "Iteration: 2000; Percent complete: 50.0%; Average loss: 3.1627\n",
            "Iteration: 2100; Percent complete: 52.5%; Average loss: 3.1521\n",
            "Iteration: 2200; Percent complete: 55.0%; Average loss: 3.0965\n",
            "Iteration: 2300; Percent complete: 57.5%; Average loss: 3.0967\n",
            "Iteration: 2400; Percent complete: 60.0%; Average loss: 3.0363\n",
            "Iteration: 2500; Percent complete: 62.5%; Average loss: 3.0502\n",
            "Iteration: 2600; Percent complete: 65.0%; Average loss: 3.0232\n",
            "Iteration: 2700; Percent complete: 67.5%; Average loss: 2.9629\n",
            "Iteration: 2800; Percent complete: 70.0%; Average loss: 2.9174\n",
            "Iteration: 2900; Percent complete: 72.5%; Average loss: 2.8999\n",
            "Iteration: 3000; Percent complete: 75.0%; Average loss: 2.8884\n",
            "Iteration: 3100; Percent complete: 77.5%; Average loss: 2.8780\n",
            "Iteration: 3200; Percent complete: 80.0%; Average loss: 2.8430\n",
            "Iteration: 3300; Percent complete: 82.5%; Average loss: 2.8126\n",
            "Iteration: 3400; Percent complete: 85.0%; Average loss: 2.7654\n",
            "Iteration: 3500; Percent complete: 87.5%; Average loss: 2.7480\n",
            "Iteration: 3600; Percent complete: 90.0%; Average loss: 2.7325\n",
            "Iteration: 3700; Percent complete: 92.5%; Average loss: 2.7096\n",
            "Iteration: 3800; Percent complete: 95.0%; Average loss: 2.7050\n",
            "Iteration: 3900; Percent complete: 97.5%; Average loss: 2.6434\n",
            "Iteration: 4000; Percent complete: 100.0%; Average loss: 2.6223\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Run Evaluation"
      ],
      "metadata": {
        "id": "phOQwrr8Slwj"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Set dropout layers to ``eval`` mode\n",
        "encoder.eval()\n",
        "decoder.eval()\n",
        "\n",
        "# Initialize search module\n",
        "searcher = GreedySearchDecoder(encoder, decoder)\n",
        "\n",
        "# Begin chatting (uncomment and run the following line to begin)\n",
        "evaluateInput(searcher, voc)"
      ],
      "metadata": {
        "id": "CImWH2wtSkGh",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a1152096-39f7-451b-db1b-2017b70d69e7"
      },
      "execution_count": null,
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "> hi\n",
            "Bot: hi . s van day .\n",
            "> how are you?\n",
            "Bot: i m fine . . . .\n",
            "> what's up?\n",
            "Bot: you re a good man . it .\n",
            "> quit\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Problem 1.2-1.4"
      ],
      "metadata": {
        "id": "ZJLIaw44Ljgg"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Installing `wandb`"
      ],
      "metadata": {
        "id": "9hpKZgT7KjpL"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install wandb --upgrade"
      ],
      "metadata": {
        "id": "aNrBWLx7KjKf",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "73972b2e-9f5e-4586-e7eb-cdba0a5a97c6"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: wandb in /usr/local/lib/python3.10/dist-packages (0.18.5)\n",
            "Requirement already satisfied: click!=8.0.0,>=7.1 in /usr/local/lib/python3.10/dist-packages (from wandb) (8.1.7)\n",
            "Requirement already satisfied: docker-pycreds>=0.4.0 in /usr/local/lib/python3.10/dist-packages (from wandb) (0.4.0)\n",
            "Requirement already satisfied: gitpython!=3.1.29,>=1.0.0 in /usr/local/lib/python3.10/dist-packages (from wandb) (3.1.43)\n",
            "Requirement already satisfied: platformdirs in /usr/local/lib/python3.10/dist-packages (from wandb) (4.3.6)\n",
            "Requirement already satisfied: protobuf!=4.21.0,!=5.28.0,<6,>=3.19.0 in /usr/local/lib/python3.10/dist-packages (from wandb) (3.20.3)\n",
            "Requirement already satisfied: psutil>=5.0.0 in /usr/local/lib/python3.10/dist-packages (from wandb) (5.9.5)\n",
            "Requirement already satisfied: pyyaml in /usr/local/lib/python3.10/dist-packages (from wandb) (6.0.2)\n",
            "Requirement already satisfied: requests<3,>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from wandb) (2.32.3)\n",
            "Requirement already satisfied: sentry-sdk>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from wandb) (2.17.0)\n",
            "Requirement already satisfied: setproctitle in /usr/local/lib/python3.10/dist-packages (from wandb) (1.3.3)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.10/dist-packages (from wandb) (75.1.0)\n",
            "Requirement already satisfied: typing-extensions<5,>=4.4 in /usr/local/lib/python3.10/dist-packages (from wandb) (4.12.2)\n",
            "Requirement already satisfied: six>=1.4.0 in /usr/local/lib/python3.10/dist-packages (from docker-pycreds>=0.4.0->wandb) (1.16.0)\n",
            "Requirement already satisfied: gitdb<5,>=4.0.1 in /usr/local/lib/python3.10/dist-packages (from gitpython!=3.1.29,>=1.0.0->wandb) (4.0.11)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.0.0->wandb) (3.4.0)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.0.0->wandb) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.0.0->wandb) (2.2.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.0.0->wandb) (2024.8.30)\n",
            "Requirement already satisfied: smmap<6,>=3.0.1 in /usr/local/lib/python3.10/dist-packages (from gitdb<5,>=4.0.1->gitpython!=3.1.29,>=1.0.0->wandb) (5.0.1)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Importing `wandb` and logging in"
      ],
      "metadata": {
        "id": "KbzxJgaZK-70"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import wandb\n",
        "\n",
        "wandb.login()"
      ],
      "metadata": {
        "id": "zrqkIRoUKpXX",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 136
        },
        "outputId": "f5d7b8d0-0dad-41b5-c2a1-edc7d80360c8"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[34m\u001b[1mwandb\u001b[0m: Using wandb-core as the SDK backend. Please refer to https://wandb.me/wandb-core for more information.\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "\n",
              "        window._wandbApiKey = new Promise((resolve, reject) => {\n",
              "            function loadScript(url) {\n",
              "            return new Promise(function(resolve, reject) {\n",
              "                let newScript = document.createElement(\"script\");\n",
              "                newScript.onerror = reject;\n",
              "                newScript.onload = resolve;\n",
              "                document.body.appendChild(newScript);\n",
              "                newScript.src = url;\n",
              "            });\n",
              "            }\n",
              "            loadScript(\"https://cdn.jsdelivr.net/npm/postmate/build/postmate.min.js\").then(() => {\n",
              "            const iframe = document.createElement('iframe')\n",
              "            iframe.style.cssText = \"width:0;height:0;border:none\"\n",
              "            document.body.appendChild(iframe)\n",
              "            const handshake = new Postmate({\n",
              "                container: iframe,\n",
              "                url: 'https://wandb.ai/authorize'\n",
              "            });\n",
              "            const timeout = setTimeout(() => reject(\"Couldn't auto authenticate\"), 5000)\n",
              "            handshake.then(function(child) {\n",
              "                child.on('authorize', data => {\n",
              "                    clearTimeout(timeout)\n",
              "                    resolve(data)\n",
              "                });\n",
              "            });\n",
              "            })\n",
              "        });\n",
              "    "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[34m\u001b[1mwandb\u001b[0m: Logging into wandb.ai. (Learn how to deploy a W&B server locally: https://wandb.me/wandb-server)\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: You can find your API key in your browser here: https://wandb.ai/authorize\n",
            "wandb: Paste an API key from your profile and hit enter, or press ctrl+c to quit:"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            " ··········\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[34m\u001b[1mwandb\u001b[0m: Appending key for api.wandb.ai to your netrc file: /root/.netrc\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 22
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Define Sweep Configuration"
      ],
      "metadata": {
        "id": "P5t35JJqki7Y"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "sweep_config = {\n",
        "    'method': 'random'\n",
        "    }"
      ],
      "metadata": {
        "id": "PuX5K6OTaBfx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "metric = {\n",
        "    'name': 'loss',\n",
        "    'goal': 'minimize'\n",
        "    }\n",
        "\n",
        "sweep_config['metric'] = metric"
      ],
      "metadata": {
        "id": "KwciBmk0a6D1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "parameters_dict = {\n",
        "      'learning_rate': {\n",
        "          'values': [0.0001, 0.00025, 0.0005, 0.001]\n",
        "      },\n",
        "      'optimizer': {\n",
        "          'values': [\"adam\", \"sgd\"]\n",
        "      },\n",
        "      'clip': {\n",
        "          'values': [0, 25, 50, 100]\n",
        "      },\n",
        "      'teacher_forcing_ratio': {\n",
        "          'values': [0, 0.5, 1.0]\n",
        "      },\n",
        "      'decoder_learning_ratio':{\n",
        "          'values': [1.0, 3.0, 5.0, 10.0]\n",
        "      }\n",
        "    }\n",
        "\n",
        "sweep_config['parameters'] = parameters_dict"
      ],
      "metadata": {
        "id": "EWVt_5Vya6pI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import pprint\n",
        "\n",
        "pprint.pprint(sweep_config)"
      ],
      "metadata": {
        "id": "mQNejC3OcNYU",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "3bb5f524-b1be-485f-af17-a20782dc8137"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'method': 'random',\n",
            " 'metric': {'goal': 'minimize', 'name': 'loss'},\n",
            " 'parameters': {'clip': {'values': [0, 25, 50, 100]},\n",
            "                'decoder_learning_ratio': {'values': [1.0, 3.0, 5.0, 10.0]},\n",
            "                'learning_rate': {'values': [0.0001, 0.00025, 0.0005, 0.001]},\n",
            "                'optimizer': {'values': ['adam', 'sgd']},\n",
            "                'teacher_forcing_ratio': {'values': [0, 0.5, 1.0]}}}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Creating a train and record function, that initializes `wandb` recording, and runs training on the model"
      ],
      "metadata": {
        "id": "OtE4oalukwce"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def train_and_record():\n",
        "    run = wandb.init(project=\"W&BProjectName\", entity=\"W&BUserName\")\n",
        "    config = run.config\n",
        "\n",
        "    # Configure models\n",
        "    model_name = 'cb_model'\n",
        "    attn_model = 'dot'\n",
        "    hidden_size = 500\n",
        "    encoder_n_layers = 2\n",
        "    decoder_n_layers = 2\n",
        "    dropout = 0.1\n",
        "    batch_size = 64\n",
        "\n",
        "    print('Building encoder and decoder ...')\n",
        "    # Initialize word embeddings\n",
        "    embedding = nn.Embedding(voc.num_words, hidden_size)\n",
        "\n",
        "    # Initialize encoder & decoder models\n",
        "    encoder = EncoderRNN(hidden_size, embedding, encoder_n_layers, dropout)\n",
        "    decoder = LuongAttnDecoderRNN(attn_model, embedding, hidden_size, voc.num_words, decoder_n_layers, dropout)\n",
        "\n",
        "    # Use appropriate device\n",
        "    encoder = encoder.to(device)\n",
        "    decoder = decoder.to(device)\n",
        "    print('Models built and ready to go!')\n",
        "\n",
        "    # Configure training/optimization\n",
        "    clip = config.clip\n",
        "    teacher_forcing_ratio = config.teacher_forcing_ratio\n",
        "    learning_rate = config.learning_rate\n",
        "    decoder_learning_ratio = config.decoder_learning_ratio\n",
        "    n_iteration = 4000\n",
        "    # Changed to not populate the entire console with loss outputs\n",
        "    print_every = 1000\n",
        "    # Fix to NOT save model while running wandb\n",
        "    save_every = 5000\n",
        "\n",
        "    # Ensure dropout layers are in train mode\n",
        "    encoder.train()\n",
        "    decoder.train()\n",
        "\n",
        "    # Initialize optimizers\n",
        "    print('Building optimizers ...')\n",
        "    if config.optimizer == 'adam':\n",
        "        encoder_optimizer = optim.Adam(encoder.parameters(), lr=learning_rate)\n",
        "        decoder_optimizer = optim.Adam(decoder.parameters(), lr=learning_rate * decoder_learning_ratio)\n",
        "    elif config.optimizer == 'sgd':\n",
        "        encoder_optimizer = optim.SGD(encoder.parameters(), lr=learning_rate)\n",
        "        decoder_optimizer = optim.SGD(decoder.parameters(), lr=learning_rate * decoder_learning_ratio)\n",
        "\n",
        "    # If you have CUDA, configure CUDA to call\n",
        "    for state in encoder_optimizer.state.values():\n",
        "        for k, v in state.items():\n",
        "            if isinstance(v, torch.Tensor):\n",
        "                state[k] = v.cuda()\n",
        "\n",
        "    for state in decoder_optimizer.state.values():\n",
        "        for k, v in state.items():\n",
        "            if isinstance(v, torch.Tensor):\n",
        "                state[k] = v.cuda()\n",
        "\n",
        "    # Run training iterations\n",
        "    print(\"Starting Training!\")\n",
        "    trainIters(model_name, voc, pairs, encoder, decoder, encoder_optimizer, decoder_optimizer,\n",
        "            embedding, encoder_n_layers, decoder_n_layers, save_dir, n_iteration, batch_size,\n",
        "            print_every, save_every, clip, teacher_forcing_ratio, hidden_size, corpus_name, record=True)"
      ],
      "metadata": {
        "id": "OOpnmjr-kv1L"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Run Hyperparameter Sweep"
      ],
      "metadata": {
        "id": "08vTOWBoYyqS"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "sweep_id = wandb.sweep(sweep_config, project=\"hpml-chatbot\")"
      ],
      "metadata": {
        "id": "cvKLb4GKcWY0",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "9b06c4f5-2019-414c-c0c2-0377b3801f93"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Create sweep with ID: gv10awn2\n",
            "Sweep URL: https://wandb.ai/nyu-hpml/hpml-chatbot/sweeps/gv10awn2\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "wandb.agent(sweep_id, function=train_and_record, count=25)"
      ],
      "metadata": {
        "collapsed": true,
        "id": "R8SEJrxSkX8S",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000,
          "referenced_widgets": [
            "2d73704b09784a40a1ed89525ab054c1",
            "196bb02d6f17472d8c1b28bbe08fa634",
            "4d6c1ec8510f4bca8d5a36ce267e8df5",
            "84c4b5c8d3af4bacb5f0df99c7ba2938",
            "a26b80662951462083cfbfe27ff5190e",
            "5642e2242c074ae3804f00e57cd40ba9",
            "24fa38c2ec3a48fe8b6f1db2b287dedf",
            "43d95ea04a74479d97e7b18290019dc8"
          ]
        },
        "outputId": "9fde6291-7ee1-42ee-f589-a31bf0ed870a"
      },
      "execution_count": 29,
      "outputs": [
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\u001b[34m\u001b[1mwandb\u001b[0m: Agent Starting Run: ci913wk0 with config:\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \tclip: 50\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \tdecoder_learning_ratio: 1\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \tlearning_rate: 0.00025\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \toptimizer: sgd\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \tteacher_forcing_ratio: 0.5\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mrrm9598\u001b[0m. Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Ignored wandb.init() arg project when running a sweep.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Ignored wandb.init() arg entity when running a sweep.\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "Tracking run with wandb version 0.18.5"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "Run data is saved locally in <code>/content/wandb/run-20241024_041253-ci913wk0</code>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "Syncing run <strong><a href='https://wandb.ai/nyu-hpml/hpml-chatbot/runs/ci913wk0' target=\"_blank\">genial-sweep-1</a></strong> to <a href='https://wandb.ai/nyu-hpml/hpml-chatbot' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>Sweep page: <a href='https://wandb.ai/nyu-hpml/hpml-chatbot/sweeps/gv10awn2' target=\"_blank\">https://wandb.ai/nyu-hpml/hpml-chatbot/sweeps/gv10awn2</a>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              " View project at <a href='https://wandb.ai/nyu-hpml/hpml-chatbot' target=\"_blank\">https://wandb.ai/nyu-hpml/hpml-chatbot</a>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              " View sweep at <a href='https://wandb.ai/nyu-hpml/hpml-chatbot/sweeps/gv10awn2' target=\"_blank\">https://wandb.ai/nyu-hpml/hpml-chatbot/sweeps/gv10awn2</a>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              " View run at <a href='https://wandb.ai/nyu-hpml/hpml-chatbot/runs/ci913wk0' target=\"_blank\">https://wandb.ai/nyu-hpml/hpml-chatbot/runs/ci913wk0</a>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Building encoder and decoder ...\n",
            "Models built and ready to go!\n",
            "Building optimizers ...\n",
            "Starting Training!\n",
            "Initializing ...\n",
            "Training...\n",
            "Iteration: 1000; Percent complete: 25.0%; Average loss: 7.0455\n",
            "Iteration: 2000; Percent complete: 50.0%; Average loss: 5.6932\n",
            "Iteration: 3000; Percent complete: 75.0%; Average loss: 5.2878\n",
            "Iteration: 4000; Percent complete: 100.0%; Average loss: 5.0883\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "<style>\n",
              "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
              "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
              "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
              "    </style>\n",
              "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>loss</td><td>███▇▅▄▄▄▃▃▃▃▃▃▃▃▂▂▃▂▂▂▂▂▂▂▁▂▁▁▁▁▂▂▂▁▂▁▁▂</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>loss</td><td>5.04522</td></tr></table><br/></div></div>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              " View run <strong style=\"color:#cdcd00\">genial-sweep-1</strong> at: <a href='https://wandb.ai/nyu-hpml/hpml-chatbot/runs/ci913wk0' target=\"_blank\">https://wandb.ai/nyu-hpml/hpml-chatbot/runs/ci913wk0</a><br/> View project at: <a href='https://wandb.ai/nyu-hpml/hpml-chatbot' target=\"_blank\">https://wandb.ai/nyu-hpml/hpml-chatbot</a><br/>Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "Find logs at: <code>./wandb/run-20241024_041253-ci913wk0/logs</code>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\u001b[34m\u001b[1mwandb\u001b[0m: Agent Starting Run: sypg6rwf with config:\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \tclip: 25\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \tdecoder_learning_ratio: 1\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \tlearning_rate: 0.0001\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \toptimizer: sgd\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \tteacher_forcing_ratio: 1\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Ignored wandb.init() arg project when running a sweep.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Ignored wandb.init() arg entity when running a sweep.\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "Tracking run with wandb version 0.18.5"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "Run data is saved locally in <code>/content/wandb/run-20241024_041617-sypg6rwf</code>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "Syncing run <strong><a href='https://wandb.ai/nyu-hpml/hpml-chatbot/runs/sypg6rwf' target=\"_blank\">avid-sweep-2</a></strong> to <a href='https://wandb.ai/nyu-hpml/hpml-chatbot' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>Sweep page: <a href='https://wandb.ai/nyu-hpml/hpml-chatbot/sweeps/gv10awn2' target=\"_blank\">https://wandb.ai/nyu-hpml/hpml-chatbot/sweeps/gv10awn2</a>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              " View project at <a href='https://wandb.ai/nyu-hpml/hpml-chatbot' target=\"_blank\">https://wandb.ai/nyu-hpml/hpml-chatbot</a>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              " View sweep at <a href='https://wandb.ai/nyu-hpml/hpml-chatbot/sweeps/gv10awn2' target=\"_blank\">https://wandb.ai/nyu-hpml/hpml-chatbot/sweeps/gv10awn2</a>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              " View run at <a href='https://wandb.ai/nyu-hpml/hpml-chatbot/runs/sypg6rwf' target=\"_blank\">https://wandb.ai/nyu-hpml/hpml-chatbot/runs/sypg6rwf</a>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Building encoder and decoder ...\n",
            "Models built and ready to go!\n",
            "Building optimizers ...\n",
            "Starting Training!\n",
            "Initializing ...\n",
            "Training...\n",
            "Iteration: 1000; Percent complete: 25.0%; Average loss: 8.2744\n",
            "Iteration: 2000; Percent complete: 50.0%; Average loss: 6.4895\n",
            "Iteration: 3000; Percent complete: 75.0%; Average loss: 6.0242\n",
            "Iteration: 4000; Percent complete: 100.0%; Average loss: 5.7004\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "<style>\n",
              "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
              "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
              "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
              "    </style>\n",
              "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>loss</td><td>███▆▅▄▃▃▃▃▃▃▃▃▃▃▂▃▃▃▂▂▃▂▂▂▂▂▂▁▂▂▂▂▂▁▁▁▁▁</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>loss</td><td>5.68057</td></tr></table><br/></div></div>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              " View run <strong style=\"color:#cdcd00\">avid-sweep-2</strong> at: <a href='https://wandb.ai/nyu-hpml/hpml-chatbot/runs/sypg6rwf' target=\"_blank\">https://wandb.ai/nyu-hpml/hpml-chatbot/runs/sypg6rwf</a><br/> View project at: <a href='https://wandb.ai/nyu-hpml/hpml-chatbot' target=\"_blank\">https://wandb.ai/nyu-hpml/hpml-chatbot</a><br/>Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "Find logs at: <code>./wandb/run-20241024_041617-sypg6rwf/logs</code>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\u001b[34m\u001b[1mwandb\u001b[0m: Agent Starting Run: kwns0dtx with config:\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \tclip: 0\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \tdecoder_learning_ratio: 10\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \tlearning_rate: 0.0005\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \toptimizer: adam\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \tteacher_forcing_ratio: 1\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Ignored wandb.init() arg project when running a sweep.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Ignored wandb.init() arg entity when running a sweep.\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "Tracking run with wandb version 0.18.5"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "Run data is saved locally in <code>/content/wandb/run-20241024_041910-kwns0dtx</code>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "Syncing run <strong><a href='https://wandb.ai/nyu-hpml/hpml-chatbot/runs/kwns0dtx' target=\"_blank\">still-sweep-3</a></strong> to <a href='https://wandb.ai/nyu-hpml/hpml-chatbot' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>Sweep page: <a href='https://wandb.ai/nyu-hpml/hpml-chatbot/sweeps/gv10awn2' target=\"_blank\">https://wandb.ai/nyu-hpml/hpml-chatbot/sweeps/gv10awn2</a>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              " View project at <a href='https://wandb.ai/nyu-hpml/hpml-chatbot' target=\"_blank\">https://wandb.ai/nyu-hpml/hpml-chatbot</a>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              " View sweep at <a href='https://wandb.ai/nyu-hpml/hpml-chatbot/sweeps/gv10awn2' target=\"_blank\">https://wandb.ai/nyu-hpml/hpml-chatbot/sweeps/gv10awn2</a>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              " View run at <a href='https://wandb.ai/nyu-hpml/hpml-chatbot/runs/kwns0dtx' target=\"_blank\">https://wandb.ai/nyu-hpml/hpml-chatbot/runs/kwns0dtx</a>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Building encoder and decoder ...\n",
            "Models built and ready to go!\n",
            "Building optimizers ...\n",
            "Starting Training!\n",
            "Initializing ...\n",
            "Training...\n",
            "Iteration: 1000; Percent complete: 25.0%; Average loss: 8.9637\n",
            "Iteration: 2000; Percent complete: 50.0%; Average loss: 8.9636\n",
            "Iteration: 3000; Percent complete: 75.0%; Average loss: 8.9637\n",
            "Iteration: 4000; Percent complete: 100.0%; Average loss: 8.9637\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "<style>\n",
              "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
              "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
              "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
              "    </style>\n",
              "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>loss</td><td>▃▄▃▅▄▅▄▁▆▂▃▆▄▂▅▂▅▃▁▄▃▄▂▄▅▃▄█▄▅▄▄▂▄▂▂▃▆▃▄</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>loss</td><td>8.96294</td></tr></table><br/></div></div>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              " View run <strong style=\"color:#cdcd00\">still-sweep-3</strong> at: <a href='https://wandb.ai/nyu-hpml/hpml-chatbot/runs/kwns0dtx' target=\"_blank\">https://wandb.ai/nyu-hpml/hpml-chatbot/runs/kwns0dtx</a><br/> View project at: <a href='https://wandb.ai/nyu-hpml/hpml-chatbot' target=\"_blank\">https://wandb.ai/nyu-hpml/hpml-chatbot</a><br/>Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "Find logs at: <code>./wandb/run-20241024_041910-kwns0dtx/logs</code>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\u001b[34m\u001b[1mwandb\u001b[0m: Agent Starting Run: gs60l9xa with config:\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \tclip: 0\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \tdecoder_learning_ratio: 1\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \tlearning_rate: 0.00025\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \toptimizer: sgd\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \tteacher_forcing_ratio: 0\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Ignored wandb.init() arg project when running a sweep.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Ignored wandb.init() arg entity when running a sweep.\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "Tracking run with wandb version 0.18.5"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "Run data is saved locally in <code>/content/wandb/run-20241024_042229-gs60l9xa</code>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "Syncing run <strong><a href='https://wandb.ai/nyu-hpml/hpml-chatbot/runs/gs60l9xa' target=\"_blank\">bright-sweep-4</a></strong> to <a href='https://wandb.ai/nyu-hpml/hpml-chatbot' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>Sweep page: <a href='https://wandb.ai/nyu-hpml/hpml-chatbot/sweeps/gv10awn2' target=\"_blank\">https://wandb.ai/nyu-hpml/hpml-chatbot/sweeps/gv10awn2</a>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              " View project at <a href='https://wandb.ai/nyu-hpml/hpml-chatbot' target=\"_blank\">https://wandb.ai/nyu-hpml/hpml-chatbot</a>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              " View sweep at <a href='https://wandb.ai/nyu-hpml/hpml-chatbot/sweeps/gv10awn2' target=\"_blank\">https://wandb.ai/nyu-hpml/hpml-chatbot/sweeps/gv10awn2</a>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              " View run at <a href='https://wandb.ai/nyu-hpml/hpml-chatbot/runs/gs60l9xa' target=\"_blank\">https://wandb.ai/nyu-hpml/hpml-chatbot/runs/gs60l9xa</a>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Building encoder and decoder ...\n",
            "Models built and ready to go!\n",
            "Building optimizers ...\n",
            "Starting Training!\n",
            "Initializing ...\n",
            "Training...\n",
            "Iteration: 1000; Percent complete: 25.0%; Average loss: 8.9584\n",
            "Iteration: 2000; Percent complete: 50.0%; Average loss: 8.9583\n",
            "Iteration: 3000; Percent complete: 75.0%; Average loss: 8.9583\n",
            "Iteration: 4000; Percent complete: 100.0%; Average loss: 8.9583\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "<style>\n",
              "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
              "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
              "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
              "    </style>\n",
              "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>loss</td><td>▅▁▆▃▆▅▁▃▂▅▅▅▅▄█▇▇▅▄▄█▄▃▅▇▂▂▆▅▇▆▄▅▄▄▅▄▄▄▅</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>loss</td><td>8.95523</td></tr></table><br/></div></div>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              " View run <strong style=\"color:#cdcd00\">bright-sweep-4</strong> at: <a href='https://wandb.ai/nyu-hpml/hpml-chatbot/runs/gs60l9xa' target=\"_blank\">https://wandb.ai/nyu-hpml/hpml-chatbot/runs/gs60l9xa</a><br/> View project at: <a href='https://wandb.ai/nyu-hpml/hpml-chatbot' target=\"_blank\">https://wandb.ai/nyu-hpml/hpml-chatbot</a><br/>Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "Find logs at: <code>./wandb/run-20241024_042229-gs60l9xa/logs</code>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\u001b[34m\u001b[1mwandb\u001b[0m: Agent Starting Run: 7e0y907q with config:\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \tclip: 50\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \tdecoder_learning_ratio: 5\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \tlearning_rate: 0.0005\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \toptimizer: adam\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \tteacher_forcing_ratio: 0\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Ignored wandb.init() arg project when running a sweep.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Ignored wandb.init() arg entity when running a sweep.\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "Tracking run with wandb version 0.18.5"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "Run data is saved locally in <code>/content/wandb/run-20241024_042603-7e0y907q</code>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "Syncing run <strong><a href='https://wandb.ai/nyu-hpml/hpml-chatbot/runs/7e0y907q' target=\"_blank\">snowy-sweep-5</a></strong> to <a href='https://wandb.ai/nyu-hpml/hpml-chatbot' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>Sweep page: <a href='https://wandb.ai/nyu-hpml/hpml-chatbot/sweeps/gv10awn2' target=\"_blank\">https://wandb.ai/nyu-hpml/hpml-chatbot/sweeps/gv10awn2</a>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              " View project at <a href='https://wandb.ai/nyu-hpml/hpml-chatbot' target=\"_blank\">https://wandb.ai/nyu-hpml/hpml-chatbot</a>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              " View sweep at <a href='https://wandb.ai/nyu-hpml/hpml-chatbot/sweeps/gv10awn2' target=\"_blank\">https://wandb.ai/nyu-hpml/hpml-chatbot/sweeps/gv10awn2</a>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              " View run at <a href='https://wandb.ai/nyu-hpml/hpml-chatbot/runs/7e0y907q' target=\"_blank\">https://wandb.ai/nyu-hpml/hpml-chatbot/runs/7e0y907q</a>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Building encoder and decoder ...\n",
            "Models built and ready to go!\n",
            "Building optimizers ...\n",
            "Starting Training!\n",
            "Initializing ...\n",
            "Training...\n",
            "Iteration: 1000; Percent complete: 25.0%; Average loss: 5.0509\n",
            "Iteration: 2000; Percent complete: 50.0%; Average loss: 4.8957\n",
            "Iteration: 3000; Percent complete: 75.0%; Average loss: 4.7213\n",
            "Iteration: 4000; Percent complete: 100.0%; Average loss: 4.5114\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "<style>\n",
              "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
              "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
              "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
              "    </style>\n",
              "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>loss</td><td>██▇▆▇▅▅█▅▆▆▅▄▆▆▅▅▅▄▆▅▆▅▅▅▄▄▆▇▄▅▅▅▃▄▄▄▃▁▃</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>loss</td><td>4.54506</td></tr></table><br/></div></div>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              " View run <strong style=\"color:#cdcd00\">snowy-sweep-5</strong> at: <a href='https://wandb.ai/nyu-hpml/hpml-chatbot/runs/7e0y907q' target=\"_blank\">https://wandb.ai/nyu-hpml/hpml-chatbot/runs/7e0y907q</a><br/> View project at: <a href='https://wandb.ai/nyu-hpml/hpml-chatbot' target=\"_blank\">https://wandb.ai/nyu-hpml/hpml-chatbot</a><br/>Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "Find logs at: <code>./wandb/run-20241024_042603-7e0y907q/logs</code>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\u001b[34m\u001b[1mwandb\u001b[0m: Agent Starting Run: 7p62xl7g with config:\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \tclip: 25\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \tdecoder_learning_ratio: 5\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \tlearning_rate: 0.001\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \toptimizer: sgd\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \tteacher_forcing_ratio: 0\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Ignored wandb.init() arg project when running a sweep.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Ignored wandb.init() arg entity when running a sweep.\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "Tracking run with wandb version 0.18.5"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "Run data is saved locally in <code>/content/wandb/run-20241024_042957-7p62xl7g</code>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "Syncing run <strong><a href='https://wandb.ai/nyu-hpml/hpml-chatbot/runs/7p62xl7g' target=\"_blank\">zesty-sweep-6</a></strong> to <a href='https://wandb.ai/nyu-hpml/hpml-chatbot' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>Sweep page: <a href='https://wandb.ai/nyu-hpml/hpml-chatbot/sweeps/gv10awn2' target=\"_blank\">https://wandb.ai/nyu-hpml/hpml-chatbot/sweeps/gv10awn2</a>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              " View project at <a href='https://wandb.ai/nyu-hpml/hpml-chatbot' target=\"_blank\">https://wandb.ai/nyu-hpml/hpml-chatbot</a>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              " View sweep at <a href='https://wandb.ai/nyu-hpml/hpml-chatbot/sweeps/gv10awn2' target=\"_blank\">https://wandb.ai/nyu-hpml/hpml-chatbot/sweeps/gv10awn2</a>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              " View run at <a href='https://wandb.ai/nyu-hpml/hpml-chatbot/runs/7p62xl7g' target=\"_blank\">https://wandb.ai/nyu-hpml/hpml-chatbot/runs/7p62xl7g</a>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Building encoder and decoder ...\n",
            "Models built and ready to go!\n",
            "Building optimizers ...\n",
            "Starting Training!\n",
            "Initializing ...\n",
            "Training...\n",
            "Iteration: 1000; Percent complete: 25.0%; Average loss: 5.1616\n",
            "Iteration: 2000; Percent complete: 50.0%; Average loss: 4.7487\n",
            "Iteration: 3000; Percent complete: 75.0%; Average loss: 4.6950\n",
            "Iteration: 4000; Percent complete: 100.0%; Average loss: 4.6629\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "<style>\n",
              "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
              "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
              "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
              "    </style>\n",
              "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>loss</td><td>█▂▃▂▂▂▂▂▁▂▂▂▂▁▁▁▁▁▂▁▂▁▂▂▂▂▁▂▁▂▁▁▁▁▁▁▁▁▁▁</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>loss</td><td>4.54752</td></tr></table><br/></div></div>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              " View run <strong style=\"color:#cdcd00\">zesty-sweep-6</strong> at: <a href='https://wandb.ai/nyu-hpml/hpml-chatbot/runs/7p62xl7g' target=\"_blank\">https://wandb.ai/nyu-hpml/hpml-chatbot/runs/7p62xl7g</a><br/> View project at: <a href='https://wandb.ai/nyu-hpml/hpml-chatbot' target=\"_blank\">https://wandb.ai/nyu-hpml/hpml-chatbot</a><br/>Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "Find logs at: <code>./wandb/run-20241024_042957-7p62xl7g/logs</code>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\u001b[34m\u001b[1mwandb\u001b[0m: Agent Starting Run: toncuq80 with config:\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \tclip: 100\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \tdecoder_learning_ratio: 10\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \tlearning_rate: 0.0005\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \toptimizer: adam\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \tteacher_forcing_ratio: 0.5\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Ignored wandb.init() arg project when running a sweep.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Ignored wandb.init() arg entity when running a sweep.\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "Tracking run with wandb version 0.18.5"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "Run data is saved locally in <code>/content/wandb/run-20241024_043330-toncuq80</code>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "Syncing run <strong><a href='https://wandb.ai/nyu-hpml/hpml-chatbot/runs/toncuq80' target=\"_blank\">prime-sweep-7</a></strong> to <a href='https://wandb.ai/nyu-hpml/hpml-chatbot' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>Sweep page: <a href='https://wandb.ai/nyu-hpml/hpml-chatbot/sweeps/gv10awn2' target=\"_blank\">https://wandb.ai/nyu-hpml/hpml-chatbot/sweeps/gv10awn2</a>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              " View project at <a href='https://wandb.ai/nyu-hpml/hpml-chatbot' target=\"_blank\">https://wandb.ai/nyu-hpml/hpml-chatbot</a>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              " View sweep at <a href='https://wandb.ai/nyu-hpml/hpml-chatbot/sweeps/gv10awn2' target=\"_blank\">https://wandb.ai/nyu-hpml/hpml-chatbot/sweeps/gv10awn2</a>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              " View run at <a href='https://wandb.ai/nyu-hpml/hpml-chatbot/runs/toncuq80' target=\"_blank\">https://wandb.ai/nyu-hpml/hpml-chatbot/runs/toncuq80</a>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Building encoder and decoder ...\n",
            "Models built and ready to go!\n",
            "Building optimizers ...\n",
            "Starting Training!\n",
            "Initializing ...\n",
            "Training...\n",
            "Iteration: 1000; Percent complete: 25.0%; Average loss: 4.9804\n",
            "Iteration: 2000; Percent complete: 50.0%; Average loss: 4.8257\n",
            "Iteration: 3000; Percent complete: 75.0%; Average loss: 4.7935\n",
            "Iteration: 4000; Percent complete: 100.0%; Average loss: 4.8363\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "<style>\n",
              "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
              "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
              "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
              "    </style>\n",
              "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>loss</td><td>▅█▆▂▂▅▂▁▃▇▄▅▆▂▆▆▄▆▄▅▆▆▂▆█▇▂▇▂▃▃▂█▇▅▅▂▃▄▄</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>loss</td><td>5.68426</td></tr></table><br/></div></div>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              " View run <strong style=\"color:#cdcd00\">prime-sweep-7</strong> at: <a href='https://wandb.ai/nyu-hpml/hpml-chatbot/runs/toncuq80' target=\"_blank\">https://wandb.ai/nyu-hpml/hpml-chatbot/runs/toncuq80</a><br/> View project at: <a href='https://wandb.ai/nyu-hpml/hpml-chatbot' target=\"_blank\">https://wandb.ai/nyu-hpml/hpml-chatbot</a><br/>Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "Find logs at: <code>./wandb/run-20241024_043330-toncuq80/logs</code>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\u001b[34m\u001b[1mwandb\u001b[0m: Agent Starting Run: 6jykk190 with config:\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \tclip: 25\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \tdecoder_learning_ratio: 1\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \tlearning_rate: 0.0001\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \toptimizer: adam\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \tteacher_forcing_ratio: 0\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Ignored wandb.init() arg project when running a sweep.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Ignored wandb.init() arg entity when running a sweep.\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "Tracking run with wandb version 0.18.5"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "Run data is saved locally in <code>/content/wandb/run-20241024_043714-6jykk190</code>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "Syncing run <strong><a href='https://wandb.ai/nyu-hpml/hpml-chatbot/runs/6jykk190' target=\"_blank\">azure-sweep-8</a></strong> to <a href='https://wandb.ai/nyu-hpml/hpml-chatbot' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>Sweep page: <a href='https://wandb.ai/nyu-hpml/hpml-chatbot/sweeps/gv10awn2' target=\"_blank\">https://wandb.ai/nyu-hpml/hpml-chatbot/sweeps/gv10awn2</a>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              " View project at <a href='https://wandb.ai/nyu-hpml/hpml-chatbot' target=\"_blank\">https://wandb.ai/nyu-hpml/hpml-chatbot</a>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              " View sweep at <a href='https://wandb.ai/nyu-hpml/hpml-chatbot/sweeps/gv10awn2' target=\"_blank\">https://wandb.ai/nyu-hpml/hpml-chatbot/sweeps/gv10awn2</a>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              " View run at <a href='https://wandb.ai/nyu-hpml/hpml-chatbot/runs/6jykk190' target=\"_blank\">https://wandb.ai/nyu-hpml/hpml-chatbot/runs/6jykk190</a>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Building encoder and decoder ...\n",
            "Models built and ready to go!\n",
            "Building optimizers ...\n",
            "Starting Training!\n",
            "Initializing ...\n",
            "Training...\n",
            "Iteration: 1000; Percent complete: 25.0%; Average loss: 4.8235\n",
            "Iteration: 2000; Percent complete: 50.0%; Average loss: 4.5969\n",
            "Iteration: 3000; Percent complete: 75.0%; Average loss: 4.5651\n",
            "Iteration: 4000; Percent complete: 100.0%; Average loss: 4.5123\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "2d73704b09784a40a1ed89525ab054c1",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "VBox(children=(Label(value='0.011 MB of 0.011 MB uploaded\\r'), FloatProgress(value=1.0, max=1.0)))"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "<style>\n",
              "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
              "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
              "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
              "    </style>\n",
              "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>loss</td><td>█▄▂▂▃▂▃▂▂▂▂▂▂▂▂▂▂▂▂▂▂▂▂▁▂▂▁▂▂▁▁▂▂▂▂▂▂▂▂▁</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>loss</td><td>4.46142</td></tr></table><br/></div></div>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              " View run <strong style=\"color:#cdcd00\">azure-sweep-8</strong> at: <a href='https://wandb.ai/nyu-hpml/hpml-chatbot/runs/6jykk190' target=\"_blank\">https://wandb.ai/nyu-hpml/hpml-chatbot/runs/6jykk190</a><br/> View project at: <a href='https://wandb.ai/nyu-hpml/hpml-chatbot' target=\"_blank\">https://wandb.ai/nyu-hpml/hpml-chatbot</a><br/>Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "Find logs at: <code>./wandb/run-20241024_043714-6jykk190/logs</code>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\u001b[34m\u001b[1mwandb\u001b[0m: Agent Starting Run: mn0jgr6r with config:\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \tclip: 100\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \tdecoder_learning_ratio: 5\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \tlearning_rate: 0.00025\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \toptimizer: sgd\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \tteacher_forcing_ratio: 0.5\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Ignored wandb.init() arg project when running a sweep.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Ignored wandb.init() arg entity when running a sweep.\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "Tracking run with wandb version 0.18.5"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "Run data is saved locally in <code>/content/wandb/run-20241024_044116-mn0jgr6r</code>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "Syncing run <strong><a href='https://wandb.ai/nyu-hpml/hpml-chatbot/runs/mn0jgr6r' target=\"_blank\">daily-sweep-9</a></strong> to <a href='https://wandb.ai/nyu-hpml/hpml-chatbot' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>Sweep page: <a href='https://wandb.ai/nyu-hpml/hpml-chatbot/sweeps/gv10awn2' target=\"_blank\">https://wandb.ai/nyu-hpml/hpml-chatbot/sweeps/gv10awn2</a>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              " View project at <a href='https://wandb.ai/nyu-hpml/hpml-chatbot' target=\"_blank\">https://wandb.ai/nyu-hpml/hpml-chatbot</a>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              " View sweep at <a href='https://wandb.ai/nyu-hpml/hpml-chatbot/sweeps/gv10awn2' target=\"_blank\">https://wandb.ai/nyu-hpml/hpml-chatbot/sweeps/gv10awn2</a>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              " View run at <a href='https://wandb.ai/nyu-hpml/hpml-chatbot/runs/mn0jgr6r' target=\"_blank\">https://wandb.ai/nyu-hpml/hpml-chatbot/runs/mn0jgr6r</a>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Building encoder and decoder ...\n",
            "Models built and ready to go!\n",
            "Building optimizers ...\n",
            "Starting Training!\n",
            "Initializing ...\n",
            "Training...\n",
            "Iteration: 1000; Percent complete: 25.0%; Average loss: 5.8261\n",
            "Iteration: 2000; Percent complete: 50.0%; Average loss: 4.9082\n",
            "Iteration: 3000; Percent complete: 75.0%; Average loss: 4.7576\n",
            "Iteration: 4000; Percent complete: 100.0%; Average loss: 4.6801\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "<style>\n",
              "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
              "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
              "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
              "    </style>\n",
              "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>loss</td><td>█▆▅▃▃▃▃▃▂▂▃▂▃▃▂▂▂▂▂▂▃▂▁▂▂▂▁▂▂▂▂▁▂▂▁▁▁▁▂▁</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>loss</td><td>5.02757</td></tr></table><br/></div></div>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              " View run <strong style=\"color:#cdcd00\">daily-sweep-9</strong> at: <a href='https://wandb.ai/nyu-hpml/hpml-chatbot/runs/mn0jgr6r' target=\"_blank\">https://wandb.ai/nyu-hpml/hpml-chatbot/runs/mn0jgr6r</a><br/> View project at: <a href='https://wandb.ai/nyu-hpml/hpml-chatbot' target=\"_blank\">https://wandb.ai/nyu-hpml/hpml-chatbot</a><br/>Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "Find logs at: <code>./wandb/run-20241024_044116-mn0jgr6r/logs</code>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\u001b[34m\u001b[1mwandb\u001b[0m: Agent Starting Run: zdght34v with config:\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \tclip: 50\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \tdecoder_learning_ratio: 3\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \tlearning_rate: 0.0005\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \toptimizer: adam\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \tteacher_forcing_ratio: 1\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Ignored wandb.init() arg project when running a sweep.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Ignored wandb.init() arg entity when running a sweep.\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "Tracking run with wandb version 0.18.5"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "Run data is saved locally in <code>/content/wandb/run-20241024_044429-zdght34v</code>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "Syncing run <strong><a href='https://wandb.ai/nyu-hpml/hpml-chatbot/runs/zdght34v' target=\"_blank\">sunny-sweep-10</a></strong> to <a href='https://wandb.ai/nyu-hpml/hpml-chatbot' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>Sweep page: <a href='https://wandb.ai/nyu-hpml/hpml-chatbot/sweeps/gv10awn2' target=\"_blank\">https://wandb.ai/nyu-hpml/hpml-chatbot/sweeps/gv10awn2</a>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              " View project at <a href='https://wandb.ai/nyu-hpml/hpml-chatbot' target=\"_blank\">https://wandb.ai/nyu-hpml/hpml-chatbot</a>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              " View sweep at <a href='https://wandb.ai/nyu-hpml/hpml-chatbot/sweeps/gv10awn2' target=\"_blank\">https://wandb.ai/nyu-hpml/hpml-chatbot/sweeps/gv10awn2</a>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              " View run at <a href='https://wandb.ai/nyu-hpml/hpml-chatbot/runs/zdght34v' target=\"_blank\">https://wandb.ai/nyu-hpml/hpml-chatbot/runs/zdght34v</a>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Building encoder and decoder ...\n",
            "Models built and ready to go!\n",
            "Building optimizers ...\n",
            "Starting Training!\n",
            "Initializing ...\n",
            "Training...\n",
            "Iteration: 1000; Percent complete: 25.0%; Average loss: 3.7578\n",
            "Iteration: 2000; Percent complete: 50.0%; Average loss: 3.0330\n",
            "Iteration: 3000; Percent complete: 75.0%; Average loss: 2.5742\n",
            "Iteration: 4000; Percent complete: 100.0%; Average loss: 2.1613\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "<style>\n",
              "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
              "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
              "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
              "    </style>\n",
              "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>loss</td><td>█▇▆▆▆▅▅▆▆▅▅▆▅▅▅▅▄▅▄▄▄▃▃▄▄▃▃▃▃▃▃▂▃▃▂▂▂▂▂▁</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>loss</td><td>2.01315</td></tr></table><br/></div></div>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              " View run <strong style=\"color:#cdcd00\">sunny-sweep-10</strong> at: <a href='https://wandb.ai/nyu-hpml/hpml-chatbot/runs/zdght34v' target=\"_blank\">https://wandb.ai/nyu-hpml/hpml-chatbot/runs/zdght34v</a><br/> View project at: <a href='https://wandb.ai/nyu-hpml/hpml-chatbot' target=\"_blank\">https://wandb.ai/nyu-hpml/hpml-chatbot</a><br/>Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "Find logs at: <code>./wandb/run-20241024_044429-zdght34v/logs</code>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\u001b[34m\u001b[1mwandb\u001b[0m: Agent Starting Run: ejee6dyz with config:\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \tclip: 100\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \tdecoder_learning_ratio: 3\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \tlearning_rate: 0.001\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \toptimizer: sgd\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \tteacher_forcing_ratio: 0\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Ignored wandb.init() arg project when running a sweep.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Ignored wandb.init() arg entity when running a sweep.\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "Tracking run with wandb version 0.18.5"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "Run data is saved locally in <code>/content/wandb/run-20241024_044748-ejee6dyz</code>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "Syncing run <strong><a href='https://wandb.ai/nyu-hpml/hpml-chatbot/runs/ejee6dyz' target=\"_blank\">winter-sweep-11</a></strong> to <a href='https://wandb.ai/nyu-hpml/hpml-chatbot' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>Sweep page: <a href='https://wandb.ai/nyu-hpml/hpml-chatbot/sweeps/gv10awn2' target=\"_blank\">https://wandb.ai/nyu-hpml/hpml-chatbot/sweeps/gv10awn2</a>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              " View project at <a href='https://wandb.ai/nyu-hpml/hpml-chatbot' target=\"_blank\">https://wandb.ai/nyu-hpml/hpml-chatbot</a>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              " View sweep at <a href='https://wandb.ai/nyu-hpml/hpml-chatbot/sweeps/gv10awn2' target=\"_blank\">https://wandb.ai/nyu-hpml/hpml-chatbot/sweeps/gv10awn2</a>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              " View run at <a href='https://wandb.ai/nyu-hpml/hpml-chatbot/runs/ejee6dyz' target=\"_blank\">https://wandb.ai/nyu-hpml/hpml-chatbot/runs/ejee6dyz</a>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Building encoder and decoder ...\n",
            "Models built and ready to go!\n",
            "Building optimizers ...\n",
            "Starting Training!\n",
            "Initializing ...\n",
            "Training...\n",
            "Iteration: 1000; Percent complete: 25.0%; Average loss: 5.2955\n",
            "Iteration: 2000; Percent complete: 50.0%; Average loss: 4.8008\n",
            "Iteration: 3000; Percent complete: 75.0%; Average loss: 4.7284\n",
            "Iteration: 4000; Percent complete: 100.0%; Average loss: 4.7004\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "<style>\n",
              "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
              "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
              "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
              "    </style>\n",
              "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>loss</td><td>█▇▃▃▃▃▂▂▂▂▃▃▂▂▂▂▂▃▂▂▂▂▁▂▂▂▂▂▂▂▂▁▁▂▂▁▂▂▃▂</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>loss</td><td>4.61409</td></tr></table><br/></div></div>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              " View run <strong style=\"color:#cdcd00\">winter-sweep-11</strong> at: <a href='https://wandb.ai/nyu-hpml/hpml-chatbot/runs/ejee6dyz' target=\"_blank\">https://wandb.ai/nyu-hpml/hpml-chatbot/runs/ejee6dyz</a><br/> View project at: <a href='https://wandb.ai/nyu-hpml/hpml-chatbot' target=\"_blank\">https://wandb.ai/nyu-hpml/hpml-chatbot</a><br/>Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "Find logs at: <code>./wandb/run-20241024_044748-ejee6dyz/logs</code>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\u001b[34m\u001b[1mwandb\u001b[0m: Sweep Agent: Waiting for job.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Job received.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Agent Starting Run: q72x4a70 with config:\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \tclip: 50\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \tdecoder_learning_ratio: 1\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \tlearning_rate: 0.0001\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \toptimizer: sgd\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \tteacher_forcing_ratio: 1\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Ignored wandb.init() arg project when running a sweep.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Ignored wandb.init() arg entity when running a sweep.\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "Tracking run with wandb version 0.18.5"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "Run data is saved locally in <code>/content/wandb/run-20241024_045126-q72x4a70</code>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "Syncing run <strong><a href='https://wandb.ai/nyu-hpml/hpml-chatbot/runs/q72x4a70' target=\"_blank\">helpful-sweep-12</a></strong> to <a href='https://wandb.ai/nyu-hpml/hpml-chatbot' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>Sweep page: <a href='https://wandb.ai/nyu-hpml/hpml-chatbot/sweeps/gv10awn2' target=\"_blank\">https://wandb.ai/nyu-hpml/hpml-chatbot/sweeps/gv10awn2</a>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              " View project at <a href='https://wandb.ai/nyu-hpml/hpml-chatbot' target=\"_blank\">https://wandb.ai/nyu-hpml/hpml-chatbot</a>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              " View sweep at <a href='https://wandb.ai/nyu-hpml/hpml-chatbot/sweeps/gv10awn2' target=\"_blank\">https://wandb.ai/nyu-hpml/hpml-chatbot/sweeps/gv10awn2</a>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              " View run at <a href='https://wandb.ai/nyu-hpml/hpml-chatbot/runs/q72x4a70' target=\"_blank\">https://wandb.ai/nyu-hpml/hpml-chatbot/runs/q72x4a70</a>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Building encoder and decoder ...\n",
            "Models built and ready to go!\n",
            "Building optimizers ...\n",
            "Starting Training!\n",
            "Initializing ...\n",
            "Training...\n",
            "Iteration: 1000; Percent complete: 25.0%; Average loss: 8.3837\n",
            "Iteration: 2000; Percent complete: 50.0%; Average loss: 6.5788\n",
            "Iteration: 3000; Percent complete: 75.0%; Average loss: 6.0874\n",
            "Iteration: 4000; Percent complete: 100.0%; Average loss: 5.7312\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "<style>\n",
              "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
              "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
              "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
              "    </style>\n",
              "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>loss</td><td>██████▇▇▇▇▄▄▃▃▄▃▃▂▃▂▃▂▂▃▂▂▂▂▂▂▂▂▂▁▁▂▁▁▁▁</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>loss</td><td>5.5288</td></tr></table><br/></div></div>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              " View run <strong style=\"color:#cdcd00\">helpful-sweep-12</strong> at: <a href='https://wandb.ai/nyu-hpml/hpml-chatbot/runs/q72x4a70' target=\"_blank\">https://wandb.ai/nyu-hpml/hpml-chatbot/runs/q72x4a70</a><br/> View project at: <a href='https://wandb.ai/nyu-hpml/hpml-chatbot' target=\"_blank\">https://wandb.ai/nyu-hpml/hpml-chatbot</a><br/>Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "Find logs at: <code>./wandb/run-20241024_045126-q72x4a70/logs</code>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\u001b[34m\u001b[1mwandb\u001b[0m: Agent Starting Run: pw9ba5af with config:\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \tclip: 50\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \tdecoder_learning_ratio: 3\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \tlearning_rate: 0.0001\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \toptimizer: sgd\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \tteacher_forcing_ratio: 0\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Ignored wandb.init() arg project when running a sweep.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Ignored wandb.init() arg entity when running a sweep.\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "Tracking run with wandb version 0.18.5"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "Run data is saved locally in <code>/content/wandb/run-20241024_045423-pw9ba5af</code>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "Syncing run <strong><a href='https://wandb.ai/nyu-hpml/hpml-chatbot/runs/pw9ba5af' target=\"_blank\">revived-sweep-13</a></strong> to <a href='https://wandb.ai/nyu-hpml/hpml-chatbot' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>Sweep page: <a href='https://wandb.ai/nyu-hpml/hpml-chatbot/sweeps/gv10awn2' target=\"_blank\">https://wandb.ai/nyu-hpml/hpml-chatbot/sweeps/gv10awn2</a>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              " View project at <a href='https://wandb.ai/nyu-hpml/hpml-chatbot' target=\"_blank\">https://wandb.ai/nyu-hpml/hpml-chatbot</a>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              " View sweep at <a href='https://wandb.ai/nyu-hpml/hpml-chatbot/sweeps/gv10awn2' target=\"_blank\">https://wandb.ai/nyu-hpml/hpml-chatbot/sweeps/gv10awn2</a>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              " View run at <a href='https://wandb.ai/nyu-hpml/hpml-chatbot/runs/pw9ba5af' target=\"_blank\">https://wandb.ai/nyu-hpml/hpml-chatbot/runs/pw9ba5af</a>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Building encoder and decoder ...\n",
            "Models built and ready to go!\n",
            "Building optimizers ...\n",
            "Starting Training!\n",
            "Initializing ...\n",
            "Training...\n",
            "Iteration: 1000; Percent complete: 25.0%; Average loss: 6.8362\n",
            "Iteration: 2000; Percent complete: 50.0%; Average loss: 5.7641\n",
            "Iteration: 3000; Percent complete: 75.0%; Average loss: 5.3650\n",
            "Iteration: 4000; Percent complete: 100.0%; Average loss: 5.1645\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "<style>\n",
              "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
              "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
              "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
              "    </style>\n",
              "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>loss</td><td>█▆▅▄▄▄▄▃▃▃▃▃▂▂▃▃▂▂▂▂▂▂▂▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>loss</td><td>5.00222</td></tr></table><br/></div></div>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              " View run <strong style=\"color:#cdcd00\">revived-sweep-13</strong> at: <a href='https://wandb.ai/nyu-hpml/hpml-chatbot/runs/pw9ba5af' target=\"_blank\">https://wandb.ai/nyu-hpml/hpml-chatbot/runs/pw9ba5af</a><br/> View project at: <a href='https://wandb.ai/nyu-hpml/hpml-chatbot' target=\"_blank\">https://wandb.ai/nyu-hpml/hpml-chatbot</a><br/>Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "Find logs at: <code>./wandb/run-20241024_045423-pw9ba5af/logs</code>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\u001b[34m\u001b[1mwandb\u001b[0m: Agent Starting Run: 2rgfnvus with config:\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \tclip: 50\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \tdecoder_learning_ratio: 3\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \tlearning_rate: 0.001\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \toptimizer: sgd\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \tteacher_forcing_ratio: 0\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Ignored wandb.init() arg project when running a sweep.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Ignored wandb.init() arg entity when running a sweep.\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "Tracking run with wandb version 0.18.5"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "Run data is saved locally in <code>/content/wandb/run-20241024_045802-2rgfnvus</code>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "Syncing run <strong><a href='https://wandb.ai/nyu-hpml/hpml-chatbot/runs/2rgfnvus' target=\"_blank\">crimson-sweep-14</a></strong> to <a href='https://wandb.ai/nyu-hpml/hpml-chatbot' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>Sweep page: <a href='https://wandb.ai/nyu-hpml/hpml-chatbot/sweeps/gv10awn2' target=\"_blank\">https://wandb.ai/nyu-hpml/hpml-chatbot/sweeps/gv10awn2</a>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              " View project at <a href='https://wandb.ai/nyu-hpml/hpml-chatbot' target=\"_blank\">https://wandb.ai/nyu-hpml/hpml-chatbot</a>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              " View sweep at <a href='https://wandb.ai/nyu-hpml/hpml-chatbot/sweeps/gv10awn2' target=\"_blank\">https://wandb.ai/nyu-hpml/hpml-chatbot/sweeps/gv10awn2</a>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              " View run at <a href='https://wandb.ai/nyu-hpml/hpml-chatbot/runs/2rgfnvus' target=\"_blank\">https://wandb.ai/nyu-hpml/hpml-chatbot/runs/2rgfnvus</a>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Building encoder and decoder ...\n",
            "Models built and ready to go!\n",
            "Building optimizers ...\n",
            "Starting Training!\n",
            "Initializing ...\n",
            "Training...\n",
            "Iteration: 1000; Percent complete: 25.0%; Average loss: 5.2995\n",
            "Iteration: 2000; Percent complete: 50.0%; Average loss: 4.8106\n",
            "Iteration: 3000; Percent complete: 75.0%; Average loss: 4.7302\n",
            "Iteration: 4000; Percent complete: 100.0%; Average loss: 4.7020\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "<style>\n",
              "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
              "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
              "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
              "    </style>\n",
              "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>loss</td><td>█▄▃▃▄▃▃▃▃▂▂▂▃▃▂▂▁▁▃▁▂▂▂▂▂▂▁▁▂▁▁▂▂▂▂▃▂▂▂▂</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>loss</td><td>4.55736</td></tr></table><br/></div></div>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              " View run <strong style=\"color:#cdcd00\">crimson-sweep-14</strong> at: <a href='https://wandb.ai/nyu-hpml/hpml-chatbot/runs/2rgfnvus' target=\"_blank\">https://wandb.ai/nyu-hpml/hpml-chatbot/runs/2rgfnvus</a><br/> View project at: <a href='https://wandb.ai/nyu-hpml/hpml-chatbot' target=\"_blank\">https://wandb.ai/nyu-hpml/hpml-chatbot</a><br/>Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "Find logs at: <code>./wandb/run-20241024_045802-2rgfnvus/logs</code>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\u001b[34m\u001b[1mwandb\u001b[0m: Agent Starting Run: saa7wvwi with config:\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \tclip: 0\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \tdecoder_learning_ratio: 5\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \tlearning_rate: 0.00025\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \toptimizer: sgd\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \tteacher_forcing_ratio: 0\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Ignored wandb.init() arg project when running a sweep.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Ignored wandb.init() arg entity when running a sweep.\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "Tracking run with wandb version 0.18.5"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "Run data is saved locally in <code>/content/wandb/run-20241024_050141-saa7wvwi</code>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "Syncing run <strong><a href='https://wandb.ai/nyu-hpml/hpml-chatbot/runs/saa7wvwi' target=\"_blank\">young-sweep-15</a></strong> to <a href='https://wandb.ai/nyu-hpml/hpml-chatbot' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>Sweep page: <a href='https://wandb.ai/nyu-hpml/hpml-chatbot/sweeps/gv10awn2' target=\"_blank\">https://wandb.ai/nyu-hpml/hpml-chatbot/sweeps/gv10awn2</a>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              " View project at <a href='https://wandb.ai/nyu-hpml/hpml-chatbot' target=\"_blank\">https://wandb.ai/nyu-hpml/hpml-chatbot</a>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              " View sweep at <a href='https://wandb.ai/nyu-hpml/hpml-chatbot/sweeps/gv10awn2' target=\"_blank\">https://wandb.ai/nyu-hpml/hpml-chatbot/sweeps/gv10awn2</a>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              " View run at <a href='https://wandb.ai/nyu-hpml/hpml-chatbot/runs/saa7wvwi' target=\"_blank\">https://wandb.ai/nyu-hpml/hpml-chatbot/runs/saa7wvwi</a>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Building encoder and decoder ...\n",
            "Models built and ready to go!\n",
            "Building optimizers ...\n",
            "Starting Training!\n",
            "Initializing ...\n",
            "Training...\n",
            "Iteration: 1000; Percent complete: 25.0%; Average loss: 8.9829\n",
            "Iteration: 2000; Percent complete: 50.0%; Average loss: 8.9827\n",
            "Iteration: 3000; Percent complete: 75.0%; Average loss: 8.9827\n",
            "Iteration: 4000; Percent complete: 100.0%; Average loss: 8.9827\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "<style>\n",
              "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
              "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
              "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
              "    </style>\n",
              "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>loss</td><td>█▅▃▂▁▆▃▄▆▅▂▃▄▄▂▃▄▆▅▄▅▆▅▃█▃▆▂▄▅▅▂▄▅▅▅▄▂▅▆</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>loss</td><td>8.98237</td></tr></table><br/></div></div>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              " View run <strong style=\"color:#cdcd00\">young-sweep-15</strong> at: <a href='https://wandb.ai/nyu-hpml/hpml-chatbot/runs/saa7wvwi' target=\"_blank\">https://wandb.ai/nyu-hpml/hpml-chatbot/runs/saa7wvwi</a><br/> View project at: <a href='https://wandb.ai/nyu-hpml/hpml-chatbot' target=\"_blank\">https://wandb.ai/nyu-hpml/hpml-chatbot</a><br/>Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "Find logs at: <code>./wandb/run-20241024_050141-saa7wvwi/logs</code>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\u001b[34m\u001b[1mwandb\u001b[0m: Agent Starting Run: lbi9olgj with config:\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \tclip: 50\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \tdecoder_learning_ratio: 3\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \tlearning_rate: 0.0005\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \toptimizer: adam\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \tteacher_forcing_ratio: 0.5\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Ignored wandb.init() arg project when running a sweep.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Ignored wandb.init() arg entity when running a sweep.\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "Tracking run with wandb version 0.18.5"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "Run data is saved locally in <code>/content/wandb/run-20241024_050519-lbi9olgj</code>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "Syncing run <strong><a href='https://wandb.ai/nyu-hpml/hpml-chatbot/runs/lbi9olgj' target=\"_blank\">northern-sweep-16</a></strong> to <a href='https://wandb.ai/nyu-hpml/hpml-chatbot' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>Sweep page: <a href='https://wandb.ai/nyu-hpml/hpml-chatbot/sweeps/gv10awn2' target=\"_blank\">https://wandb.ai/nyu-hpml/hpml-chatbot/sweeps/gv10awn2</a>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              " View project at <a href='https://wandb.ai/nyu-hpml/hpml-chatbot' target=\"_blank\">https://wandb.ai/nyu-hpml/hpml-chatbot</a>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              " View sweep at <a href='https://wandb.ai/nyu-hpml/hpml-chatbot/sweeps/gv10awn2' target=\"_blank\">https://wandb.ai/nyu-hpml/hpml-chatbot/sweeps/gv10awn2</a>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              " View run at <a href='https://wandb.ai/nyu-hpml/hpml-chatbot/runs/lbi9olgj' target=\"_blank\">https://wandb.ai/nyu-hpml/hpml-chatbot/runs/lbi9olgj</a>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Building encoder and decoder ...\n",
            "Models built and ready to go!\n",
            "Building optimizers ...\n",
            "Starting Training!\n",
            "Initializing ...\n",
            "Training...\n",
            "Iteration: 1000; Percent complete: 25.0%; Average loss: 4.6219\n",
            "Iteration: 2000; Percent complete: 50.0%; Average loss: 4.0759\n",
            "Iteration: 3000; Percent complete: 75.0%; Average loss: 3.7695\n",
            "Iteration: 4000; Percent complete: 100.0%; Average loss: 3.4625\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "<style>\n",
              "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
              "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
              "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
              "    </style>\n",
              "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>loss</td><td>█▆▆▆▆▄▆▄▄▄▅▅▅▃▅▃▃▃▃▂▅▅▃▂▅▄▄▂▁▂▁▄▁▄▄▄▄▃▁▁</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>loss</td><td>3.62506</td></tr></table><br/></div></div>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              " View run <strong style=\"color:#cdcd00\">northern-sweep-16</strong> at: <a href='https://wandb.ai/nyu-hpml/hpml-chatbot/runs/lbi9olgj' target=\"_blank\">https://wandb.ai/nyu-hpml/hpml-chatbot/runs/lbi9olgj</a><br/> View project at: <a href='https://wandb.ai/nyu-hpml/hpml-chatbot' target=\"_blank\">https://wandb.ai/nyu-hpml/hpml-chatbot</a><br/>Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "Find logs at: <code>./wandb/run-20241024_050519-lbi9olgj/logs</code>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\u001b[34m\u001b[1mwandb\u001b[0m: Agent Starting Run: m32thjkw with config:\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \tclip: 50\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \tdecoder_learning_ratio: 1\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \tlearning_rate: 0.0005\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \toptimizer: adam\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \tteacher_forcing_ratio: 0\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Ignored wandb.init() arg project when running a sweep.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Ignored wandb.init() arg entity when running a sweep.\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "Tracking run with wandb version 0.18.5"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "Run data is saved locally in <code>/content/wandb/run-20241024_050902-m32thjkw</code>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "Syncing run <strong><a href='https://wandb.ai/nyu-hpml/hpml-chatbot/runs/m32thjkw' target=\"_blank\">spring-sweep-17</a></strong> to <a href='https://wandb.ai/nyu-hpml/hpml-chatbot' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>Sweep page: <a href='https://wandb.ai/nyu-hpml/hpml-chatbot/sweeps/gv10awn2' target=\"_blank\">https://wandb.ai/nyu-hpml/hpml-chatbot/sweeps/gv10awn2</a>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              " View project at <a href='https://wandb.ai/nyu-hpml/hpml-chatbot' target=\"_blank\">https://wandb.ai/nyu-hpml/hpml-chatbot</a>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              " View sweep at <a href='https://wandb.ai/nyu-hpml/hpml-chatbot/sweeps/gv10awn2' target=\"_blank\">https://wandb.ai/nyu-hpml/hpml-chatbot/sweeps/gv10awn2</a>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              " View run at <a href='https://wandb.ai/nyu-hpml/hpml-chatbot/runs/m32thjkw' target=\"_blank\">https://wandb.ai/nyu-hpml/hpml-chatbot/runs/m32thjkw</a>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Building encoder and decoder ...\n",
            "Models built and ready to go!\n",
            "Building optimizers ...\n",
            "Starting Training!\n",
            "Initializing ...\n",
            "Training...\n",
            "Iteration: 1000; Percent complete: 25.0%; Average loss: 4.7667\n",
            "Iteration: 2000; Percent complete: 50.0%; Average loss: 4.5798\n",
            "Iteration: 3000; Percent complete: 75.0%; Average loss: 4.4487\n",
            "Iteration: 4000; Percent complete: 100.0%; Average loss: 4.2706\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "<style>\n",
              "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
              "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
              "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
              "    </style>\n",
              "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>loss</td><td>█▇▇▇▆▆▆▆▅▆▇▅▅▆▄▆▄▅▅▅▄▄▄▅▄▅▄▃▅▃▄▃▄▂▂▂▃▃▃▁</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>loss</td><td>4.24082</td></tr></table><br/></div></div>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              " View run <strong style=\"color:#cdcd00\">spring-sweep-17</strong> at: <a href='https://wandb.ai/nyu-hpml/hpml-chatbot/runs/m32thjkw' target=\"_blank\">https://wandb.ai/nyu-hpml/hpml-chatbot/runs/m32thjkw</a><br/> View project at: <a href='https://wandb.ai/nyu-hpml/hpml-chatbot' target=\"_blank\">https://wandb.ai/nyu-hpml/hpml-chatbot</a><br/>Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "Find logs at: <code>./wandb/run-20241024_050902-m32thjkw/logs</code>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\u001b[34m\u001b[1mwandb\u001b[0m: Agent Starting Run: srxegavg with config:\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \tclip: 50\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \tdecoder_learning_ratio: 3\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \tlearning_rate: 0.0001\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \toptimizer: sgd\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \tteacher_forcing_ratio: 0.5\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Ignored wandb.init() arg project when running a sweep.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Ignored wandb.init() arg entity when running a sweep.\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "Tracking run with wandb version 0.18.5"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "Run data is saved locally in <code>/content/wandb/run-20241024_051306-srxegavg</code>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "Syncing run <strong><a href='https://wandb.ai/nyu-hpml/hpml-chatbot/runs/srxegavg' target=\"_blank\">cerulean-sweep-18</a></strong> to <a href='https://wandb.ai/nyu-hpml/hpml-chatbot' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>Sweep page: <a href='https://wandb.ai/nyu-hpml/hpml-chatbot/sweeps/gv10awn2' target=\"_blank\">https://wandb.ai/nyu-hpml/hpml-chatbot/sweeps/gv10awn2</a>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              " View project at <a href='https://wandb.ai/nyu-hpml/hpml-chatbot' target=\"_blank\">https://wandb.ai/nyu-hpml/hpml-chatbot</a>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              " View sweep at <a href='https://wandb.ai/nyu-hpml/hpml-chatbot/sweeps/gv10awn2' target=\"_blank\">https://wandb.ai/nyu-hpml/hpml-chatbot/sweeps/gv10awn2</a>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              " View run at <a href='https://wandb.ai/nyu-hpml/hpml-chatbot/runs/srxegavg' target=\"_blank\">https://wandb.ai/nyu-hpml/hpml-chatbot/runs/srxegavg</a>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Building encoder and decoder ...\n",
            "Models built and ready to go!\n",
            "Building optimizers ...\n",
            "Starting Training!\n",
            "Initializing ...\n",
            "Training...\n",
            "Iteration: 1000; Percent complete: 25.0%; Average loss: 7.0867\n",
            "Iteration: 2000; Percent complete: 50.0%; Average loss: 5.6834\n",
            "Iteration: 3000; Percent complete: 75.0%; Average loss: 5.2767\n",
            "Iteration: 4000; Percent complete: 100.0%; Average loss: 5.0796\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "<style>\n",
              "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
              "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
              "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
              "    </style>\n",
              "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>loss</td><td>██▇▄▅▄▄▄▃▄▃▃▃▃▂▂▂▂▂▂▂▂▂▂▁▂▂▁▁▂▂▁▂▂▁▁▁▂▁▁</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>loss</td><td>4.80389</td></tr></table><br/></div></div>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              " View run <strong style=\"color:#cdcd00\">cerulean-sweep-18</strong> at: <a href='https://wandb.ai/nyu-hpml/hpml-chatbot/runs/srxegavg' target=\"_blank\">https://wandb.ai/nyu-hpml/hpml-chatbot/runs/srxegavg</a><br/> View project at: <a href='https://wandb.ai/nyu-hpml/hpml-chatbot' target=\"_blank\">https://wandb.ai/nyu-hpml/hpml-chatbot</a><br/>Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "Find logs at: <code>./wandb/run-20241024_051306-srxegavg/logs</code>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\u001b[34m\u001b[1mwandb\u001b[0m: Agent Starting Run: 5c6ud02d with config:\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \tclip: 100\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \tdecoder_learning_ratio: 3\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \tlearning_rate: 0.001\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \toptimizer: adam\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \tteacher_forcing_ratio: 1\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Ignored wandb.init() arg project when running a sweep.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Ignored wandb.init() arg entity when running a sweep.\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "Tracking run with wandb version 0.18.5"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "Run data is saved locally in <code>/content/wandb/run-20241024_051623-5c6ud02d</code>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "Syncing run <strong><a href='https://wandb.ai/nyu-hpml/hpml-chatbot/runs/5c6ud02d' target=\"_blank\">stoic-sweep-19</a></strong> to <a href='https://wandb.ai/nyu-hpml/hpml-chatbot' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>Sweep page: <a href='https://wandb.ai/nyu-hpml/hpml-chatbot/sweeps/gv10awn2' target=\"_blank\">https://wandb.ai/nyu-hpml/hpml-chatbot/sweeps/gv10awn2</a>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              " View project at <a href='https://wandb.ai/nyu-hpml/hpml-chatbot' target=\"_blank\">https://wandb.ai/nyu-hpml/hpml-chatbot</a>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              " View sweep at <a href='https://wandb.ai/nyu-hpml/hpml-chatbot/sweeps/gv10awn2' target=\"_blank\">https://wandb.ai/nyu-hpml/hpml-chatbot/sweeps/gv10awn2</a>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              " View run at <a href='https://wandb.ai/nyu-hpml/hpml-chatbot/runs/5c6ud02d' target=\"_blank\">https://wandb.ai/nyu-hpml/hpml-chatbot/runs/5c6ud02d</a>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Building encoder and decoder ...\n",
            "Models built and ready to go!\n",
            "Building optimizers ...\n",
            "Starting Training!\n",
            "Initializing ...\n",
            "Training...\n",
            "Iteration: 1000; Percent complete: 25.0%; Average loss: 4.1190\n",
            "Iteration: 2000; Percent complete: 50.0%; Average loss: 3.5663\n",
            "Iteration: 3000; Percent complete: 75.0%; Average loss: 3.3127\n",
            "Iteration: 4000; Percent complete: 100.0%; Average loss: 3.1376\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "<style>\n",
              "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
              "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
              "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
              "    </style>\n",
              "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>loss</td><td>█▆▄▆▅▅▅▅▅▅▃▄▄▃▄▃▃▅▃▃▂▃▃▃▂▃▂▃▃▂▂▂▃▂▃▂▃▃▃▁</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>loss</td><td>3.28074</td></tr></table><br/></div></div>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              " View run <strong style=\"color:#cdcd00\">stoic-sweep-19</strong> at: <a href='https://wandb.ai/nyu-hpml/hpml-chatbot/runs/5c6ud02d' target=\"_blank\">https://wandb.ai/nyu-hpml/hpml-chatbot/runs/5c6ud02d</a><br/> View project at: <a href='https://wandb.ai/nyu-hpml/hpml-chatbot' target=\"_blank\">https://wandb.ai/nyu-hpml/hpml-chatbot</a><br/>Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "Find logs at: <code>./wandb/run-20241024_051623-5c6ud02d/logs</code>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\u001b[34m\u001b[1mwandb\u001b[0m: Agent Starting Run: ytbavdsy with config:\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \tclip: 25\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \tdecoder_learning_ratio: 1\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \tlearning_rate: 0.00025\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \toptimizer: adam\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \tteacher_forcing_ratio: 0.5\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Ignored wandb.init() arg project when running a sweep.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Ignored wandb.init() arg entity when running a sweep.\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "Tracking run with wandb version 0.18.5"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "Run data is saved locally in <code>/content/wandb/run-20241024_051948-ytbavdsy</code>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "Syncing run <strong><a href='https://wandb.ai/nyu-hpml/hpml-chatbot/runs/ytbavdsy' target=\"_blank\">divine-sweep-20</a></strong> to <a href='https://wandb.ai/nyu-hpml/hpml-chatbot' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>Sweep page: <a href='https://wandb.ai/nyu-hpml/hpml-chatbot/sweeps/gv10awn2' target=\"_blank\">https://wandb.ai/nyu-hpml/hpml-chatbot/sweeps/gv10awn2</a>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              " View project at <a href='https://wandb.ai/nyu-hpml/hpml-chatbot' target=\"_blank\">https://wandb.ai/nyu-hpml/hpml-chatbot</a>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              " View sweep at <a href='https://wandb.ai/nyu-hpml/hpml-chatbot/sweeps/gv10awn2' target=\"_blank\">https://wandb.ai/nyu-hpml/hpml-chatbot/sweeps/gv10awn2</a>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              " View run at <a href='https://wandb.ai/nyu-hpml/hpml-chatbot/runs/ytbavdsy' target=\"_blank\">https://wandb.ai/nyu-hpml/hpml-chatbot/runs/ytbavdsy</a>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Building encoder and decoder ...\n",
            "Models built and ready to go!\n",
            "Building optimizers ...\n",
            "Starting Training!\n",
            "Initializing ...\n",
            "Training...\n",
            "Iteration: 1000; Percent complete: 25.0%; Average loss: 4.5678\n",
            "Iteration: 2000; Percent complete: 50.0%; Average loss: 4.2062\n",
            "Iteration: 3000; Percent complete: 75.0%; Average loss: 4.0256\n",
            "Iteration: 4000; Percent complete: 100.0%; Average loss: 3.9041\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "<style>\n",
              "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
              "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
              "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
              "    </style>\n",
              "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>loss</td><td>█▄▄▄▃▃▃▃▄▃▃▃▂▃▃▄▄▄▂▂▂▂▄▄▄▃▄▃▂▂▄▂▃▁▂▁▁▄▁▁</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>loss</td><td>3.29276</td></tr></table><br/></div></div>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              " View run <strong style=\"color:#cdcd00\">divine-sweep-20</strong> at: <a href='https://wandb.ai/nyu-hpml/hpml-chatbot/runs/ytbavdsy' target=\"_blank\">https://wandb.ai/nyu-hpml/hpml-chatbot/runs/ytbavdsy</a><br/> View project at: <a href='https://wandb.ai/nyu-hpml/hpml-chatbot' target=\"_blank\">https://wandb.ai/nyu-hpml/hpml-chatbot</a><br/>Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "Find logs at: <code>./wandb/run-20241024_051948-ytbavdsy/logs</code>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\u001b[34m\u001b[1mwandb\u001b[0m: Agent Starting Run: 0v2a6d91 with config:\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \tclip: 25\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \tdecoder_learning_ratio: 5\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \tlearning_rate: 0.00025\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \toptimizer: adam\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \tteacher_forcing_ratio: 1\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Ignored wandb.init() arg project when running a sweep.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Ignored wandb.init() arg entity when running a sweep.\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "Tracking run with wandb version 0.18.5"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "Run data is saved locally in <code>/content/wandb/run-20241024_052332-0v2a6d91</code>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "Syncing run <strong><a href='https://wandb.ai/nyu-hpml/hpml-chatbot/runs/0v2a6d91' target=\"_blank\">noble-sweep-21</a></strong> to <a href='https://wandb.ai/nyu-hpml/hpml-chatbot' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>Sweep page: <a href='https://wandb.ai/nyu-hpml/hpml-chatbot/sweeps/gv10awn2' target=\"_blank\">https://wandb.ai/nyu-hpml/hpml-chatbot/sweeps/gv10awn2</a>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              " View project at <a href='https://wandb.ai/nyu-hpml/hpml-chatbot' target=\"_blank\">https://wandb.ai/nyu-hpml/hpml-chatbot</a>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              " View sweep at <a href='https://wandb.ai/nyu-hpml/hpml-chatbot/sweeps/gv10awn2' target=\"_blank\">https://wandb.ai/nyu-hpml/hpml-chatbot/sweeps/gv10awn2</a>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              " View run at <a href='https://wandb.ai/nyu-hpml/hpml-chatbot/runs/0v2a6d91' target=\"_blank\">https://wandb.ai/nyu-hpml/hpml-chatbot/runs/0v2a6d91</a>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Building encoder and decoder ...\n",
            "Models built and ready to go!\n",
            "Building optimizers ...\n",
            "Starting Training!\n",
            "Initializing ...\n",
            "Training...\n",
            "Iteration: 1000; Percent complete: 25.0%; Average loss: 3.7541\n",
            "Iteration: 2000; Percent complete: 50.0%; Average loss: 3.0946\n",
            "Iteration: 3000; Percent complete: 75.0%; Average loss: 2.6655\n",
            "Iteration: 4000; Percent complete: 100.0%; Average loss: 2.3014\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "<style>\n",
              "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
              "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
              "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
              "    </style>\n",
              "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>loss</td><td>█▇▇▇▇▆▇▆▄▄▅▄▄▄▄▄▄▄▄▄▃▃▃▂▃▂▁▃▂▂▂▂▂▂▂▁▂▂▂▁</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>loss</td><td>2.07931</td></tr></table><br/></div></div>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              " View run <strong style=\"color:#cdcd00\">noble-sweep-21</strong> at: <a href='https://wandb.ai/nyu-hpml/hpml-chatbot/runs/0v2a6d91' target=\"_blank\">https://wandb.ai/nyu-hpml/hpml-chatbot/runs/0v2a6d91</a><br/> View project at: <a href='https://wandb.ai/nyu-hpml/hpml-chatbot' target=\"_blank\">https://wandb.ai/nyu-hpml/hpml-chatbot</a><br/>Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "Find logs at: <code>./wandb/run-20241024_052332-0v2a6d91/logs</code>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\u001b[34m\u001b[1mwandb\u001b[0m: Agent Starting Run: gu21tst0 with config:\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \tclip: 0\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \tdecoder_learning_ratio: 3\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \tlearning_rate: 0.001\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \toptimizer: adam\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \tteacher_forcing_ratio: 0\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Ignored wandb.init() arg project when running a sweep.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Ignored wandb.init() arg entity when running a sweep.\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "Tracking run with wandb version 0.18.5"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "Run data is saved locally in <code>/content/wandb/run-20241024_052700-gu21tst0</code>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "Syncing run <strong><a href='https://wandb.ai/nyu-hpml/hpml-chatbot/runs/gu21tst0' target=\"_blank\">denim-sweep-22</a></strong> to <a href='https://wandb.ai/nyu-hpml/hpml-chatbot' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>Sweep page: <a href='https://wandb.ai/nyu-hpml/hpml-chatbot/sweeps/gv10awn2' target=\"_blank\">https://wandb.ai/nyu-hpml/hpml-chatbot/sweeps/gv10awn2</a>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              " View project at <a href='https://wandb.ai/nyu-hpml/hpml-chatbot' target=\"_blank\">https://wandb.ai/nyu-hpml/hpml-chatbot</a>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              " View sweep at <a href='https://wandb.ai/nyu-hpml/hpml-chatbot/sweeps/gv10awn2' target=\"_blank\">https://wandb.ai/nyu-hpml/hpml-chatbot/sweeps/gv10awn2</a>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              " View run at <a href='https://wandb.ai/nyu-hpml/hpml-chatbot/runs/gu21tst0' target=\"_blank\">https://wandb.ai/nyu-hpml/hpml-chatbot/runs/gu21tst0</a>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Building encoder and decoder ...\n",
            "Models built and ready to go!\n",
            "Building optimizers ...\n",
            "Starting Training!\n",
            "Initializing ...\n",
            "Training...\n",
            "Iteration: 1000; Percent complete: 25.0%; Average loss: 8.9636\n",
            "Iteration: 2000; Percent complete: 50.0%; Average loss: 8.9637\n",
            "Iteration: 3000; Percent complete: 75.0%; Average loss: 8.9637\n",
            "Iteration: 4000; Percent complete: 100.0%; Average loss: 8.9636\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "<style>\n",
              "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
              "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
              "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
              "    </style>\n",
              "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>loss</td><td>▃▆▄▄▅▃▅▃▄▃▃▅▂▇▂▅▄▃▅▄▄▄█▅▅▅▃▁▅▄▄▃▆▆▇▇▇▅▄▂</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>loss</td><td>8.96125</td></tr></table><br/></div></div>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              " View run <strong style=\"color:#cdcd00\">denim-sweep-22</strong> at: <a href='https://wandb.ai/nyu-hpml/hpml-chatbot/runs/gu21tst0' target=\"_blank\">https://wandb.ai/nyu-hpml/hpml-chatbot/runs/gu21tst0</a><br/> View project at: <a href='https://wandb.ai/nyu-hpml/hpml-chatbot' target=\"_blank\">https://wandb.ai/nyu-hpml/hpml-chatbot</a><br/>Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Find logs at: <code>./wandb/run-20241024_052700-gu21tst0/logs</code>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[34m\u001b[1mwandb\u001b[0m: Agent Starting Run: 30631d1e with config:\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \tclip: 0\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \tdecoder_learning_ratio: 1\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \tlearning_rate: 0.0001\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \toptimizer: sgd\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \tteacher_forcing_ratio: 0.5\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Ignored wandb.init() arg project when running a sweep.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Ignored wandb.init() arg entity when running a sweep.\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Tracking run with wandb version 0.18.5"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Run data is saved locally in <code>/content/wandb/run-20241024_053104-30631d1e</code>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Syncing run <strong><a href='https://wandb.ai/nyu-hpml/hpml-chatbot/runs/30631d1e' target=\"_blank\">crimson-sweep-23</a></strong> to <a href='https://wandb.ai/nyu-hpml/hpml-chatbot' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>Sweep page: <a href='https://wandb.ai/nyu-hpml/hpml-chatbot/sweeps/gv10awn2' target=\"_blank\">https://wandb.ai/nyu-hpml/hpml-chatbot/sweeps/gv10awn2</a>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              " View project at <a href='https://wandb.ai/nyu-hpml/hpml-chatbot' target=\"_blank\">https://wandb.ai/nyu-hpml/hpml-chatbot</a>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              " View sweep at <a href='https://wandb.ai/nyu-hpml/hpml-chatbot/sweeps/gv10awn2' target=\"_blank\">https://wandb.ai/nyu-hpml/hpml-chatbot/sweeps/gv10awn2</a>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              " View run at <a href='https://wandb.ai/nyu-hpml/hpml-chatbot/runs/30631d1e' target=\"_blank\">https://wandb.ai/nyu-hpml/hpml-chatbot/runs/30631d1e</a>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Building encoder and decoder ...\n",
            "Models built and ready to go!\n",
            "Building optimizers ...\n",
            "Starting Training!\n",
            "Initializing ...\n",
            "Training...\n",
            "Iteration: 1000; Percent complete: 25.0%; Average loss: 8.9707\n",
            "Iteration: 2000; Percent complete: 50.0%; Average loss: 8.9708\n",
            "Iteration: 3000; Percent complete: 75.0%; Average loss: 8.9708\n",
            "Iteration: 4000; Percent complete: 100.0%; Average loss: 8.9706\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "<style>\n",
              "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
              "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
              "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
              "    </style>\n",
              "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>loss</td><td>▅█▇▂▁▇▃▄▃▄▂█▇▄▄▆▃▆▇▅▄▅▅█▄▅▄▅▅▂▄▄▆▃▅▇▅▅▆▃</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>loss</td><td>8.96898</td></tr></table><br/></div></div>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              " View run <strong style=\"color:#cdcd00\">crimson-sweep-23</strong> at: <a href='https://wandb.ai/nyu-hpml/hpml-chatbot/runs/30631d1e' target=\"_blank\">https://wandb.ai/nyu-hpml/hpml-chatbot/runs/30631d1e</a><br/> View project at: <a href='https://wandb.ai/nyu-hpml/hpml-chatbot' target=\"_blank\">https://wandb.ai/nyu-hpml/hpml-chatbot</a><br/>Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Find logs at: <code>./wandb/run-20241024_053104-30631d1e/logs</code>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[34m\u001b[1mwandb\u001b[0m: Agent Starting Run: hd02ryps with config:\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \tclip: 100\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \tdecoder_learning_ratio: 1\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \tlearning_rate: 0.0001\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \toptimizer: sgd\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \tteacher_forcing_ratio: 0\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Ignored wandb.init() arg project when running a sweep.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Ignored wandb.init() arg entity when running a sweep.\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Tracking run with wandb version 0.18.5"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Run data is saved locally in <code>/content/wandb/run-20241024_053422-hd02ryps</code>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Syncing run <strong><a href='https://wandb.ai/nyu-hpml/hpml-chatbot/runs/hd02ryps' target=\"_blank\">clear-sweep-24</a></strong> to <a href='https://wandb.ai/nyu-hpml/hpml-chatbot' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>Sweep page: <a href='https://wandb.ai/nyu-hpml/hpml-chatbot/sweeps/gv10awn2' target=\"_blank\">https://wandb.ai/nyu-hpml/hpml-chatbot/sweeps/gv10awn2</a>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              " View project at <a href='https://wandb.ai/nyu-hpml/hpml-chatbot' target=\"_blank\">https://wandb.ai/nyu-hpml/hpml-chatbot</a>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              " View sweep at <a href='https://wandb.ai/nyu-hpml/hpml-chatbot/sweeps/gv10awn2' target=\"_blank\">https://wandb.ai/nyu-hpml/hpml-chatbot/sweeps/gv10awn2</a>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              " View run at <a href='https://wandb.ai/nyu-hpml/hpml-chatbot/runs/hd02ryps' target=\"_blank\">https://wandb.ai/nyu-hpml/hpml-chatbot/runs/hd02ryps</a>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Building encoder and decoder ...\n",
            "Models built and ready to go!\n",
            "Building optimizers ...\n",
            "Starting Training!\n",
            "Initializing ...\n",
            "Training...\n",
            "Iteration: 1000; Percent complete: 25.0%; Average loss: 7.8085\n",
            "Iteration: 2000; Percent complete: 50.0%; Average loss: 6.4499\n",
            "Iteration: 3000; Percent complete: 75.0%; Average loss: 6.0513\n",
            "Iteration: 4000; Percent complete: 100.0%; Average loss: 5.7692\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "<style>\n",
              "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
              "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
              "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
              "    </style>\n",
              "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>loss</td><td>█████▇▅▃▃▃▃▄▃▃▃▂▂▂▂▂▂▂▂▁▂▂▂▂▂▂▁▂▂▁▁▁▁▁▁▁</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>loss</td><td>5.74151</td></tr></table><br/></div></div>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              " View run <strong style=\"color:#cdcd00\">clear-sweep-24</strong> at: <a href='https://wandb.ai/nyu-hpml/hpml-chatbot/runs/hd02ryps' target=\"_blank\">https://wandb.ai/nyu-hpml/hpml-chatbot/runs/hd02ryps</a><br/> View project at: <a href='https://wandb.ai/nyu-hpml/hpml-chatbot' target=\"_blank\">https://wandb.ai/nyu-hpml/hpml-chatbot</a><br/>Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Find logs at: <code>./wandb/run-20241024_053422-hd02ryps/logs</code>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[34m\u001b[1mwandb\u001b[0m: Agent Starting Run: o74esbax with config:\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \tclip: 0\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \tdecoder_learning_ratio: 5\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \tlearning_rate: 0.0005\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \toptimizer: adam\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \tteacher_forcing_ratio: 0.5\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Ignored wandb.init() arg project when running a sweep.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Ignored wandb.init() arg entity when running a sweep.\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Tracking run with wandb version 0.18.5"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Run data is saved locally in <code>/content/wandb/run-20241024_053802-o74esbax</code>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Syncing run <strong><a href='https://wandb.ai/nyu-hpml/hpml-chatbot/runs/o74esbax' target=\"_blank\">silver-sweep-25</a></strong> to <a href='https://wandb.ai/nyu-hpml/hpml-chatbot' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>Sweep page: <a href='https://wandb.ai/nyu-hpml/hpml-chatbot/sweeps/gv10awn2' target=\"_blank\">https://wandb.ai/nyu-hpml/hpml-chatbot/sweeps/gv10awn2</a>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              " View project at <a href='https://wandb.ai/nyu-hpml/hpml-chatbot' target=\"_blank\">https://wandb.ai/nyu-hpml/hpml-chatbot</a>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              " View sweep at <a href='https://wandb.ai/nyu-hpml/hpml-chatbot/sweeps/gv10awn2' target=\"_blank\">https://wandb.ai/nyu-hpml/hpml-chatbot/sweeps/gv10awn2</a>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              " View run at <a href='https://wandb.ai/nyu-hpml/hpml-chatbot/runs/o74esbax' target=\"_blank\">https://wandb.ai/nyu-hpml/hpml-chatbot/runs/o74esbax</a>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Building encoder and decoder ...\n",
            "Models built and ready to go!\n",
            "Building optimizers ...\n",
            "Starting Training!\n",
            "Initializing ...\n",
            "Training...\n",
            "Iteration: 1000; Percent complete: 25.0%; Average loss: 8.9786\n",
            "Iteration: 2000; Percent complete: 50.0%; Average loss: 8.9786\n",
            "Iteration: 3000; Percent complete: 75.0%; Average loss: 8.9785\n",
            "Iteration: 4000; Percent complete: 100.0%; Average loss: 8.9786\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "<style>\n",
              "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
              "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
              "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
              "    </style>\n",
              "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>loss</td><td>▆▅▄▅█▅█▅▇▅▇▇▅▄▂▅▄▆▆▆▄▅▃▄▄▇▆▅▄▅▆▄▅▅▅▅█▇▅▁</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>loss</td><td>8.973</td></tr></table><br/></div></div>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              " View run <strong style=\"color:#cdcd00\">silver-sweep-25</strong> at: <a href='https://wandb.ai/nyu-hpml/hpml-chatbot/runs/o74esbax' target=\"_blank\">https://wandb.ai/nyu-hpml/hpml-chatbot/runs/o74esbax</a><br/> View project at: <a href='https://wandb.ai/nyu-hpml/hpml-chatbot' target=\"_blank\">https://wandb.ai/nyu-hpml/hpml-chatbot</a><br/>Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Find logs at: <code>./wandb/run-20241024_053802-o74esbax/logs</code>"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Problem 1.5"
      ],
      "metadata": {
        "id": "r21mE8DeYdiA"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "The best configuration is the one with the lowest loss.\n",
        "\n",
        "Lowest Loss =  2.01315\n",
        "\n",
        "Configuration:\n",
        "\n",
        "- clip = 50\n",
        "- decoder_learning_ratio = 3\n",
        "- learning_rate = 0.0005\n",
        "- optimizer = adam\n",
        "- teacher_forcing_ratio = 1"
      ],
      "metadata": {
        "id": "YMDeyobPbwde"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def run_best_model(clip=50, decoder_learning_ratio=3, learning_rate=0.0005, optimizer='adam', teacher_forcing_ratio=1):\n",
        "    # Configure models\n",
        "    model_name = 'cb_model'\n",
        "    attn_model = 'dot'\n",
        "    hidden_size = 500\n",
        "    encoder_n_layers = 2\n",
        "    decoder_n_layers = 2\n",
        "    dropout = 0.1\n",
        "    batch_size = 64\n",
        "\n",
        "    print('Building encoder and decoder ...')\n",
        "    # Initialize word embeddings\n",
        "    embedding = nn.Embedding(voc.num_words, hidden_size)\n",
        "\n",
        "    # Initialize encoder & decoder models\n",
        "    encoder = EncoderRNN(hidden_size, embedding, encoder_n_layers, dropout)\n",
        "    decoder = LuongAttnDecoderRNN(attn_model, embedding, hidden_size, voc.num_words, decoder_n_layers, dropout)\n",
        "\n",
        "    # Use appropriate device\n",
        "    encoder = encoder.to(device)\n",
        "    decoder = decoder.to(device)\n",
        "    print('Models built and ready to go!')\n",
        "\n",
        "    # Configure training/optimization\n",
        "    clip = clip\n",
        "    teacher_forcing_ratio = teacher_forcing_ratio\n",
        "    learning_rate = learning_rate\n",
        "    decoder_learning_ratio = decoder_learning_ratio\n",
        "    n_iteration = 4000\n",
        "    # Changed to not populate the entire console with loss outputs\n",
        "    print_every = 500\n",
        "    save_every = 1000\n",
        "\n",
        "    # Ensure dropout layers are in train mode\n",
        "    encoder.train()\n",
        "    decoder.train()\n",
        "\n",
        "    # Initialize optimizers\n",
        "    print('Building optimizers ...')\n",
        "    if optimizer == 'adam':\n",
        "        encoder_optimizer = optim.Adam(encoder.parameters(), lr=learning_rate)\n",
        "        decoder_optimizer = optim.Adam(decoder.parameters(), lr=learning_rate * decoder_learning_ratio)\n",
        "    elif optimizer == 'sgd':\n",
        "        encoder_optimizer = optim.SGD(encoder.parameters(), lr=learning_rate)\n",
        "        decoder_optimizer = optim.SGD(decoder.parameters(), lr=learning_rate * decoder_learning_ratio)\n",
        "\n",
        "    # If you have CUDA, configure CUDA to call\n",
        "    for state in encoder_optimizer.state.values():\n",
        "        for k, v in state.items():\n",
        "            if isinstance(v, torch.Tensor):\n",
        "                state[k] = v.cuda()\n",
        "\n",
        "    for state in decoder_optimizer.state.values():\n",
        "        for k, v in state.items():\n",
        "            if isinstance(v, torch.Tensor):\n",
        "                state[k] = v.cuda()\n",
        "\n",
        "    # Run training iterations\n",
        "    print(\"Starting Training!\")\n",
        "    trainIters(model_name, voc, pairs, encoder, decoder, encoder_optimizer, decoder_optimizer,\n",
        "            embedding, encoder_n_layers, decoder_n_layers, save_dir, n_iteration, batch_size,\n",
        "            print_every, save_every, clip, teacher_forcing_ratio, hidden_size, corpus_name)\n",
        "\n",
        "    return encoder, decoder"
      ],
      "metadata": {
        "id": "9JWYfxmdCow0"
      },
      "execution_count": 30,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "best_model_enc, best_model_dec = run_best_model()"
      ],
      "metadata": {
        "id": "1FQOn0iRLqqf",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "4d89bc54-6e67-4abe-a9a4-7214c8393389"
      },
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Building encoder and decoder ...\n",
            "Models built and ready to go!\n",
            "Building optimizers ...\n",
            "Starting Training!\n",
            "Initializing ...\n",
            "Training...\n",
            "Iteration: 500; Percent complete: 12.5%; Average loss: 4.0238\n",
            "Iteration: 1000; Percent complete: 25.0%; Average loss: 3.4242\n",
            "Iteration: 1500; Percent complete: 37.5%; Average loss: 3.1569\n",
            "Iteration: 2000; Percent complete: 50.0%; Average loss: 2.8885\n",
            "Iteration: 2500; Percent complete: 62.5%; Average loss: 2.6317\n",
            "Iteration: 3000; Percent complete: 75.0%; Average loss: 2.4166\n",
            "Iteration: 3500; Percent complete: 87.5%; Average loss: 2.2310\n",
            "Iteration: 4000; Percent complete: 100.0%; Average loss: 2.0535\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Problem 1.6-1.7"
      ],
      "metadata": {
        "id": "2mSnLfy5-07o"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Importing libraries"
      ],
      "metadata": {
        "id": "JtpwgX4ZfGGk"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from torch.profiler import profile, record_function, ProfilerActivity"
      ],
      "metadata": {
        "id": "udTSyWubdwjR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Profiling CPU Time and CUDA Time"
      ],
      "metadata": {
        "id": "nvn-KIMGMJ4B"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "best_model_enc.eval()\n",
        "best_model_dec.eval()\n",
        "\n",
        "input_sentence = 'hello how are you?'\n",
        "print('> ' + input_sentence)\n",
        "\n",
        "input_sentence = normalizeString(input_sentence)\n",
        "best_model_searcher = GreedySearchDecoder(best_model_enc, best_model_dec)\n",
        "\n",
        "with profile(activities=[ProfilerActivity.CPU, ProfilerActivity.CUDA], profile_memory=True, record_shapes=True) as prof:\n",
        "    with record_function(\"model_inference\"):\n",
        "        output_words = evaluate(best_model_searcher, voc, input_sentence)\n",
        "        output_words[:] = [x for x in output_words if not (x == 'EOS' or x == 'PAD')]\n",
        "        print('Bot:', ' '.join(output_words))"
      ],
      "metadata": {
        "id": "bvtPK2difI71"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(prof.key_averages().table(sort_by=\"cpu_time_total\", row_limit=10))"
      ],
      "metadata": {
        "id": "_Rxy35XTMFbQ",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "5f9f43da-88af-475e-c5f5-772d83a7f502"
      },
      "execution_count": 34,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "-------------------------------------------------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  \n",
            "                                                   Name    Self CPU %      Self CPU   CPU total %     CPU total  CPU time avg     Self CUDA   Self CUDA %    CUDA total  CUDA time avg       CPU Mem  Self CPU Mem      CUDA Mem  Self CUDA Mem    # of Calls  \n",
            "-------------------------------------------------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  \n",
            "                                        model_inference        50.86%      20.131ms        99.92%      39.549ms      39.549ms       0.000us         0.00%       4.342ms       4.342ms           0 b      -7.96 Kb           0 b      -1.03 Mb             1  \n",
            "                                              aten::gru         2.21%     874.298us        28.95%      11.458ms       1.042ms       0.000us         0.00%       2.493ms     226.644us           0 b           0 b      91.50 Kb           0 b            11  \n",
            "                                       aten::_cudnn_rnn         4.17%       1.651ms        25.98%      10.283ms     934.841us       2.493ms        57.41%       2.493ms     226.644us           0 b           0 b      91.50 Kb    -344.74 Mb            11  \n",
            "cudaOccupancyMaxActiveBlocksPerMultiprocessorWithFla...        18.07%       7.153ms        18.07%       7.153ms       3.577ms       0.000us         0.00%       0.000us       0.000us           0 b           0 b           0 b           0 b             2  \n",
            "                                       cudaLaunchKernel         5.15%       2.038ms         5.15%       2.038ms       8.184us       0.000us         0.00%       0.000us       0.000us           0 b           0 b           0 b           0 b           249  \n",
            "                                           aten::linear         0.23%      91.267us         3.02%       1.195ms      59.772us       0.000us         0.00%       1.053ms      52.644us           0 b           0 b     330.00 Kb           0 b            20  \n",
            "                                               aten::to         2.04%     807.574us         2.54%       1.005ms     167.574us       0.000us         0.00%       2.015us       0.336us           0 b           0 b       8.50 Kb           0 b             6  \n",
            "                                              aten::cat         1.58%     623.918us         2.31%     914.293us      29.493us     137.087us         3.16%     137.087us       4.422us           0 b           0 b      62.00 Kb      62.00 Kb            31  \n",
            "                                            aten::addmm         1.80%     712.815us         2.27%     899.872us      44.994us       1.053ms        24.25%       1.053ms      52.644us           0 b           0 b     330.00 Kb     330.00 Kb            20  \n",
            "                                        aten::embedding         0.45%     176.511us         1.94%     768.702us      69.882us       0.000us         0.00%      61.536us       5.594us           0 b           0 b      32.00 Kb           0 b            11  \n",
            "-------------------------------------------------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  \n",
            "Self CPU time total: 39.582ms\n",
            "Self CUDA time total: 4.342ms\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(prof.key_averages(group_by_input_shape=True).table(sort_by=\"cpu_time_total\", row_limit=10))"
      ],
      "metadata": {
        "id": "67uFCYddL_EN",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "affe5a8c-9209-4bbc-9036-ad3f2936dea9"
      },
      "execution_count": 35,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "-------------------------------------------------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  --------------------------------------------------------------------------------  \n",
            "                                                   Name    Self CPU %      Self CPU   CPU total %     CPU total  CPU time avg     Self CUDA   Self CUDA %    CUDA total  CUDA time avg       CPU Mem  Self CPU Mem      CUDA Mem  Self CUDA Mem    # of Calls                                                                      Input Shapes  \n",
            "-------------------------------------------------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  --------------------------------------------------------------------------------  \n",
            "                                        model_inference        50.86%      20.131ms        99.92%      39.549ms      39.549ms       0.000us         0.00%       4.342ms       4.342ms           0 b      -7.96 Kb           0 b      -1.03 Mb             1                                                                                []  \n",
            "                                              aten::gru         1.01%     400.283us        21.49%       8.508ms       8.508ms       0.000us         0.00%       1.281ms       1.281ms           0 b           0 b      31.50 Kb           0 b             1                              [[6, 500], [6], [4, 1, 500], [], [], [], [], [], []]  \n",
            "                                       aten::_cudnn_rnn         1.16%     458.454us        20.34%       8.049ms       8.049ms       1.281ms        29.51%       1.281ms       1.281ms           0 b           0 b      31.50 Kb     -60.76 Mb             1  [[6, 500], [], [], [7512000], [4, 1, 500], [], [], [], [], [], [], [], [], [], [  \n",
            "cudaOccupancyMaxActiveBlocksPerMultiprocessorWithFla...        18.07%       7.153ms        18.07%       7.153ms       3.577ms       0.000us         0.00%       0.000us       0.000us           0 b           0 b           0 b           0 b             2                                                                                []  \n",
            "                                              aten::gru         1.20%     474.015us         7.45%       2.950ms     294.986us       0.000us         0.00%       1.212ms     121.174us           0 b           0 b      60.00 Kb           0 b            10                            [[1, 1, 500], [2, 1, 500], [], [], [], [], [], [], []]  \n",
            "                                       aten::_cudnn_rnn         3.01%       1.193ms         5.64%       2.234ms     223.391us       1.212ms        27.90%       1.212ms     121.174us           0 b           0 b      60.00 Kb    -283.97 Mb            10  [[1, 1, 500], [], [], [3006000], [2, 1, 500], [], [], [], [], [], [], [], [], []  \n",
            "                                       cudaLaunchKernel         5.15%       2.038ms         5.15%       2.038ms       8.184us       0.000us         0.00%       0.000us       0.000us           0 b           0 b           0 b           0 b           249                                                                                []  \n",
            "                                               aten::to         2.03%     801.883us         2.39%     945.157us     945.157us       0.000us         0.00%       0.735us       0.735us           0 b           0 b         512 b           0 b             1                                              [[6, 1], [], [], [], [], [], [], []]  \n",
            "                                              aten::cat         1.58%     623.918us         2.31%     914.293us      29.493us     137.087us         3.16%     137.087us       4.422us           0 b           0 b      62.00 Kb      62.00 Kb            31                                                                          [[], []]  \n",
            "                                           aten::linear         0.14%      54.852us         1.67%     660.850us      66.085us       0.000us         0.00%     201.307us      20.131us           0 b           0 b      20.00 Kb           0 b            10                                                   [[1, 1000], [500, 1000], [500]]  \n",
            "-------------------------------------------------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  --------------------------------------------------------------------------------  \n",
            "Self CPU time total: 39.582ms\n",
            "Self CUDA time total: 4.342ms\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(prof.key_averages().table(sort_by=\"cuda_time_total\", row_limit=10))"
      ],
      "metadata": {
        "id": "O0dAJ9DML-cs",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "bbe13b06-2d5c-4410-e488-07f0df50a2fa"
      },
      "execution_count": 36,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "-------------------------------------------------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  \n",
            "                                                   Name    Self CPU %      Self CPU   CPU total %     CPU total  CPU time avg     Self CUDA   Self CUDA %    CUDA total  CUDA time avg       CPU Mem  Self CPU Mem      CUDA Mem  Self CUDA Mem    # of Calls  \n",
            "-------------------------------------------------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  \n",
            "                                        model_inference         0.00%       0.000us         0.00%       0.000us       0.000us     122.752ms      2826.77%     122.752ms      13.639ms           0 b           0 b           0 b           0 b             9  \n",
            "                                        model_inference        50.86%      20.131ms        99.92%      39.549ms      39.549ms       0.000us         0.00%       4.342ms       4.342ms           0 b      -7.96 Kb           0 b      -1.03 Mb             1  \n",
            "                                              aten::gru         2.21%     874.298us        28.95%      11.458ms       1.042ms       0.000us         0.00%       2.493ms     226.644us           0 b           0 b      91.50 Kb           0 b            11  \n",
            "                                       aten::_cudnn_rnn         4.17%       1.651ms        25.98%      10.283ms     934.841us       2.493ms        57.41%       2.493ms     226.644us           0 b           0 b      91.50 Kb    -344.74 Mb            11  \n",
            "void gemv2T_kernel_val<int, int, float, float, float...         0.00%       0.000us         0.00%       0.000us       0.000us       1.759ms        40.50%       1.759ms      27.481us           0 b           0 b           0 b           0 b            64  \n",
            "                                           aten::linear         0.23%      91.267us         3.02%       1.195ms      59.772us       0.000us         0.00%       1.053ms      52.644us           0 b           0 b     330.00 Kb           0 b            20  \n",
            "                                            aten::addmm         1.80%     712.815us         2.27%     899.872us      44.994us       1.053ms        24.25%       1.053ms      52.644us           0 b           0 b     330.00 Kb     330.00 Kb            20  \n",
            "void gemv2T_kernel_val<int, int, float, float, float...         0.00%       0.000us         0.00%       0.000us       0.000us     851.563us        19.61%     851.563us      85.156us           0 b           0 b           0 b           0 b            10  \n",
            "void elemWiseRNNcell<float, float, float, (cudnnRNNM...         0.00%       0.000us         0.00%       0.000us       0.000us     412.532us         9.50%     412.532us       9.376us           0 b           0 b           0 b           0 b            44  \n",
            "std::enable_if<!(false), void>::type internal::gemvx...         0.00%       0.000us         0.00%       0.000us       0.000us     201.307us         4.64%     201.307us      20.131us           0 b           0 b           0 b           0 b            10  \n",
            "-------------------------------------------------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  \n",
            "Self CPU time total: 39.582ms\n",
            "Self CUDA time total: 4.342ms\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Profiling CPU Memory and CUDA Memory"
      ],
      "metadata": {
        "id": "6YCCoElQfIp8"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print(prof.key_averages().table(sort_by=\"self_cpu_memory_usage\", row_limit=10))"
      ],
      "metadata": {
        "id": "eyUX73ZrVVnk",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "018d3bc0-cd75-4f40-c3f2-7574f84d5f8b"
      },
      "execution_count": 37,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "-------------------------------------------------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  \n",
            "                                                   Name    Self CPU %      Self CPU   CPU total %     CPU total  CPU time avg     Self CUDA   Self CUDA %    CUDA total  CUDA time avg       CPU Mem  Self CPU Mem      CUDA Mem  Self CUDA Mem    # of Calls  \n",
            "-------------------------------------------------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  \n",
            "                                            aten::empty         1.53%     605.766us         1.53%     605.766us       6.310us       0.000us         0.00%       0.000us       0.000us       7.96 Kb       7.96 Kb     344.85 Mb     344.85 Mb            96  \n",
            "                                               aten::to         2.04%     807.574us         2.54%       1.005ms     167.574us       0.000us         0.00%       2.015us       0.336us           0 b           0 b       8.50 Kb           0 b             6  \n",
            "                                       aten::lift_fresh         0.00%       1.270us         0.00%       1.270us       0.635us       0.000us         0.00%       0.000us       0.000us           0 b           0 b           0 b           0 b             2  \n",
            "                                          aten::detach_         0.02%       6.391us         0.03%      10.254us      10.254us       0.000us         0.00%       0.000us       0.000us           0 b           0 b           0 b           0 b             1  \n",
            "                                                detach_         0.01%       3.863us         0.01%       3.863us       3.863us       0.000us         0.00%       0.000us       0.000us           0 b           0 b           0 b           0 b             1  \n",
            "                                        aten::transpose         0.45%     179.438us         0.62%     246.185us       6.005us       0.000us         0.00%       0.000us       0.000us           0 b           0 b           0 b           0 b            41  \n",
            "                                       aten::as_strided         0.39%     155.023us         0.39%     155.023us       1.140us       0.000us         0.00%       0.000us       0.000us           0 b           0 b           0 b           0 b           136  \n",
            "                                         aten::_to_copy         0.07%      28.102us         0.50%     197.871us      98.935us       0.000us         0.00%       2.015us       1.007us           0 b           0 b       8.50 Kb           0 b             2  \n",
            "                                    aten::empty_strided         0.11%      44.401us         0.11%      44.401us      22.200us       0.000us         0.00%       0.000us       0.000us           0 b           0 b       8.50 Kb       8.50 Kb             2  \n",
            "                                            aten::copy_         0.19%      76.458us         0.41%     163.381us      54.460us       5.279us         0.12%       5.279us       1.760us           0 b           0 b           0 b           0 b             3  \n",
            "-------------------------------------------------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  \n",
            "Self CPU time total: 39.582ms\n",
            "Self CUDA time total: 4.342ms\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(prof.key_averages().table(sort_by=\"self_cuda_memory_usage\", row_limit=10))"
      ],
      "metadata": {
        "id": "73Go3ai3Vq6v",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "5492a903-9400-4cf9-9ef2-42e85618bd0e"
      },
      "execution_count": 38,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "-------------------------------------------------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  \n",
            "                                                   Name    Self CPU %      Self CPU   CPU total %     CPU total  CPU time avg     Self CUDA   Self CUDA %    CUDA total  CUDA time avg       CPU Mem  Self CPU Mem      CUDA Mem  Self CUDA Mem    # of Calls  \n",
            "-------------------------------------------------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  \n",
            "                                            aten::empty         1.53%     605.766us         1.53%     605.766us       6.310us       0.000us         0.00%       0.000us       0.000us       7.96 Kb       7.96 Kb     344.85 Mb     344.85 Mb            96  \n",
            "                                            aten::addmm         1.80%     712.815us         2.27%     899.872us      44.994us       1.053ms        24.25%       1.053ms      52.644us           0 b           0 b     330.00 Kb     330.00 Kb            20  \n",
            "                                         aten::_softmax         0.84%     334.058us         1.22%     483.800us      24.190us     175.578us         4.04%     175.578us       8.779us           0 b           0 b     315.00 Kb     315.00 Kb            20  \n",
            "                                              aten::mul         0.76%     299.885us         1.10%     434.794us      39.527us      51.486us         1.19%      51.486us       4.681us           0 b           0 b     120.50 Kb     120.50 Kb            11  \n",
            "                                              aten::cat         1.58%     623.918us         2.31%     914.293us      29.493us     137.087us         3.16%     137.087us       4.422us           0 b           0 b      62.00 Kb      62.00 Kb            31  \n",
            "                                          aten::resize_         0.16%      61.534us         0.16%      61.534us       5.594us       0.000us         0.00%       0.000us       0.000us           0 b           0 b      32.00 Kb      32.00 Kb            11  \n",
            "                                              aten::bmm         0.93%     366.302us         1.15%     455.422us      45.542us      46.177us         1.06%      46.177us       4.618us           0 b           0 b      20.00 Kb      20.00 Kb            10  \n",
            "                                             aten::tanh         0.50%     199.119us         0.69%     271.255us      27.126us      42.588us         0.98%      42.588us       4.259us           0 b           0 b      20.00 Kb      20.00 Kb            10  \n",
            "                                              aten::add         0.09%      33.801us         0.12%      45.868us      45.868us       4.384us         0.10%       4.384us       4.384us           0 b           0 b      12.00 Kb      12.00 Kb             1  \n",
            "                                              aten::max         0.86%     341.679us         1.21%     479.754us      47.975us     160.157us         3.69%     160.157us      16.016us           0 b           0 b      10.00 Kb      10.00 Kb            10  \n",
            "-------------------------------------------------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  \n",
            "Self CPU time total: 39.582ms\n",
            "Self CUDA time total: 4.342ms\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Exporting the chrome trace"
      ],
      "metadata": {
        "id": "Xg7tmFrdXWJh"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "prof.export_chrome_trace(\"trace.json\")"
      ],
      "metadata": {
        "id": "uUzS6l2BV60H"
      },
      "execution_count": 39,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Problem 2.3"
      ],
      "metadata": {
        "id": "qxwh7T7Jba3T"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### TorchScript Greedy Search Decoder"
      ],
      "metadata": {
        "id": "muUo-8crvvmU"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class GreedySearchDecoder(nn.Module):\n",
        "    def __init__(self, encoder, decoder, decoder_n_layers):\n",
        "        super(GreedySearchDecoder, self).__init__()\n",
        "        self.encoder = encoder\n",
        "        self.decoder = decoder\n",
        "        self._device = device\n",
        "        self._SOS_token = SOS_token\n",
        "        self._decoder_n_layers = decoder_n_layers\n",
        "\n",
        "    __constants__ = ['_device', '_SOS_token', '_decoder_n_layers']\n",
        "\n",
        "    def forward(self, input_seq: torch.Tensor, input_length: torch.Tensor, max_length: int):\n",
        "        # Forward input through encoder model\n",
        "        encoder_outputs, encoder_hidden = self.encoder(input_seq, input_length)\n",
        "        # Prepare encoder's final hidden layer to be first hidden input to the decoder\n",
        "        decoder_hidden = encoder_hidden[:self._decoder_n_layers]\n",
        "        # Initialize decoder input with SOS_token\n",
        "\n",
        "        decoder_input = torch.ones(1, input_seq.shape[1], device=self._device, dtype=torch.long) * self._SOS_token\n",
        "        # Initialize tensors to append decoded words to\n",
        "        all_tokens = torch.zeros([0], device=self._device, dtype=torch.long)\n",
        "        all_scores = torch.zeros([0], device=self._device)\n",
        "        # Iteratively decode one word token at a time\n",
        "        for _ in range(max_length):\n",
        "            # Forward pass through decoder\n",
        "            decoder_output, decoder_hidden = self.decoder(decoder_input, decoder_hidden, encoder_outputs)\n",
        "            # Obtain most likely word token and its softmax score\n",
        "            decoder_scores, decoder_input = torch.max(decoder_output, dim=1)\n",
        "            # Record token and score\n",
        "            all_tokens = torch.cat((all_tokens, decoder_input), dim=0)\n",
        "            all_scores = torch.cat((all_scores, decoder_scores), dim=0)\n",
        "            # Prepare current token to be next decoder input (add a dimension)\n",
        "            decoder_input = torch.unsqueeze(decoder_input, 0)\n",
        "        # Return collections of word tokens and scores\n",
        "        return all_tokens, all_scores"
      ],
      "metadata": {
        "id": "sejUNRcdbaRK"
      },
      "execution_count": 40,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### TorchScript Model"
      ],
      "metadata": {
        "id": "Wn8FAAQg4Y0X"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "device = torch.device('cpu')"
      ],
      "metadata": {
        "id": "yWSgIShwvC71"
      },
      "execution_count": 57,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "save_dir = os.path.join(\"data\", \"save\")\n",
        "corpus_name = \"movie-corpus\"\n",
        "\n",
        "# Configure models\n",
        "model_name = 'cb_model'\n",
        "attn_model = 'dot'\n",
        "hidden_size = 500\n",
        "encoder_n_layers = 2\n",
        "decoder_n_layers = 2\n",
        "dropout = 0.1\n",
        "batch_size = 64\n",
        "\n",
        "checkpoint_iter = 4000\n",
        "\n",
        "loadFilename = os.path.join(save_dir, model_name, corpus_name,\n",
        "                         '{}-{}_{}'.format(encoder_n_layers, decoder_n_layers, hidden_size),\n",
        "                         '{}_checkpoint.tar'.format(checkpoint_iter))\n",
        "\n",
        "# Load model\n",
        "# Force CPU device options (to match tensors in this tutorial)\n",
        "checkpoint = torch.load(loadFilename, map_location=device)\n",
        "encoder_sd = checkpoint['en']\n",
        "decoder_sd = checkpoint['de']\n",
        "encoder_optimizer_sd = checkpoint['en_opt']\n",
        "decoder_optimizer_sd = checkpoint['de_opt']\n",
        "embedding_sd = checkpoint['embedding']\n",
        "voc = Voc(corpus_name)\n",
        "voc.__dict__ = checkpoint['voc_dict']\n",
        "\n",
        "\n",
        "print('Building encoder and decoder ...')\n",
        "# Initialize word embeddings\n",
        "embedding = nn.Embedding(voc.num_words, hidden_size)\n",
        "embedding.load_state_dict(embedding_sd)\n",
        "# Initialize encoder & decoder models\n",
        "encoder = EncoderRNN(hidden_size, embedding, encoder_n_layers, dropout)\n",
        "decoder = LuongAttnDecoderRNN(attn_model, embedding, hidden_size, voc.num_words, decoder_n_layers, dropout)\n",
        "# Load trained model parameters\n",
        "encoder.load_state_dict(encoder_sd)\n",
        "decoder.load_state_dict(decoder_sd)\n",
        "# Use appropriate device\n",
        "encoder = encoder.to(device)\n",
        "decoder = decoder.to(device)\n",
        "# Set dropout layers to ``eval`` mode\n",
        "encoder.eval()\n",
        "decoder.eval()\n",
        "print('Models built and ready to go!')"
      ],
      "metadata": {
        "id": "_-rDi2cs3FR7",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b678d5bc-f8b0-4170-babf-d3d21965ea63"
      },
      "execution_count": 58,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-58-d8618d2baa96>:21: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
            "  checkpoint = torch.load(loadFilename, map_location=device)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Building encoder and decoder ...\n",
            "Models built and ready to go!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "### Compile the whole greedy search model to TorchScript model\n",
        "# Create artificial inputs\n",
        "test_seq = torch.LongTensor(MAX_LENGTH, 1).random_(0, voc.num_words).to(device)\n",
        "test_seq_length = torch.LongTensor([test_seq.size()[0]]).to(torch.device('cpu'))\n",
        "# Trace the model\n",
        "traced_encoder = torch.jit.trace(encoder, (test_seq, test_seq_length))\n",
        "\n",
        "### Convert decoder model\n",
        "# Create and generate artificial inputs\n",
        "test_encoder_outputs, test_encoder_hidden = traced_encoder(test_seq, test_seq_length)\n",
        "test_decoder_hidden = test_encoder_hidden[:decoder.n_layers]\n",
        "test_decoder_input = torch.LongTensor(1, 1).random_(0, voc.num_words)\n",
        "\n",
        "# Move the test inputs to the same device as the model (GPU)\n",
        "test_encoder_outputs = test_encoder_outputs.to(device)\n",
        "test_decoder_hidden = test_decoder_hidden.to(device)\n",
        "test_decoder_input = test_decoder_input.to(device)\n",
        "\n",
        "# Trace the model\n",
        "traced_decoder = torch.jit.trace(decoder, (test_decoder_input, test_decoder_hidden, test_encoder_outputs))\n",
        "\n",
        "### Initialize searcher module by wrapping ``torch.jit.script`` call\n",
        "scripted_searcher = torch.jit.script(GreedySearchDecoder(traced_encoder, traced_decoder, decoder.n_layers))"
      ],
      "metadata": {
        "id": "zMCehxjP4qDZ",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a6303cf5-28f5-44d6-dada-ea01b795f7af"
      },
      "execution_count": 59,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/jit/_trace.py:166: UserWarning: The .grad attribute of a Tensor that is not a leaf Tensor is being accessed. Its .grad attribute won't be populated during autograd.backward(). If you indeed want the .grad field to be populated for a non-leaf Tensor, use .retain_grad() on the non-leaf Tensor. If you access the non-leaf Tensor by mistake, make sure you access the leaf Tensor instead. See github.com/pytorch/pytorch/pull/30531 for more informations. (Triggered internally at aten/src/ATen/core/TensorBody.h:489.)\n",
            "  if a.grad is not None:\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Problem 2.4"
      ],
      "metadata": {
        "id": "7eZ0ZGLlNQM5"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print('scripted_searcher graph:\\n', scripted_searcher.graph)"
      ],
      "metadata": {
        "id": "oo2aCnlF4stj",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "5583a47f-3871-48c0-b33e-9f9c38874de7"
      },
      "execution_count": 60,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "scripted_searcher graph:\n",
            " graph(%self : __torch__.___torch_mangle_60.GreedySearchDecoder,\n",
            "      %input_seq.1 : Tensor,\n",
            "      %input_length.1 : Tensor,\n",
            "      %max_length.1 : int):\n",
            "  %56 : bool = prim::Constant[value=0]()\n",
            "  %45 : bool = prim::Constant[value=1]() # <ipython-input-40-22c2fc12193e>:24:8\n",
            "  %21 : int = prim::Constant[value=4]() # <ipython-input-40-22c2fc12193e>:19:85\n",
            "  %20 : Device = prim::Constant[value=\"cpu\"]() # <ipython-input-40-22c2fc12193e>:19:65\n",
            "  %14 : NoneType = prim::Constant()\n",
            "  %12 : int = prim::Constant[value=2]() # <ipython-input-40-22c2fc12193e>:16:41\n",
            "  %16 : int = prim::Constant[value=1]() # <ipython-input-40-22c2fc12193e>:19:35\n",
            "  %29 : int = prim::Constant[value=0]() # <ipython-input-40-22c2fc12193e>:21:34\n",
            "  %encoder : __torch__.___torch_mangle_40.EncoderRNN = prim::GetAttr[name=\"encoder\"](%self)\n",
            "  %7 : (Tensor, Tensor) = prim::CallMethod[name=\"forward\"](%encoder, %input_seq.1, %input_length.1) # <ipython-input-40-22c2fc12193e>:14:42\n",
            "  %encoder_outputs.1 : Tensor, %encoder_hidden.1 : Tensor = prim::TupleUnpack(%7)\n",
            "  %decoder_hidden.1 : Tensor = aten::slice(%encoder_hidden.1, %29, %14, %12, %16) # <ipython-input-40-22c2fc12193e>:16:25\n",
            "  %18 : int[] = aten::size(%input_seq.1) # <string>:13:9\n",
            "  %19 : int = aten::__getitem__(%18, %16) # <ipython-input-40-22c2fc12193e>:19:38\n",
            "  %23 : int[] = prim::ListConstruct(%16, %19)\n",
            "  %26 : Tensor = aten::ones(%23, %21, %14, %20, %14) # <ipython-input-40-22c2fc12193e>:19:24\n",
            "  %decoder_input.1 : Tensor = aten::mul(%26, %16) # <ipython-input-40-22c2fc12193e>:19:24\n",
            "  %30 : int[] = prim::ListConstruct(%29)\n",
            "  %all_tokens.1 : Tensor = aten::zeros(%30, %21, %14, %20, %14) # <ipython-input-40-22c2fc12193e>:21:21\n",
            "  %36 : int[] = prim::ListConstruct(%29)\n",
            "  %all_scores.1 : Tensor = aten::zeros(%36, %14, %14, %20, %14) # <ipython-input-40-22c2fc12193e>:22:21\n",
            "  %all_tokens : Tensor, %all_scores : Tensor, %decoder_hidden : Tensor, %decoder_input : Tensor = prim::Loop(%max_length.1, %45, %all_tokens.1, %all_scores.1, %decoder_hidden.1, %decoder_input.1) # <ipython-input-40-22c2fc12193e>:24:8\n",
            "    block0(%46 : int, %all_tokens.11 : Tensor, %all_scores.11 : Tensor, %decoder_hidden.9 : Tensor, %decoder_input.17 : Tensor):\n",
            "      %decoder : __torch__.___torch_mangle_51.LuongAttnDecoderRNN = prim::GetAttr[name=\"decoder\"](%self)\n",
            "      %51 : (Tensor, Tensor) = prim::CallMethod[name=\"forward\"](%decoder, %decoder_input.17, %decoder_hidden.9, %encoder_outputs.1) # <ipython-input-40-22c2fc12193e>:26:45\n",
            "      %decoder_output.1 : Tensor, %decoder_hidden.5 : Tensor = prim::TupleUnpack(%51)\n",
            "      %decoder_scores.1 : Tensor, %decoder_input.5 : Tensor = aten::max(%decoder_output.1, %16, %56) # <ipython-input-40-22c2fc12193e>:28:44\n",
            "      %64 : Tensor[] = prim::ListConstruct(%all_tokens.11, %decoder_input.5)\n",
            "      %all_tokens.5 : Tensor = aten::cat(%64, %29) # <ipython-input-40-22c2fc12193e>:30:25\n",
            "      %70 : Tensor[] = prim::ListConstruct(%all_scores.11, %decoder_scores.1)\n",
            "      %all_scores.5 : Tensor = aten::cat(%70, %29) # <ipython-input-40-22c2fc12193e>:31:25\n",
            "      %decoder_input.13 : Tensor = aten::unsqueeze(%decoder_input.5, %29) # <ipython-input-40-22c2fc12193e>:33:28\n",
            "      -> (%45, %all_tokens.5, %all_scores.5, %decoder_hidden.5, %decoder_input.13)\n",
            "  %78 : (Tensor, Tensor) = prim::TupleConstruct(%all_tokens, %all_scores)\n",
            "  return (%78)\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Problem 2.5"
      ],
      "metadata": {
        "id": "CU7u1w0fNU1j"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Use appropriate device\n",
        "scripted_searcher.to(device)\n",
        "# Set dropout layers to ``eval`` mode\n",
        "scripted_searcher.eval()\n",
        "\n",
        "# Evaluate examples\n",
        "sentences = [\"hello\", \"what's up?\", \"who are you?\", \"where am I?\", \"where are you from?\"]\n",
        "for s in sentences:\n",
        "    evaluateExample(s, scripted_searcher, voc)"
      ],
      "metadata": {
        "id": "1bn6XIB04u4s",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "20e5a4ab-46ab-423e-fafd-7860a83d1dd0"
      },
      "execution_count": 61,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "> hello\n",
            "Bot: hello . s a lovely .\n",
            "> what's up?\n",
            "Bot: harry . . . . .\n",
            "> who are you?\n",
            "Bot: thomas kent . i m with .\n",
            "> where am I?\n",
            "Bot: i can t . the past . .\n",
            "> where are you from?\n",
            "Bot: south boston . . hospital .\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Problem 2.6"
      ],
      "metadata": {
        "id": "MK5tX0PQNfJ5"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def evaluateAndTime(searcher, eval_batches, n_iteration, device, max_length=MAX_LENGTH):\n",
        "    time_diffs = []\n",
        "    searcher = searcher.to(device)\n",
        "    for iteration in range(n_iteration):\n",
        "        input_variable, lengths, target_variable, mask, max_target_len = eval_batches[iteration]\n",
        "        input_variable = input_variable.to(device)\n",
        "        lengths = lengths.to('cpu')\n",
        "        if iteration > 5:\n",
        "            torch.cuda.synchronize()\n",
        "            start = time.monotonic_ns()\n",
        "        with torch.no_grad():\n",
        "            output = searcher(input_variable, lengths, max_length)\n",
        "        if iteration > 5:\n",
        "            torch.cuda.synchronize()\n",
        "            end = time.monotonic_ns()\n",
        "        if iteration > 5:\n",
        "            time_diffs.append(end - start)\n",
        "    return np.array(time_diffs) / 1_000_000"
      ],
      "metadata": {
        "id": "5sG5wZkLNetl"
      },
      "execution_count": 62,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "n_iteration = 100\n",
        "\n",
        "eval_batches = [batch2TrainData(voc, [random.choice(pairs) for _ in range(64)])\n",
        "                    for _ in range(n_iteration)]"
      ],
      "metadata": {
        "id": "-k8BOFotOm7q"
      },
      "execution_count": 63,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "device = torch.device('cuda')\n",
        "\n",
        "regular_gpu = evaluateAndTime(best_model_searcher, eval_batches, n_iteration, device)\n",
        "\n",
        "print(regular_gpu.mean())"
      ],
      "metadata": {
        "id": "Epyku_DIOOcX",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "374d3c11-68f5-4bec-f61a-795f0d59598c"
      },
      "execution_count": 64,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "14.70044623404255\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "device = torch.device('cpu')\n",
        "\n",
        "regular_cpu = evaluateAndTime(best_model_searcher, eval_batches, n_iteration, device)\n",
        "\n",
        "print(regular_cpu.mean())"
      ],
      "metadata": {
        "id": "dZzajNldOgZS",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "25352e74-4a30-4bcb-dceb-262fa640dd41"
      },
      "execution_count": 65,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "286.13959080851066\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "device = torch.device('cpu')\n",
        "\n",
        "torchscript_cpu = evaluateAndTime(scripted_searcher, eval_batches, n_iteration, device)\n",
        "\n",
        "print(torchscript_cpu.mean())"
      ],
      "metadata": {
        "id": "x5qxveN0PGUT",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "519c1ba7-a810-4c57-d99f-4517398a4c6f"
      },
      "execution_count": 66,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "280.9392284680851\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "scripted_searcher.save(\"scripted_chatbot_cpu.pth\")"
      ],
      "metadata": {
        "id": "h8HFo2GOtEK0"
      },
      "execution_count": 67,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### TorchScript Model for GPU"
      ],
      "metadata": {
        "id": "nkJPV8_Hq_oH"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "device = torch.device('cuda')\n",
        "\n",
        "save_dir = os.path.join(\"data\", \"save\")\n",
        "corpus_name = \"movie-corpus\"\n",
        "\n",
        "# Configure models\n",
        "model_name = 'cb_model'\n",
        "attn_model = 'dot'\n",
        "hidden_size = 500\n",
        "encoder_n_layers = 2\n",
        "decoder_n_layers = 2\n",
        "dropout = 0.1\n",
        "batch_size = 64\n",
        "\n",
        "checkpoint_iter = 4000\n",
        "\n",
        "loadFilename = os.path.join(save_dir, model_name, corpus_name,\n",
        "                         '{}-{}_{}'.format(encoder_n_layers, decoder_n_layers, hidden_size),\n",
        "                         '{}_checkpoint.tar'.format(checkpoint_iter))\n",
        "\n",
        "# Load model\n",
        "# Force CPU device options (to match tensors in this tutorial)\n",
        "checkpoint = torch.load(loadFilename, map_location=device)\n",
        "encoder_sd = checkpoint['en']\n",
        "decoder_sd = checkpoint['de']\n",
        "encoder_optimizer_sd = checkpoint['en_opt']\n",
        "decoder_optimizer_sd = checkpoint['de_opt']\n",
        "embedding_sd = checkpoint['embedding']\n",
        "voc = Voc(corpus_name)\n",
        "voc.__dict__ = checkpoint['voc_dict']\n",
        "\n",
        "\n",
        "print('Building encoder and decoder ...')\n",
        "# Initialize word embeddings\n",
        "embedding = nn.Embedding(voc.num_words, hidden_size)\n",
        "embedding.load_state_dict(embedding_sd)\n",
        "# Initialize encoder & decoder models\n",
        "encoder = EncoderRNN(hidden_size, embedding, encoder_n_layers, dropout)\n",
        "decoder = LuongAttnDecoderRNN(attn_model, embedding, hidden_size, voc.num_words, decoder_n_layers, dropout)\n",
        "# Load trained model parameters\n",
        "encoder.load_state_dict(encoder_sd)\n",
        "decoder.load_state_dict(decoder_sd)\n",
        "# Use appropriate device\n",
        "encoder = encoder.to(device)\n",
        "decoder = decoder.to(device)\n",
        "# Set dropout layers to ``eval`` mode\n",
        "encoder.eval()\n",
        "decoder.eval()\n",
        "print('Models built and ready to go!')\n",
        "\n",
        "### Compile the whole greedy search model to TorchScript model\n",
        "# Create artificial inputs\n",
        "test_seq = torch.LongTensor(MAX_LENGTH, 1).random_(0, voc.num_words).to(device)\n",
        "test_seq_length = torch.LongTensor([test_seq.size()[0]]).to(torch.device('cpu'))\n",
        "# Trace the model\n",
        "traced_encoder = torch.jit.trace(encoder, (test_seq, test_seq_length))\n",
        "\n",
        "### Convert decoder model\n",
        "# Create and generate artificial inputs\n",
        "test_encoder_outputs, test_encoder_hidden = traced_encoder(test_seq, test_seq_length)\n",
        "test_decoder_hidden = test_encoder_hidden[:decoder.n_layers]\n",
        "test_decoder_input = torch.LongTensor(1, 1).random_(0, voc.num_words)\n",
        "\n",
        "# Move the test inputs to the same device as the model (GPU)\n",
        "test_encoder_outputs = test_encoder_outputs.to(device)\n",
        "test_decoder_hidden = test_decoder_hidden.to(device)\n",
        "test_decoder_input = test_decoder_input.to(device)\n",
        "\n",
        "# Trace the model\n",
        "traced_decoder = torch.jit.trace(decoder, (test_decoder_input, test_decoder_hidden, test_encoder_outputs))\n",
        "\n",
        "### Initialize searcher module by wrapping ``torch.jit.script`` call\n",
        "scripted_searcher = torch.jit.script(GreedySearchDecoder(traced_encoder, traced_decoder, decoder.n_layers))\n",
        "\n",
        "print('scripted_searcher graph:\\n', scripted_searcher.graph)"
      ],
      "metadata": {
        "id": "uKNlx99cqo_9",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "1147bf82-dbf5-441f-bee9-5024099d49f0"
      },
      "execution_count": 68,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-68-69c2af95745b>:23: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
            "  checkpoint = torch.load(loadFilename, map_location=device)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Building encoder and decoder ...\n",
            "Models built and ready to go!\n",
            "scripted_searcher graph:\n",
            " graph(%self : __torch__.___torch_mangle_83.GreedySearchDecoder,\n",
            "      %input_seq.1 : Tensor,\n",
            "      %input_length.1 : Tensor,\n",
            "      %max_length.1 : int):\n",
            "  %56 : bool = prim::Constant[value=0]()\n",
            "  %45 : bool = prim::Constant[value=1]() # <ipython-input-40-22c2fc12193e>:24:8\n",
            "  %21 : int = prim::Constant[value=4]() # <ipython-input-40-22c2fc12193e>:19:85\n",
            "  %20 : Device = prim::Constant[value=\"cuda\"]() # <ipython-input-40-22c2fc12193e>:19:65\n",
            "  %14 : NoneType = prim::Constant()\n",
            "  %12 : int = prim::Constant[value=2]() # <ipython-input-40-22c2fc12193e>:16:41\n",
            "  %16 : int = prim::Constant[value=1]() # <ipython-input-40-22c2fc12193e>:19:35\n",
            "  %29 : int = prim::Constant[value=0]() # <ipython-input-40-22c2fc12193e>:21:34\n",
            "  %encoder : __torch__.___torch_mangle_63.EncoderRNN = prim::GetAttr[name=\"encoder\"](%self)\n",
            "  %7 : (Tensor, Tensor) = prim::CallMethod[name=\"forward\"](%encoder, %input_seq.1, %input_length.1) # <ipython-input-40-22c2fc12193e>:14:42\n",
            "  %encoder_outputs.1 : Tensor, %encoder_hidden.1 : Tensor = prim::TupleUnpack(%7)\n",
            "  %decoder_hidden.1 : Tensor = aten::slice(%encoder_hidden.1, %29, %14, %12, %16) # <ipython-input-40-22c2fc12193e>:16:25\n",
            "  %18 : int[] = aten::size(%input_seq.1) # <string>:13:9\n",
            "  %19 : int = aten::__getitem__(%18, %16) # <ipython-input-40-22c2fc12193e>:19:38\n",
            "  %23 : int[] = prim::ListConstruct(%16, %19)\n",
            "  %26 : Tensor = aten::ones(%23, %21, %14, %20, %14) # <ipython-input-40-22c2fc12193e>:19:24\n",
            "  %decoder_input.1 : Tensor = aten::mul(%26, %16) # <ipython-input-40-22c2fc12193e>:19:24\n",
            "  %30 : int[] = prim::ListConstruct(%29)\n",
            "  %all_tokens.1 : Tensor = aten::zeros(%30, %21, %14, %20, %14) # <ipython-input-40-22c2fc12193e>:21:21\n",
            "  %36 : int[] = prim::ListConstruct(%29)\n",
            "  %all_scores.1 : Tensor = aten::zeros(%36, %14, %14, %20, %14) # <ipython-input-40-22c2fc12193e>:22:21\n",
            "  %all_tokens : Tensor, %all_scores : Tensor, %decoder_hidden : Tensor, %decoder_input : Tensor = prim::Loop(%max_length.1, %45, %all_tokens.1, %all_scores.1, %decoder_hidden.1, %decoder_input.1) # <ipython-input-40-22c2fc12193e>:24:8\n",
            "    block0(%46 : int, %all_tokens.11 : Tensor, %all_scores.11 : Tensor, %decoder_hidden.9 : Tensor, %decoder_input.17 : Tensor):\n",
            "      %decoder : __torch__.___torch_mangle_74.LuongAttnDecoderRNN = prim::GetAttr[name=\"decoder\"](%self)\n",
            "      %51 : (Tensor, Tensor) = prim::CallMethod[name=\"forward\"](%decoder, %decoder_input.17, %decoder_hidden.9, %encoder_outputs.1) # <ipython-input-40-22c2fc12193e>:26:45\n",
            "      %decoder_output.1 : Tensor, %decoder_hidden.5 : Tensor = prim::TupleUnpack(%51)\n",
            "      %decoder_scores.1 : Tensor, %decoder_input.5 : Tensor = aten::max(%decoder_output.1, %16, %56) # <ipython-input-40-22c2fc12193e>:28:44\n",
            "      %64 : Tensor[] = prim::ListConstruct(%all_tokens.11, %decoder_input.5)\n",
            "      %all_tokens.5 : Tensor = aten::cat(%64, %29) # <ipython-input-40-22c2fc12193e>:30:25\n",
            "      %70 : Tensor[] = prim::ListConstruct(%all_scores.11, %decoder_scores.1)\n",
            "      %all_scores.5 : Tensor = aten::cat(%70, %29) # <ipython-input-40-22c2fc12193e>:31:25\n",
            "      %decoder_input.13 : Tensor = aten::unsqueeze(%decoder_input.5, %29) # <ipython-input-40-22c2fc12193e>:33:28\n",
            "      -> (%45, %all_tokens.5, %all_scores.5, %decoder_hidden.5, %decoder_input.13)\n",
            "  %78 : (Tensor, Tensor) = prim::TupleConstruct(%all_tokens, %all_scores)\n",
            "  return (%78)\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "device = torch.device('cuda')\n",
        "\n",
        "torchscript_gpu = evaluateAndTime(scripted_searcher, eval_batches, n_iteration, device)\n",
        "\n",
        "print(torchscript_gpu.mean())"
      ],
      "metadata": {
        "id": "RmOR-9jEPGIU",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "782d0ea4-7b75-4a92-9a11-8ecf6ad22420"
      },
      "execution_count": 69,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "9.89043485106383\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "\n",
        "timing_table = pd.DataFrame({\n",
        "    'Framework': ['PyTorch', 'TorchScript'],\n",
        "    'Latency on CPU (ms)': [regular_cpu.mean(), torchscript_cpu.mean()],\n",
        "    'Latency on GPU (ms)': [regular_gpu.mean(), torchscript_gpu.mean()]\n",
        "})"
      ],
      "metadata": {
        "id": "I0O1Iu_nrrJW"
      },
      "execution_count": 70,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Timing Table"
      ],
      "metadata": {
        "id": "ift8WDZesvOx"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "timing_table"
      ],
      "metadata": {
        "id": "N6JSIjCLr2xC",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 125
        },
        "outputId": "a13e3c52-864d-40b5-afa6-f4271360d41f"
      },
      "execution_count": 71,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "     Framework  Latency on CPU (ms)  Latency on GPU (ms)\n",
              "0      PyTorch           286.139591            14.700446\n",
              "1  TorchScript           280.939228             9.890435"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-c691c9c9-e18f-4062-ae36-5ec41b5bae72\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Framework</th>\n",
              "      <th>Latency on CPU (ms)</th>\n",
              "      <th>Latency on GPU (ms)</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>PyTorch</td>\n",
              "      <td>286.139591</td>\n",
              "      <td>14.700446</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>TorchScript</td>\n",
              "      <td>280.939228</td>\n",
              "      <td>9.890435</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-c691c9c9-e18f-4062-ae36-5ec41b5bae72')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-c691c9c9-e18f-4062-ae36-5ec41b5bae72 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-c691c9c9-e18f-4062-ae36-5ec41b5bae72');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-cc288a8b-0931-4f4b-946a-a379c3a83ab5\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-cc288a8b-0931-4f4b-946a-a379c3a83ab5')\"\n",
              "            title=\"Suggest charts\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-cc288a8b-0931-4f4b-946a-a379c3a83ab5 button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "\n",
              "  <div id=\"id_5618dc73-5a59-4369-b9f6-3d6da20c6c16\">\n",
              "    <style>\n",
              "      .colab-df-generate {\n",
              "        background-color: #E8F0FE;\n",
              "        border: none;\n",
              "        border-radius: 50%;\n",
              "        cursor: pointer;\n",
              "        display: none;\n",
              "        fill: #1967D2;\n",
              "        height: 32px;\n",
              "        padding: 0 0 0 0;\n",
              "        width: 32px;\n",
              "      }\n",
              "\n",
              "      .colab-df-generate:hover {\n",
              "        background-color: #E2EBFA;\n",
              "        box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "        fill: #174EA6;\n",
              "      }\n",
              "\n",
              "      [theme=dark] .colab-df-generate {\n",
              "        background-color: #3B4455;\n",
              "        fill: #D2E3FC;\n",
              "      }\n",
              "\n",
              "      [theme=dark] .colab-df-generate:hover {\n",
              "        background-color: #434B5C;\n",
              "        box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "        filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "        fill: #FFFFFF;\n",
              "      }\n",
              "    </style>\n",
              "    <button class=\"colab-df-generate\" onclick=\"generateWithVariable('timing_table')\"\n",
              "            title=\"Generate code using this dataframe.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M7,19H8.4L18.45,9,17,7.55,7,17.6ZM5,21V16.75L18.45,3.32a2,2,0,0,1,2.83,0l1.4,1.43a1.91,1.91,0,0,1,.58,1.4,1.91,1.91,0,0,1-.58,1.4L9.25,21ZM18.45,9,17,7.55Zm-12,3A5.31,5.31,0,0,0,4.9,8.1,5.31,5.31,0,0,0,1,6.5,5.31,5.31,0,0,0,4.9,4.9,5.31,5.31,0,0,0,6.5,1,5.31,5.31,0,0,0,8.1,4.9,5.31,5.31,0,0,0,12,6.5,5.46,5.46,0,0,0,6.5,12Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "    <script>\n",
              "      (() => {\n",
              "      const buttonEl =\n",
              "        document.querySelector('#id_5618dc73-5a59-4369-b9f6-3d6da20c6c16 button.colab-df-generate');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      buttonEl.onclick = () => {\n",
              "        google.colab.notebook.generateWithVariable('timing_table');\n",
              "      }\n",
              "      })();\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "variable_name": "timing_table",
              "summary": "{\n  \"name\": \"timing_table\",\n  \"rows\": 2,\n  \"fields\": [\n    {\n      \"column\": \"Framework\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 2,\n        \"samples\": [\n          \"TorchScript\",\n          \"PyTorch\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Latency on CPU (ms)\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 3.677211475542056,\n        \"min\": 280.9392284680851,\n        \"max\": 286.13959080851066,\n        \"num_unique_values\": 2,\n        \"samples\": [\n          280.9392284680851,\n          286.13959080851066\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Latency on GPU (ms)\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 3.4011916664887365,\n        \"min\": 9.89043485106383,\n        \"max\": 14.70044623404255,\n        \"num_unique_values\": 2,\n        \"samples\": [\n          9.89043485106383,\n          14.70044623404255\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}"
            }
          },
          "metadata": {},
          "execution_count": 71
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Problem 2.7"
      ],
      "metadata": {
        "id": "C0_6HuiPNaRY"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "scripted_searcher.save(\"scripted_chatbot_gpu.pth\")"
      ],
      "metadata": {
        "id": "rImqXHP14vZU"
      },
      "execution_count": 72,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "soSxObOANoZ0"
      },
      "execution_count": 56,
      "outputs": []
    }
  ]
}